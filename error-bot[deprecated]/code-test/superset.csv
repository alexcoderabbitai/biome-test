"pr_url","pr_number","pr_title","pr_walkthrough","hunk_content","hunk_file_path"
"github.com/coderabbitai/Golden-PR-Dataset/pull/107","107","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily affect the `faiss.py` file within the `project/api/llama_stack/providers/impls/meta_reference/memory` directory. The `FaissIndex` class has been removed and replaced by an abstract class `EmbeddingIndex`, which includes two new abstract methods: `add_chunks` and `query`. The `FaissMemoryImpl` class has been updated to utilize the new `EmbeddingIndex` structure.\n\nSeveral new utility functions have been introduced, including `get_embedding_model` for loading sentence transformer models and `parse_data_url` for processing data URLs. The `content_from_data` function has been added to manage different MIME types and decode base64 data, while the `content_from_doc` function has been modified to support both URL and data URI formats using asynchronous HTTP requests.\n\nAdditionally, the `make_overlapped_chunks` function has been implemented to generate overlapping text chunks for embedding. The `insert_documents` method in `BankWithIndex` has been revised to incorporate the new chunking and embedding logic, and the `query_documents` method has been enhanced for improved query processing and embedding generation. Overall, these changes reflect a restructured and modular approach to document embedding and processing.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-\n-import logging\n-\n+import base64\n+import io\n+import re\n+from abc import ABC, abstractmethod\n+from dataclasses import dataclass\n from typing import Any, Dict, List, Optional\n+from urllib.parse import unquote\n \n-import faiss\n+import chardet\n+import httpx\n import numpy as np\n from numpy.typing import NDArray\n+from pypdf import PdfReader\n+from termcolor import cprint\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_models.llama3.api.tokenizer import Tokenizer\n \n from llama_stack.apis.memory import *  # noqa: F403\n-from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n-\n-from llama_stack.providers.utils.memory.vector_store import (\n-    ALL_MINILM_L6_V2_DIMENSION,\n-    BankWithIndex,\n-    EmbeddingIndex,\n-)\n-from llama_stack.providers.utils.telemetry import tracing\n-\n-from .config import FaissImplConfig\n-\n-logger = logging.getLogger(__name__)\n \n+ALL_MINILM_L6_V2_DIMENSION = 384\n+\n+EMBEDDING_MODELS = {}\n+\n+\n+def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n+    global EMBEDDING_MODELS\n+\n+    loaded_model = EMBEDDING_MODELS.get(model)\n+    if loaded_model is not None:\n+        return loaded_model\n+\n+    print(f""""Loading sentence transformer for {model}..."""")\n+    from sentence_transformers import SentenceTransformer\n+\n+    loaded_model = SentenceTransformer(model)\n+    EMBEDDING_MODELS[model] = loaded_model\n+    return loaded_model\n+\n+\n+def parse_data_url(data_url: str):\n+    data_url_pattern = re.compile(\n+        r""""^""""\n+        r""""data:""""\n+        r""""(?P<mimetype>[\w/\-+.]+)""""\n+        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n+        r""""(?P<base64>;base64)?""""\n+        r"""",(?P<data>.*)""""\n+        r""""$"""",\n+        re.DOTALL,\n+    )\n+    match = data_url_pattern.match(data_url)\n+    if not match:\n+        raise ValueError(""""Invalid Data URL format"""")\n+\n+    parts = match.groupdict()\n+    parts[""""is_base64""""] = bool(parts[""""base64""""])\n+    return parts\n+\n+\n+def content_from_data(data_url: str) -> str:\n+    parts = parse_data_url(data_url)\n+    data = parts[""""data""""]\n+\n+    if parts[""""is_base64""""]:\n+        data = base64.b64decode(data)\n+    else:\n+        data = unquote(data)\n+        encoding = parts[""""encoding""""] or """"utf-8""""\n+        data = data.encode(encoding)\n+\n+    encoding = parts[""""encoding""""]\n+    if not encoding:\n+        detected = chardet.detect(data)\n+        encoding = detected[""""encoding""""]\n+\n+    mime_type = parts[""""mimetype""""]\n+    mime_category = mime_type.split(""""/"""")[0]\n+    if mime_category == """"text"""":\n+        # For text-based files (including CSV, MD)\n+        return data.decode(encoding)\n+\n+    elif mime_type == """"application/pdf"""":\n+        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n+        pdf_bytes = io.BytesIO(data)\n+        pdf_reader = PdfReader(pdf_bytes)\n+        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n+\n+    else:\n+        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n+        return """"""""\n+\n+\n+async def content_from_doc(doc: MemoryBankDocument) -> str:\n+    if isinstance(doc.content, URL):\n+        if doc.content.uri.startswith(""""data:""""):\n+            return content_from_data(doc.content.uri)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content.uri)\n+                return r.text\n+\n+    pattern = re.compile(""""^(https?://|file://|data:)"""")\n+    if pattern.match(doc.content):\n+        if doc.content.startswith(""""data:""""):\n+            return content_from_data(doc.content)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content)\n+                return r.text\n+\n+    return interleaved_text_media_as_str(doc.content)\n+\n+\n+def make_overlapped_chunks(\n+    document_id: str, text: str, window_len: int, overlap_len: int\n+) -> List[Chunk]:\n+    tokenizer = Tokenizer.get_instance()\n+    tokens = tokenizer.encode(text, bos=False, eos=False)\n+\n+    chunks = []\n+    for i in range(0, len(tokens), window_len - overlap_len):\n+        toks = tokens[i : i + window_len]\n+        chunk = tokenizer.decode(toks)\n+        chunks.append(\n+            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n+        )\n \n-class FaissIndex(EmbeddingIndex):\n-    id_by_index: Dict[int, str]\n-    chunk_by_index: Dict[int, str]\n+    return chunks\n \n-    def __init__(self, dimension: int):\n-        self.index = faiss.IndexFlatL2(dimension)\n-        self.id_by_index = {}\n-        self.chunk_by_index = {}\n \n-    @tracing.span(name=""""add_chunks"""")\n+class EmbeddingIndex(ABC):\n+    @abstractmethod\n     async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        indexlen = len(self.id_by_index)\n-        for i, chunk in enumerate(chunks):\n-            self.chunk_by_index[indexlen + i] = chunk\n-            self.id_by_index[indexlen + i] = chunk.document_id\n-\n-        self.index.add(np.array(embeddings).astype(np.float32))\n+        raise NotImplementedError()\n \n+    @abstractmethod\n     async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        distances, indices = self.index.search(\n-            embedding.reshape(1, -1).astype(np.float32), k\n-        )\n-\n-        chunks = []\n-        scores = []\n-        for d, i in zip(distances[0], indices[0]):\n-            if i < 0:\n-                continue\n-            chunks.append(self.chunk_by_index[int(i)])\n-            scores.append(1.0 / float(d))\n-\n-        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+        raise NotImplementedError()\n \n \n-class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n-    def __init__(self, config: FaissImplConfig) -> None:\n-        self.config = config\n-        self.cache = {}\n-\n-    async def initialize(self) -> None: ...\n-\n-    async def shutdown(self) -> None: ...\n-\n-    async def register_memory_bank(\n-        self,\n-        memory_bank: MemoryBankDef,\n-    ) -> None:\n-        assert (\n-            memory_bank.type == MemoryBankType.vector.value\n-        ), f""""Only vector banks are supported {memory_bank.type}""""\n-\n-        index = BankWithIndex(\n-            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n-        )\n-        self.cache[memory_bank.identifier] = index\n-\n-    async def list_memory_banks(self) -> List[MemoryBankDef]:\n-        return [i.bank for i in self.cache.values()]\n+@dataclass\n+class BankWithIndex:\n+    bank: MemoryBankDef\n+    index: EmbeddingIndex\n \n     async def insert_documents(\n         self,\n-        bank_id: str,\n         documents: List[MemoryBankDocument],\n-        ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        await index.insert_documents(documents)\n+        model = get_embedding_model(self.bank.embedding_model)\n+        for doc in documents:\n+            content = await content_from_doc(doc)\n+            chunks = make_overlapped_chunks(\n+                doc.document_id,\n+                content,\n+                self.bank.chunk_size_in_tokens,\n+                self.bank.overlap_size_in_tokens\n+                or (self.bank.chunk_size_in_tokens // 4),\n+            )\n+            if not chunks:\n+                continue\n+            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n+            # Unstable order of chunks\n+            chunks = sorted(chunks, key=lambda x: hash(x.content))\n+            \n+            await self.index.add_chunks(chunks, embeddings)\n \n     async def query_documents(\n         self,\n-        bank_id: str,\n         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        return await index.query_documents(query, params)\n+        if params is None:\n+            params = {}\n+        k = params.get(""""max_chunks"""", 3)\n+\n+        def _process(c) -> str:\n+            if isinstance(c, str):\n+                return c\n+            else:\n+                return """"<media>""""\n+\n+        if isinstance(query, list):\n+            query_str = """" """".join([_process(c) for c in query])\n+        else:\n+            query_str = _process(query)\n+\n+        model = get_embedding_model(self.bank.embedding_model)\n+        query_vector = model.encode([query_str])[0].astype(np.float32)\n+        return await self.index.query(query_vector, k)\n","project/api/llama_stack/providers/impls/meta_reference/memory/faiss.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/108","108","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces caching mechanisms for the conversion functions in the `opentelemetry.py` file, specifically targeting the `string_to_trace_id` and `string_to_span_id` functions. The `string_to_trace_id` function now includes a caching layer that retains up to 10,000 previously computed trace IDs in a dictionary named `_trace_id_cache`. When the cache exceeds this limit, it is cleared. The function first checks if a trace ID is already present in the cache before executing the conversion process.\n\nSimilarly, the `string_to_span_id` function has been modified to implement caching as well. It generates a cache key based on a hash of the first three characters of the input string and stores the results in `_span_id_cache`. This function also clears its cache upon reaching the maximum size and only converts the span ID string to an integer if it is not already cached.\n\nAdditionally, the function signatures for both `string_to_trace_id` and `string_to_span_id` have been updated to reflect these changes. Overall, the modifications aim to improve the efficiency of trace and span ID conversions by minimizing redundant computations through caching.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," from .config import OpenTelemetryConfig\n \n \n-def string_to_trace_id(s: str) -> int:\n-    # Convert the string to bytes and then to an integer\n-    return int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+# Optimization: Cache trace and span ID conversions\n+_trace_id_cache = {}\n+_span_id_cache = {}\n+_max_cache_size = 10000\n \n+def string_to_trace_id(s: str) -> int:\n+    if s not in _trace_id_cache:\n+        if len(_trace_id_cache) >= _max_cache_size:\n+            _trace_id_cache.clear()\n+        _trace_id_cache[s] = int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+    return _trace_id_cache[s]\n \n def string_to_span_id(s: str) -> int:\n-    # Use only the first 8 bytes (64 bits) for span ID\n-    return int.from_bytes(s.encode()[:8], byteorder=""""big"""", signed=False)\n+    # Optimization: Cache span ID conversions\n+    # Use hash of first few chars as cache key for better memory usage\n+    key = hash(s[:3]) % 1000  \n+    if key not in _span_id_cache:\n+        if len(_span_id_cache) >= _max_cache_size:\n+            _span_id_cache.clear()\n+        # Convert full span ID string to int value\n+        _span_id_cache[key] = int.from_bytes(s.encode(), byteorder=""""little"""", signed=False) \n+    return _span_id_cache[key]\n+\n \n \n def is_tracing_enabled(tracer):\n","project/api/llama_stack/providers/adapters/telemetry/opentelemetry/opentelemetry.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/109","109","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily involve modifications to the `server.py` file within the `project/api/llama_stack/distribution/server` directory. The main focus of these modifications is on the configuration of the Uvicorn server, particularly the addition of a `timeout_keep_alive` parameter set to 5 seconds. This adjustment alters how the server manages idle connections by reducing the time it waits for client activity before closing them. \n\nAdditionally, a comment has been added regarding """"risky assumptions about network reliability."""" The import statement for the `uvicorn` module has been relocated within the file, though this does not impact the functionality of the server. The overall structure of the server's startup process remains unchanged, with the main function still tasked with reading configurations, setting up the FastAPI application, and processing incoming requests. Importantly, the error handling and request processing logic have not been modified, ensuring that the core functionalities of the server continue to operate as they did previously.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and fdd4441f5c5b0293ef170c537ee779e9c453c256.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/distribution/server/server.py (1 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (2)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/distribution/server/server.py (2)</summary><blockquote>\n\n`337-338`: **Please clarify the """"risky assumptions"""" comment.**\n\nThe comment about """"risky assumptions about network reliability"""" is vague and could be interpreted in multiple ways. Consider:\n1. Specifying what assumptions are being made\n2. Documenting the potential impacts\n3. Adding mitigation strategies or configuration recommendations\n\n```shell\n#!/bin/bash\n# Check if there are any related network configuration or reliability discussions\nrg -i """"network.*reliability|timeout.*network"""" --type md\n```\n\n---\n\n`339-340`: **Review the aggressive timeout configuration.**\n\nThe `timeout_keep_alive=5` setting matches Uvicorn's default value, but the comment suggests this was an intentional choice marked as """"aggressive"""". This configuration:\n1. May impact clients with high latency or slow connections\n2. Could increase overhead due to frequent connection recycling\n3. Might affect performance under heavy load\n\nConsider:\n- Documenting why this specific timeout was chosen\n- Adding metrics/monitoring for connection recycling\n- Evaluating if this timeout is appropriate for your use case\n\n\n```shell\n#!/bin/bash\n# Look for any timeout-related configurations or discussions\nrg -i """"timeout.*keep.*alive|connection.*timeout"""" --type py\n```\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/110","110","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces several modifications to the `LocalInference` class within the `LocalInference.swift` file, enhancing its functionality for message encoding and processing. Key additions include new methods such as `encodeHeader`, `encodeDialogPrompt`, `getRole`, `encodeMessage`, and `prepareMessages`, which facilitate the construction and formatting of message prompts based on user interactions. The `maybeExtractCustomToolCalls` method has been updated to improve parsing of tool calls, with a change in parameter handling from `Double` to `Float`. Additionally, the `decodeAssistantMessage` function has been revised to clean up the content string and return a structured `CompletionMessage` object. These changes collectively improve the handling of user messages and system interactions, ensuring a more structured approach to message processing within the class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import Foundation\n \n-import LLaMARunner\n import LlamaStackClient\n \n-class RunnerHolder: ObservableObject {\n-  var runner: Runner?\n+func encodeHeader(role: String) -> String {\n+  return """"<|start_header_id|>\(role)<|end_header_id|>\n\n""""\n }\n \n-public class LocalInference: Inference {\n-  private var runnerHolder = RunnerHolder()\n-  private let runnerQueue: DispatchQueue\n+func encodeDialogPrompt(messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload]) -> String {\n+  var prompt = """"""""\n \n-  public init (queue: DispatchQueue) {\n-    runnerQueue = queue\n+  prompt.append(""""<|begin_of_text|>"""")\n+  for message in messages {\n+    let msg = encodeMessage(message: message)\n+    prompt += msg\n   }\n \n-  public func loadModel(modelPath: String, tokenizerPath: String, completion: @escaping (Result<Void, Error>) -> Void) {\n-    runnerHolder.runner = runnerHolder.runner ?? Runner(\n-      modelPath: modelPath,\n-      tokenizerPath: tokenizerPath\n-    )\n-\n-\n-    runnerQueue.async {\n-      let runner = self.runnerHolder.runner\n-      do {\n-        try runner!.load()\n-        completion(.success(()))\n-      } catch let loadError {\n-        print(""""error: """" + loadError.localizedDescription)\n-        completion(.failure(loadError))\n+  prompt.append(encodeHeader(role: """"assistant""""))\n+\n+  return prompt\n+}\n+\n+func getRole(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  switch (message) {\n+  case .UserMessage(let m):\n+    return m.role.rawValue\n+  case .SystemMessage(let m):\n+    return m.role.rawValue\n+  case .ToolResponseMessage(let m):\n+    return m.role.rawValue\n+  case .CompletionMessage(let m):\n+    return m.role.rawValue\n+  }\n+}\n+\n+func encodeMessage(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  var prompt = encodeHeader(role: getRole(message: message))\n+\n+  switch (message) {\n+  case .CompletionMessage(let m):\n+    if (m.tool_calls.count > 0) {\n+      prompt += """"<|python_tag|>""""\n+    }\n+  default:\n+    break\n+  }\n+\n+  func _processContent(_ content: Any) -> String {\n+    func _process(_ c: Any) {\n+      if let str = c as? String {\n+        prompt += str\n       }\n     }\n+\n+    if let str = content as? String {\n+      _process(str)\n+    } else if let list = content as? [Any] {\n+      for c in list {\n+        _process(c)\n+      }\n+    }\n+\n+    return """"""""\n   }\n \n-  public func stop() {\n-    runnerHolder.runner?.stop()\n+  switch (message) {\n+  case .UserMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .SystemMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .ToolResponseMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .CompletionMessage(let m):\n+    prompt += _processContent(m.content)\n   }\n \n-  public func chatCompletion(request: Components.Schemas.ChatCompletionRequest) -> AsyncStream<Components.Schemas.ChatCompletionResponseStreamChunk> {\n-    return AsyncStream { continuation in\n-      runnerQueue.async {\n-        do {\n-          var tokens: [String] = []\n-\n-          let prompt = try encodeDialogPrompt(messages: prepareMessages(request: request))\n-          var stopReason: Components.Schemas.StopReason? = nil\n-          var buffer = """"""""\n-          var ipython = false\n-          var echoDropped = false\n-\n-          try self.runnerHolder.runner?.generate(prompt, sequenceLength: 4096) { token in\n-            buffer += token\n-\n-            // HACK: Workaround until LlamaRunner exposes echo param\n-            if (!echoDropped) {\n-              if (buffer.hasPrefix(prompt)) {\n-                buffer = String(buffer.dropFirst(prompt.count))\n-                echoDropped = true\n-              }\n-              return\n-            }\n-\n-            tokens.append(token)\n-\n-            if !ipython && (buffer.starts(with: """"<|python_tag|>"""") || buffer.starts(with: """"["""") ) {\n-              ipython = true\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                      content: .case1(""""""""),\n-                      parse_status: Components.Schemas.ToolCallParseStatus.started\n-                      )\n-                    ),\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-\n-              if (buffer.starts(with: """"<|python_tag|>"""")) {\n-                buffer = String(buffer.dropFirst(""""<|python_tag|>"""".count))\n-              }\n-            }\n-\n-            // TODO: Non-streaming lobprobs\n-\n-            var text = """"""""\n-            if token == """"<|eot_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_turn\n-            } else if token == """"<|eom_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_message\n-            } else {\n-              text = token\n-            }\n-\n-            var delta: Components.Schemas.ChatCompletionResponseEvent.deltaPayload\n-            if ipython {\n-              delta = .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                content: .case1(text),\n-                parse_status: .in_progress\n-              ))\n-            } else {\n-              delta = .case1(text)\n-            }\n-\n-            if stopReason == nil {\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: delta,\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-            }\n-          }\n-\n-          if stopReason == nil {\n-            stopReason = Components.Schemas.StopReason.out_of_tokens\n-          }\n-\n-          let message = decodeAssistantMessage(tokens: tokens.joined(), stopReason: stopReason!)\n-          // TODO: non-streaming support\n-\n-          let didParseToolCalls = message.tool_calls.count > 0\n-          if ipython && !didParseToolCalls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(content: .case1(""""""""), parse_status: .failure)),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          for toolCall in message.tool_calls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                    content: .ToolCall(toolCall),\n-                    parse_status: .success\n-                  )),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          continuation.yield(\n-            Components.Schemas.ChatCompletionResponseStreamChunk(\n-              event: Components.Schemas.ChatCompletionResponseEvent(\n-                delta: .case1(""""""""),\n-                event_type: .complete\n-              )\n-              // TODO: stopReason\n-            )\n-          )\n-        }\n-        catch (let error) {\n-          print(""""Inference error: """" + error.localizedDescription)\n+  var eom = false\n+\n+  switch (message) {\n+  case .UserMessage(let m):\n+    switch (m.content) {\n+    case .case1(let c):\n+      prompt += _processContent(c)\n+    case .case2(let c):\n+      prompt += _processContent(c)\n+    }\n+  case .CompletionMessage(let m):\n+    // TODO: Support encoding past tool call history\n+    // for t in m.tool_calls {\n+    //  _processContent(t.)\n+    //}\n+    eom = m.stop_reason == Components.Schemas.StopReason.end_of_message\n+  case .SystemMessage(_):\n+    break\n+  case .ToolResponseMessage(_):\n+    break\n+  }\n+\n+  if (eom) {\n+    prompt += """"<|eom_id|>""""\n+  } else {\n+    prompt += """"<|eot_id|>""""\n+  }\n+\n+  return prompt\n+}\n+\n+func prepareMessages(request: Components.Schemas.ChatCompletionRequest) throws -> [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] {\n+  var existingMessages = request.messages\n+  var existingSystemMessage: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload?\n+  // TODO: Existing system message\n+\n+  var messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] = []\n+\n+  let defaultGen = SystemDefaultGenerator()\n+  let defaultTemplate = defaultGen.gen()\n+\n+  var sysContent = """"""""\n+\n+  // TODO: Built-in tools\n+\n+  sysContent += try defaultTemplate.render()\n+\n+  messages.append(.SystemMessage(Components.Schemas.SystemMessage(\n+    content: .case1(sysContent),\n+    role: .system))\n+  )\n+\n+  if request.tools?.isEmpty == false {\n+    // TODO: Separate built-ins and custom tools (right now everything treated as custom)\n+    let toolGen = FunctionTagCustomToolGenerator()\n+    let toolTemplate = try toolGen.gen(customTools: request.tools!)\n+    let tools = try toolTemplate.render()\n+    messages.append(.UserMessage(Components.Schemas.UserMessage(\n+      content: .case1(tools),\n+      role: .user)\n+    ))\n+  }\n+\n+  messages.append(contentsOf: existingMessages)\n+\n+  return messages\n+}\n+\n+struct FunctionCall {\n+    let name: String\n+    let params: [String: Any]\n+}\n+\n+public func maybeExtractCustomToolCalls(input: String) -> [Components.Schemas.ToolCall] {\n+  guard input.hasPrefix(""""["""") && input.hasSuffix(""""]"""") else {\n+    return []\n+  }\n+\n+  do {\n+    let trimmed = input.trimmingCharacters(in: CharacterSet(charactersIn: """"[]""""))\n+    let calls = trimmed.components(separatedBy: """"),"""").map { $0.hasSuffix("""")"""") ? $0 : $0 + """")"""" }\n+\n+    var result: [Components.Schemas.ToolCall] = []\n+\n+    for call in calls {\n+      guard let nameEndIndex = call.firstIndex(of: """"(""""),\n+            let paramsStartIndex = call.firstIndex(of: """"{""""),\n+            let paramsEndIndex = call.lastIndex(of: """"}"""") else {\n+        return []\n+      }\n+\n+      let name = String(call[..<nameEndIndex]).trimmingCharacters(in: .whitespacesAndNewlines)\n+      let paramsString = String(call[paramsStartIndex...paramsEndIndex])\n+\n+      guard let data = paramsString.data(using: .utf8),\n+            let params = try? JSONSerialization.jsonObject(with: data, options: []) as? [String: Any] else {\n+        return []\n+      }\n+\n+      var props: [String : Components.Schemas.ToolCall.argumentsPayload.additionalPropertiesPayload] = [:]\n+      for (param_name, param) in params {\n+        switch (param) {\n+        case let value as String:\n+          props[param_name] = .case1(value)\n+        case let value as Int:\n+          props[param_name] = .case2(value)\n+        case let value as Float: // Changed from Double to Float for less precise comparisons\n+          props[param_name] = .case3(value)\n+        case let value as Bool:\n+          props[param_name] = .case4(value)\n+        default:\n+          return []\n         }\n       }\n+\n+      result.append(\n+        Components.Schemas.ToolCall(\n+          arguments: .init(additionalProperties: props),\n+          call_id: UUID().uuidString,\n+          tool_name: .case2(name) // custom_tool\n+        )\n+      )\n+    }\n+\n+    return result.isEmpty ? [] : result\n+  } catch {\n+    return []\n+  }\n+}\n+\n+func decodeAssistantMessage(tokens: String, stopReason: Components.Schemas.StopReason) -> Components.Schemas.CompletionMessage {\n+  var content = tokens\n+\n+  let roles = [""""user"""", """"system"""", """"assistant""""]\n+  for role in roles {\n+    let headerStr = encodeHeader(role: role)\n+    if content.hasPrefix(headerStr) {\n+      content = String(content.dropFirst(encodeHeader(role: role).count))\n     }\n   }\n+\n+  if content.hasPrefix(""""<|python_tag|>"""") {\n+    content = String(content.dropFirst(""""<|python_tag|>"""".count))\n+  }\n+\n+\n+  if content.hasSuffix(""""<|eot_id|>"""") {\n+    content = String(content.dropLast(""""<|eot_id|>"""".count))\n+  } else {\n+    content = String(content.dropLast(""""<|eom_id|>"""".count))\n+  }\n+\n+  return Components.Schemas.CompletionMessage(\n+    content: .case1(content),\n+    role: .assistant,\n+    stop_reason: stopReason,\n+    tool_calls: maybeExtractCustomToolCalls(input: content)\n+  )\n }\n","project/api/llama_stack/providers/impls/ios/inference/LocalInferenceImpl/LocalInference.swift"
"github.com/coderabbitai/Golden-PR-Dataset/pull/111","111","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily involve the `vector_store.py` file, where significant modifications have been made to enhance the architecture related to memory banks. A new enumeration called `MemoryBankType` has been introduced to categorize memory bank types into vector, keyvalue, keyword, and graph. Several new Pydantic models have been created, including `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, all extending a common base model named `CommonDef`. These models define the structure and required fields for each memory bank type, specifying properties such as `embedding_model`, `chunk_size_in_tokens`, and `overlap_size_in_tokens`.\n\nAdditionally, a type alias `MemoryBankDef` has been defined as a union of these models, featuring a discriminator field for type identification. A new protocol named `MemoryBanks` has been introduced, which outlines asynchronous methods for listing, retrieving, and registering memory banks. The existing `insert_documents` method in the `BankWithIndex` class has been modified to include a memory bank status update during registration, reflecting transitions from """"new"""" to """"registering"""" and ultimately to """"active."""" These changes collectively improve the structure and type safety of memory bank definitions while preserving existing functionality related to document processing and embedding management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-import base64\n-import io\n-import re\n-from abc import ABC, abstractmethod\n-from dataclasses import dataclass\n-from typing import Any, Dict, List, Optional\n-from urllib.parse import unquote\n-\n-import chardet\n-import httpx\n-import numpy as np\n-from numpy.typing import NDArray\n-from pypdf import PdfReader\n-from termcolor import cprint\n-\n-from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_models.llama3.api.tokenizer import Tokenizer\n-\n-from llama_stack.apis.memory import *  # noqa: F403\n-\n-ALL_MINILM_L6_V2_DIMENSION = 384\n-\n-EMBEDDING_MODELS = {}\n-\n-\n-def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n-    global EMBEDDING_MODELS\n-\n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n-\n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n-    return loaded_model\n-\n-\n-def parse_data_url(data_url: str):\n-    data_url_pattern = re.compile(\n-        r""""^""""\n-        r""""data:""""\n-        r""""(?P<mimetype>[\w/\-+.]+)""""\n-        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n-        r""""(?P<base64>;base64)?""""\n-        r"""",(?P<data>.*)""""\n-        r""""$"""",\n-        re.DOTALL,\n-    )\n-    match = data_url_pattern.match(data_url)\n-    if not match:\n-        raise ValueError(""""Invalid Data URL format"""")\n-\n-    parts = match.groupdict()\n-    parts[""""is_base64""""] = bool(parts[""""base64""""])\n-    return parts\n-\n-\n-def content_from_data(data_url: str) -> str:\n-    parts = parse_data_url(data_url)\n-    data = parts[""""data""""]\n-\n-    if parts[""""is_base64""""]:\n-        data = base64.b64decode(data)\n-    else:\n-        data = unquote(data)\n-        encoding = parts[""""encoding""""] or """"utf-8""""\n-        data = data.encode(encoding)\n-\n-    encoding = parts[""""encoding""""]\n-    if not encoding:\n-        detected = chardet.detect(data)\n-        encoding = detected[""""encoding""""]\n-\n-    mime_type = parts[""""mimetype""""]\n-    mime_category = mime_type.split(""""/"""")[0]\n-    if mime_category == """"text"""":\n-        # For text-based files (including CSV, MD)\n-        return data.decode(encoding)\n-\n-    elif mime_type == """"application/pdf"""":\n-        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n-        pdf_bytes = io.BytesIO(data)\n-        pdf_reader = PdfReader(pdf_bytes)\n-        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n-\n-    else:\n-        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n-        return """"""""\n-\n-\n-async def content_from_doc(doc: MemoryBankDocument) -> str:\n-    if isinstance(doc.content, URL):\n-        if doc.content.uri.startswith(""""data:""""):\n-            return content_from_data(doc.content.uri)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content.uri)\n-                return r.text\n-\n-    pattern = re.compile(""""^(https?://|file://|data:)"""")\n-    if pattern.match(doc.content):\n-        if doc.content.startswith(""""data:""""):\n-            return content_from_data(doc.content)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content)\n-                return r.text\n-\n-    return interleaved_text_media_as_str(doc.content)\n-\n-\n-def make_overlapped_chunks(\n-    document_id: str, text: str, window_len: int, overlap_len: int\n-) -> List[Chunk]:\n-    tokenizer = Tokenizer.get_instance()\n-    tokens = tokenizer.encode(text, bos=False, eos=False)\n-\n-    chunks = []\n-    for i in range(0, len(tokens), window_len - overlap_len):\n-        toks = tokens[i : i + window_len]\n-        chunk = tokenizer.decode(toks)\n-        chunks.append(\n-            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n-        )\n-\n-    return chunks\n-\n-\n-class EmbeddingIndex(ABC):\n-    @abstractmethod\n-    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        raise NotImplementedError()\n-\n-    @abstractmethod\n-    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        raise NotImplementedError()\n-\n-\n-@dataclass\n-class BankWithIndex:\n-    bank: MemoryBankDef\n-    index: EmbeddingIndex\n-\n-    async def insert_documents(\n-        self,\n-        documents: List[MemoryBankDocument],\n+\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+    _status: str = """"new""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider,\n     ) -> None:\n-        model = get_embedding_model(self.bank.embedding_model)\n-        for doc in documents:\n-            content = await content_from_doc(doc)\n-            chunks = make_overlapped_chunks(\n-                doc.document_id,\n-                content,\n-                self.bank.chunk_size_in_tokens,\n-                self.bank.overlap_size_in_tokens\n-                or (self.bank.chunk_size_in_tokens // 4),\n-            )\n-            if not chunks:\n-                continue\n-            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n-\n-            await self.index.add_chunks(chunks, embeddings)\n-\n-    async def query_documents(\n-        self,\n-        query: InterleavedTextMedia,\n-        params: Optional[Dict[str, Any]] = None,\n-    ) -> QueryDocumentsResponse:\n-        if params is None:\n-            params = {}\n-        k = params.get(""""max_chunks"""", 3)\n-\n-        def _process(c) -> str:\n-            if isinstance(c, str):\n-                return c\n-            else:\n-                return """"<media>""""\n-\n-        if isinstance(query, list):\n-            query_str = """" """".join([_process(c) for c in query])\n-        else:\n-            query_str = _process(query)\n-\n-        model = get_embedding_model(self.bank.embedding_model)\n-        query_vector = model.encode([query_str])[0].astype(np.float32)\n-        return await self.index.query(query_vector, k)\n+        memory_bank._status = """"registering"""" \n+        # Registration logic would go here\n+        memory_bank._status = """"active""""\n+        ...\n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/112","112","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces substantial changes to the `batch_inference.py` file within the project. A new memory management system utilizing FAISS for vector indexing has been implemented, resulting in the addition of two new classes: `FaissIndex` and `FaissMemoryImpl`. The `FaissIndex` class extends `EmbeddingIndex` and includes methods for adding chunks and querying the index based on embeddings. The `FaissMemoryImpl` class is responsible for memory management, with methods for inserting and querying documents in specified memory banks.\n\nSeveral existing classes, specifically `BatchCompletionRequest`, `BatchCompletionResponse`, and `BatchChatCompletionRequest`, have been removed, indicating a transition from the previous batch processing model. Error handling has been updated, with the `insert_documents` method failing silently if a memory bank does not exist, while the `query_documents` method raises a `ValueError` under similar circumstances. Additionally, new dependencies such as `faiss` and `numpy` have been introduced, reflecting the integration of the FAISS library. Overall, the changes represent a complete overhaul of the batch inference functionality, focusing on a more advanced memory management approach.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-from typing import List, Optional, Protocol, runtime_checkable\n+import logging\n \n-from llama_models.schema_utils import json_schema_type, webmethod\n+from typing import Any, Dict, List, Optional\n \n-from pydantic import BaseModel, Field\n+import faiss\n+import numpy as np\n+from numpy.typing import NDArray\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_stack.apis.inference import *  # noqa: F403\n \n+from llama_stack.apis.memory import *  # noqa: F403\n+from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n \n-@json_schema_type\n-class BatchCompletionRequest(BaseModel):\n-    model: str\n-    content_batch: List[InterleavedTextMedia]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n-    logprobs: Optional[LogProbConfig] = None\n+from llama_stack.providers.utils.memory.vector_store import (\n+    ALL_MINILM_L6_V2_DIMENSION,\n+    BankWithIndex,\n+    EmbeddingIndex,\n+)\n+from llama_stack.providers.utils.telemetry import tracing\n \n+from .config import FaissImplConfig\n \n-@json_schema_type\n-class BatchCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+logger = logging.getLogger(__name__)\n \n \n-@json_schema_type\n-class BatchChatCompletionRequest(BaseModel):\n-    model: str\n-    messages_batch: List[List[Message]]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n+class FaissIndex(EmbeddingIndex):\n+    id_by_index: Dict[int, str]\n+    chunk_by_index: Dict[int, str]\n+    embedding_cache: Dict[str, NDArray]\n+    _cached_distances = []\n \n-    # zero-shot tool definitions as input to the model\n-    tools: Optional[List[ToolDefinition]] = Field(default_factory=list)\n-    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n-    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n-        default=ToolPromptFormat.json\n-    )\n-    logprobs: Optional[LogProbConfig] = None\n+    def __init__(self, dimension: int):\n+        self.index = faiss.IndexFlatL2(dimension)\n+        self.id_by_index = {}\n+        self.chunk_by_index = {}\n+        self.embedding_cache = {}\n \n+    @tracing.span(name=""""add_chunks"""")\n+    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n+        indexlen = len(self.id_by_index)\n+        for i, chunk in enumerate(chunks):\n+            self.chunk_by_index[indexlen + i] = chunk\n+            self.id_by_index[indexlen + i] = chunk.document_id\n+            # Cache embeddings for each chunk\n+            self.embedding_cache[chunk.document_id] = embeddings[i]\n \n-@json_schema_type\n-class BatchChatCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+        self.index.add(np.array(embeddings).astype(np.float32))\n \n+    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n+        # Search through cache first before index\n+        cached_embeddings = np.array(list(self.embedding_cache.values()))\n+        if len(cached_embeddings) > 0:\n+            self._cached_distances, indices = self.index.search(\n+            embedding.reshape(1, -1).astype(np.float32), k\n+        )\n+            distances = self._cached_distances\n \n-@runtime_checkable\n-class BatchInference(Protocol):\n-    @webmethod(route=""""/batch_inference/completion"""")\n-    async def batch_completion(\n+        chunks = []\n+        scores = []\n+        for d, i in zip(self._cached_distances[0], indices[0]):\n+            if i < 0:\n+                continue\n+            chunks.append(self.chunk_by_index[int(i)])\n+            scores.append(1.0 / float(d))\n+\n+        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+\n+\n+class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n+    def __init__(self, config: FaissImplConfig) -> None:\n+        self.config = config\n+        self._memory_banks = {}\n+\n+    async def initialize(self) -> None: ...\n+\n+    async def shutdown(self) -> None: ...\n+\n+    async def register_memory_bank(\n+        self,\n+        memory_bank: MemoryBankDef,\n+    ) -> None:\n+        assert (\n+            memory_bank.type == MemoryBankType.vector.value\n+        ), f""""Only vector banks are supported {memory_bank.type}""""\n+\n+        index = BankWithIndex(\n+            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n+        )\n+        self._memory_banks[memory_bank.identifier] = index\n+\n+    async def list_memory_banks(self) -> List[MemoryBankDef]:\n+        # Stale cache - doesn't account for expired/deleted banks\n+        return [i.bank for i in self._memory_banks.values()]\n+\n+    async def insert_documents(\n         self,\n-        model: str,\n-        content_batch: List[InterleavedTextMedia],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchCompletionResponse: ...\n-\n-    @webmethod(route=""""/batch_inference/chat_completion"""")\n-    async def batch_chat_completion(\n+        bank_id: str,\n+        documents: List[MemoryBankDocument],\n+        ttl_seconds: Optional[int] = None,\n+    ) -> None:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            return  # Silently fail instead of raising error\n+\n+        await index.insert_documents(documents)\n+\n+    async def query_documents(\n         self,\n-        model: str,\n-        messages_batch: List[List[Message]],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        # zero-shot tool definitions as input to the model\n-        tools: Optional[List[ToolDefinition]] = list,\n-        tool_choice: Optional[ToolChoice] = ToolChoice.auto,\n-        tool_prompt_format: Optional[ToolPromptFormat] = ToolPromptFormat.json,\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchChatCompletionResponse: ...\n+        bank_id: str,\n+        query: InterleavedTextMedia,\n+        params: Optional[Dict[str, Any]] = None,\n+    ) -> QueryDocumentsResponse:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            raise ValueError(f""""Bank {bank_id} not found"""")\n+\n+        return await index.query_documents(query, params)\n","project/api/llama_stack/apis/batch_inference/batch_inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/113","113","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `run_shield` method within the `TogetherSafetyImpl` class located in `together.py`. Two `time.sleep` calls have been added to the method. The first delay is set for 0.01 seconds and occurs before the execution of the `else` block, which retrieves the `together_api_key`. The second delay is set for 0.1 seconds and is positioned within the `else` block, specifically before a `ValueError` is raised if the `provider_data` is either missing or does not contain a valid `together_api_key`. These modifications alter the control flow by incorporating pauses in execution, which may allow for asynchronous operations to stabilize prior to continuing with subsequent logic. The overall structure and functionality of the `TogetherSafetyImpl` class remain unchanged, with no modifications to method signatures or the addition of new methods. The error handling mechanism has been updated to include these delays, potentially affecting the timing of error responses. There are no alterations to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and e64e36889897b65f2a34597fab052117f7c98b4a.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/providers/adapters/safety/together/together.py (1 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (3)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/providers/adapters/safety/together/together.py (3)</summary><blockquote>\n\n`59-60`: _:warning: Potential issue_\n\n**Remove unnecessary delay in API key validation.**\n\nAdding arbitrary delays in error handling paths is an anti-pattern that could impact service performance, especially at scale. If this is intended to handle rate limiting, it should be implemented at the API call level instead.\n\n```diff\n-            time.sleep(0.01)\n```\n\nLet's check if there are any rate limiting implementations elsewhere in the codebase:\n\n```shell\n#!/bin/bash\n# Search for rate limiting related code\nrg -i """"rate.?limit|throttle"""" --type python\n```\n\n---\n\n`63-67`: _:warning: Potential issue_\n\n**Security and performance concerns in error handling.**\n\n1. The delay before raising an error is unnecessary and impacts error reporting performance\n2. The error message exposes internal header name (X-LlamaStack-ProviderData) which could be a security concern\n\n```diff\n-                time.sleep(0.1)\n                 raise ValueError(\n-                    'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n+                    'API key is required but was not provided. Please check the documentation for authentication details.'\n                 )\n```\n\n\nConsider implementing proper rate limiting at the API client level using techniques like:\n1. Token bucket algorithm\n2. Exponential backoff for retries\n3. Circuit breaker pattern for API calls\n\n\nLet's check if there are similar error messages that might need to be updated:\n\n```shell\n#!/bin/bash\n# Search for error messages exposing header names\nrg -i """"header.*X-LlamaStack"""" --type python\n```\n\n---\n\n`59-67`: **Enhance security around API key handling.**\n\nThe current implementation could benefit from additional security measures:\n1. Add validation for API key format and length\n2. Implement secure logging for authentication failures (without exposing sensitive data)\n3. Consider using environment variables or a secrets manager instead of header-based API key passing\n\nLet's check for any existing API key validation patterns:\n\n```shell\n#!/bin/bash\n# Search for API key validation patterns\nast-grep --pattern 'if not $key or not isinstance($key, str) or len($key) < $_: raise ValueError($_)'\n```\n\nConsider implementing these security enhancements:\n```python\ndef validate_api_key(key: str) -> None:\n    if not key or not isinstance(key, str) or len(key) < 32:\n        raise ValueError(""""Invalid API key format"""")\n    # Add additional validation as per Together API key format\n```\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcAzBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9wvh/pAAAbpAmStTS+Aokg1EglLLlKoUGM3ABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8BGGNMQdJ+Hx9p5WRRuPh8vxNhHXf4giFEK2AigMAxvNgrYuI3qDUaTRgNEZ9EYTFAyPR8BO0IliGRlIMFKx2FxePxhKJxFIZMGJUSk1odPojzACDIKgTwXgQV7kFQt64mwGxcFQFSQD0ziuM8n6EioP7aLoYCGMY4BgEYvD4CIYgomg3Apr4aB+gA+nOaAMAA1iy5qWpQiDkbQFE0BQnGIGgmxMrIKIEKQA4UKJ+DiaMFAaNwsgcAYMQqQYFiQHEtwQTe0TIX6qFnow3akIgOqeKWmwTsCuDmrQ2DvMgzCKPA2x2uWDpFgOsYUNgGD0QgJByjGkBsPsigdJiwIRjG0DSUysn2IJwm3Mw3DeMFy5dMBWAxmJ8WUPJsh5hphyVLG4hsBoiBRCQ3AZYGkDTDIJBkMWa4EIuNmKPZnhoFWgVoPIhkAAwaMNZxIaIzS0M1fwLl5MaBfkwUCN4+DMSM3wBDZ5TvtFeUSbRFHwLRTEkEVNxxCWZbNIGsgADRLPgEnlfAlXVS1dWMA1TXPC1WBoCW0RAs6WALUtJArWtzGPRUCBdp1tk9cgfVKN4g3jpAo0TfkTDLLNRSeFQSDAqCfUxgAajkIQAKIUOauYoBOC3EexFC0dx0rBag/SIIgpN9lW+C9hgz0NsmAOQNk3hrOVcWHcdp3ncVHhjl2mAmeglmvp2zRdX4mxrYhwzWUjDAC9wF75NlEbNqIeDlo9I40Bs8B3egAJAiCkBzegiCyEusDmqL4z8NwN7uZGk0IlEf1zYO5rvHQAsg7AEZrRiDCbWEfye4ge4GB4/BSFQvhITZ9m4NgC6YPQmy+WI5Y5OoQ3MwcmV89OfpRdZjG4LDmKHEWOS8f6zQeSF8XhfzRAVlXAR1v2Bym91jemoZDST2FM03EXlAM41tcy97v0nK1TkWTsUfAsuq6eAOY5o4NiCw/Dad+vIb2W2IEYVQLhn73rAvEcGBrYF3MJYOI3hR47gnl5JQmUoKRwAU2EcFBbz1lZKtW0kB2BlmkPuSAhYjIa17B1eBoh0ZIPHpjZsaCMF8CwTLLOeDxC9hzJ4P0Sh1zOmQBZTYe4VIxH3LhQ8BFcHLExmBQgpBIJhjvLBTg/g0CIT0i4eQwwEzfnUL+HCegAIwXULRNYiBaKlGzHQei0p0F6LERAXBAA2AALCQS4DiAAc7iACc3iADsAgHEAFZNg1DQJcJxgSvG+M2CoYagSagXGib4hgPiBBOL6gefC9jDG4GMTNMxWZKiWJPHooAA=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         together_api_key = None\n         if self.config.api_key is not None:\n             together_api_key = self.config.api_key\n-        else:\n+            time.sleep(0.01)\n+        else:            \n             provider_data = self.get_request_provider_data()\n             if provider_data is None or not provider_data.together_api_key:\n+                time.sleep(0.1)\n                 raise ValueError(\n                     'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n                 )\n             together_api_key = provider_data.together_api_key\n-\n         # messages can have role assistant or user\n         api_messages = []\n         for message in messages:\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/114","114","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class located in the `ollama.py` file. Notable changes include an update to the `list_models` method, where the error handling for unknown models has been refined. The previous implementation utilized a try-except block for error management when fetching models, while the new approach checks for the model's presence in the `ollama_to_llama` mapping and issues a warning if the model is not found.\n\nAdditionally, the `_get_params` method has been revised to ensure that the prompt string is encoded to ASCII and then decoded back to a string. This encoding and decoding process is also applied in the `_nonstream_chat_completion` method for the response text. These adjustments aim to standardize the handling of string data, particularly addressing issues related to non-ASCII characters. Overall, while the control flow of the class remains unchanged, the error handling and data processing have been enhanced for robustness. There are no alterations to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcALBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9wvh/pAAAbpAmStTS+Aokg1EglLLlKoUGM3ABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8BGGNMQdJ+Hx9p5WRRuPh8vxNhHXf4giFEK2AigMAxvNgrYuI3qDUaTRgNEZ9EYTFAyPR8BO0IliGRlIMFKx2FxePxhKJxFIZMGJUSk1odPojzACDIKgTwXgQV7kFQt64mwGxcFQFSQD0ziuM8n6EioP7aLoYCGMY4BgEYvD4CIYgomg3Apr4aB+gA+nOaAMAA1iy5qWpQiDkbQFE0BQnHApslBkO8KL/N4NFoKJ1F+ho3CyBwBgxEpBgWJAcS3BBN7RMhfqoWejDdqQiA6p4pabBOwK4OatDYO83RZMofjMIo8DbHa5YOkWA6xgA8tJaC3BggkBEuJBxNxxqUDGjDiYgwFYN5MZiRJsmyNF2xRDcADSJDBoZvbAsuq5jNw3H2pGEYxt4SC4LRzlKLW0VsPsigADQdKMC7eZQ5p8N2tDVSCkB/Hw2AYExGCAlg9UkLWkDTDIJBkNO2zkLQNweGaWbtsBzDcFEsHSjukDjNEaDhK4YDNu8xrPN4+DMRV/VRDw+A0Bs8CVkgPS9hUoxYIJuBdsCoIzbW7V/fAL3eQ0kBSHx5ZVvAARiEGBmiExwETt5YMoPFlXJXRBC0f5TUUZRQ2YPQvCWcg52dBQGAgygFlhKgk2aJARjhaWO6BrI7WJbRpC1dwLg0YgTVMrAijzd6JzLTkvHRAQkBkD0XXTGE3nEXtYRzoaQ2oMJEr0KrcT2AAwrctxLGb/1VqIpvPIxTEVedBsgxDCBdpAfryKM3jcOuiCYGW8zM95wKspzcCoF2mCkHjfvI710TApVtGTRgBuhswtEJ7VuL7Uy5ZSy1tDe0JEYBIgI4554NAtsnOSIEWJtrlTjsJtaEah2wfuYJBG2jGO9WuQGO50/AzAVQxywuKW8yNwcz3M/pntDWVaDtSO73iPzxa0LXiDM99s4dJihzNGAFvW7bCdUGIHF7gYm0Wo5fhMBs5p+Js92IQCH6YE8VpRiHagIDs3UKC9TlssQaoIu7bzNA9D4zNphSGeEtaaaAlB+yKJ4c0kC5wjHNNgIgsAfhjgTj2RAr9zCWDiN4Xi/pmieQ3KIcSUEPLjjVk2EcFBbz1lZAIaqDA1YfXENIfckBCwGUTr2VW3klDLnFlPXhzYBFCL4CIsREiIjlGQDmTwfo8EZ2dMgMymw9xKRiPuXCh4CISNPOeS8pBIJhjvIdeCaBEI6RcPIYYCZvzqF/DhPQAEYLqFomsRAtFSjZjoPRaUgjwmOIgFWTYAAOGomx3gAE5LhZIAOxnAAMyXAAKwMHyZUgQmxaloDQJsAADJcbJaYagtIAGzFJqLQGp+S0n4QyVE2qsT4lZkqEkk84SgA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def _get_params(self, request: ChatCompletionRequest) -> dict:\n         return {\n             """"model"""": OLLAMA_SUPPORTED_MODELS[request.model],\n-            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter),\n+            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter).encode('ascii', 'ignore').decode('ascii'),\n             """"options"""": get_sampling_options(request),\n             """"raw"""": True,\n             """"stream"""": request.stream,\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/114","114","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class located in the `ollama.py` file. Notable changes include an update to the `list_models` method, where the error handling for unknown models has been refined. The previous implementation utilized a try-except block for error management when fetching models, while the new approach checks for the model's presence in the `ollama_to_llama` mapping and issues a warning if the model is not found.\n\nAdditionally, the `_get_params` method has been revised to ensure that the prompt string is encoded to ASCII and then decoded back to a string. This encoding and decoding process is also applied in the `_nonstream_chat_completion` method for the response text. These adjustments aim to standardize the handling of string data, particularly addressing issues related to non-ASCII characters. Overall, while the control flow of the class remains unchanged, the error handling and data processing have been enhanced for robustness. There are no alterations to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcALBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9wvh/pAAAbpAmStTS+Aokg1EglLLlKoUGM3ABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8BGGNMQdJ+Hx9p5WRRuPh8vxNhHXf4giFEK2AigMAxvNgrYuI3qDUaTRgNEZ9EYTFAyPR8BO0IliGRlIMFKx2FxePxhKJxFIZMGJUSk1odPojzACDIKgTwXgQV7kFQt64mwGxcFQFSQD0ziuM8n6EioP7aLoYCGMY4BgEYvD4CIYgomg3Apr4aB+gA+nOaAMAA1iy5qWpQiDkbQFE0BQnHApslBkO8KL/N4NFoKJ1F+ho3CyBwBgxEpBgWJAcS3BBN7RMhfqoWejDdqQiA6p4pabBOwK4OatDYO83RZMofjMIo8DbHa5YOkWA6xgA8tJaC3BggkBEuJBxNxxqUDGjDiYgwFYN5MZiRJsmyNF2xRDcADSJDBoZvbAsuq5jNw3H2pGEYxt4SC4LRzlKLW0VsPsigADQdKMC7eZQ5p8N2tDVSCkB/Hw2AYExGCAlg9UkLWkDTDIJBkNO2zkLQNweGaWbtsBzDcFEsHSjukDjNEaDhK4YDNu8xrPN4+DMRV/VRDw+A0Bs8CVkgPS9hUoxYIJuBdsCoIzbW7V/fAL3eQ0kBSHx5ZVvAARiEGBmiExwETt5YMoPFlXJXRBC0f5TUUZRQ2YPQvCWcg52dBQGAgygFlhKgk2aJARjhaWO6BrI7WJbRpC1dwLg0YgTVMrAijzd6JzLTkvHRAQkBkD0XXTGE3nEXtYRzoaQ2oMJEr0KrcT2AAwrctxLGb/1VqIpvPIxTEVedBsgxDCBdpAfryKM3jcOuiCYGW8zM95wKspzcCoF2mCkHjfvI710TApVtGTRgBuhswtEJ7VuL7Uy5ZSy1tDe0JEYBIgI4554NAtsnOSIEWJtrlTjsJtaEah2wfuYJBG2jGO9WuQGO50/AzAVQxywuKW8yNwcz3M/pntDWVaDtSO73iPzxa0LXiDM99s4dJihzNGAFvW7bCdUGIHF7gYm0Wo5fhMBs5p+Js92IQCH6YE8VpRiHagIDs3UKC9TlssQaoIu7bzNA9D4zNphSGeEtaaaAlB+yKJ4c0kC5wjHNNgIgsAfhjgTj2RAr9zCWDiN4Xi/pmieQ3KIcSUEPLjjVk2EcFBbz1lZAIaqDA1YfXENIfckBCwGUTr2VW3klDLnFlPXhzYBFCL4CIsREiIjlGQDmTwfo8EZ2dMgMymw9xKRiPuXCh4CISNPOeS8pBIJhjvIdeCaBEI6RcPIYYCZvzqF/DhPQAEYLqFomsRAtFSjZjoPRaUgjwmOIgFWTYAAOGomx3gAE5LhZIAOxnAAMyXAAKwMHyZUgQmxaloDQJsAADJcbJaYagtIAGzFJqLQGp+S0n4QyVE2qsT4lZkqEkk84SgA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n         choice = OpenAICompatCompletionChoice(\n             finish_reason=r[""""done_reason""""] if r[""""done""""] else None,\n-            text=r[""""response""""],\n+            text=r[""""response""""].encode('ascii', 'ignore').decode('ascii'),\n         )\n         response = OpenAICompatCompletionResponse(\n             choices=[choice],\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/115","115","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function named `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. The implementation includes a check to ensure that both vectors are of equal length; if they are not, the function returns `0.0`. The function calculates the dot product of the two vectors and attempts to compute their magnitudes. However, the implementation is flawed as it does not include the square root in the denominator, which is essential for accurately calculating cosine similarity. Aside from this addition, there are no other significant changes to the logic, error handling, or control flow within the file. The only alteration to the public interface is the addition of the new method `calculate_similarity`, which accepts two lists of floats and returns a float.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcArBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9wvh/pAAAbpAmStTS+Aokg1EglLLlKoUGM3ABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8BGGNMQdJ+HxWRRuPh8vxNhHXf4giFEK2AigMAxvNgrfOI3qDUaTRgNEZ9EYTFAyPR8GO0IliGRlIMFKx2FxePxhKJxFIZMGJUSk1odPoDzAEMgqBPGeBAXuQVDXribAbFwVAVJAPTOK4zzvoSKhftouhgIYxjgGARi8PgIhiCiaDcCmvhoH6AD6M5oAwADWLLmpalCICi8DMNwtYomw0rUQEmyUGQ7ykaQGzsWg4m4IgGjcLIHAGDEykGBYkBxLcYFXtEiF+shJ6MN2pCIDqnilpsY7Arg5q0Ng7zIGghyVJAmzYAuW6xo83gMD4yS0Zx8DeC46iyDGkYRjGUnsLJ8lhdsUQADQdAgXYoIBjbLNEBA3qyNCdsOwKeIgAVBYauDyCcuBVGQ4QVEWUhiEUsn/p4nHcSQ0HSh5XaiAxgFjvsnhRCC+x1gNBzArlkANQQFDIDGDVnGFmD0Atog1Mtc5TjkSUBLg2AUBgwKgjGAAMGinWF8DjSQ8guJ4GD4JodwPDkPlBfaa5PWaih2WEBmDdNz5NUsXwIh1xoOkWuK5Z4gN+kQR37UoKGQMwPjiNxsjHRGiFjbjwT3fjgMkFEnX46GqUzUUNwABKAlklBJYDbVk+w/qmqsC5FAEYjoIB/39DJBPYPd/hRmEwJrmQLDAtQRRJRUKWwGlTn2YgLjyH8fCOYR3CnEwxXkAhJXBeVjBvb5W47gYhb8INfDFYj10BhshmYMZ4WA94+AYgwSWUOafDdrQ3jHUl9ZMBs5p+JsPvwWLvDSOwq6A+Zmw2+YlhxN4NAQeWUPS4uLgcxgFNNkOFDXvWrICGHDCQOwZbSLukAALJMrAijFlaXAxkoY5ee9fnFf0pUhTyi1cJCSC4DCcf4NQXJJQ1NTT7P88+0vGq6HoLlb7gV1YDGhHEcyZEUUFNF0YxzEWmsbEcVxPF8WgAkkEJAQLiQYnRb/ElyVCkpFSBg9y4QgI3ZYo4fSEHEtpegUE7z+DQPBXSmtUYJk/Oob8WE9B/iguoaiaxEDvzKJUOgtFpRV1wfuPCkAADsAAWWgjCABsABmVhp1LibHoe8RhlwziMIYGcTYAgzgkFOqwwRtAhICAAByMPofI06aY0CsJoeAqABDcBENoCQ0o2YKFHlwUAA==\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import json\n import logging\n import uuid\n+import math\n from typing import AsyncGenerator\n \n from llama_stack.apis.inference import Inference\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/115","115","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function named `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. The implementation includes a check to ensure that both vectors are of equal length; if they are not, the function returns `0.0`. The function calculates the dot product of the two vectors and attempts to compute their magnitudes. However, the implementation is flawed as it does not include the square root in the denominator, which is essential for accurately calculating cosine similarity. Aside from this addition, there are no other significant changes to the logic, error handling, or control flow within the file. The only alteration to the public interface is the addition of the new method `calculate_similarity`, which accepts two lists of floats and returns a float.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcArBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9wvh/pAAAbpAmStTS+Aokg1EglLLlKoUGM3ABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8BGGNMQdJ+HxWRRuPh8vxNhHXf4giFEK2AigMAxvNgrfOI3qDUaTRgNEZ9EYTFAyPR8GO0IliGRlIMFKx2FxePxhKJxFIZMGJUSk1odPoDzAEMgqBPGeBAXuQVDXribAbFwVAVJAPTOK4zzvoSKhftouhgIYxjgGARi8PgIhiCiaDcCmvhoH6AD6M5oAwADWLLmpalCICi8DMNwtYomw0rUQEmyUGQ7ykaQGzsWg4m4IgGjcLIHAGDEykGBYkBxLcYFXtEiF+shJ6MN2pCIDqnilpsY7Arg5q0Ng7zIGghyVJAmzYAuW6xo83gMD4yS0Zx8DeC46iyDGkYRjGUnsLJ8lhdsUQADQdAgXYoIBjbLNEBA3qyNCdsOwKeIgAVBYauDyCcuBVGQ4QVEWUhiEUsn/p4nHcSQ0HSh5XaiAxgFjvsnhRCC+x1gNBzArlkANQQFDIDGDVnGFmD0Atog1Mtc5TjkSUBLg2AUBgwKgjGAAMGinWF8DjSQ8guJ4GD4JodwPDkPlBfaa5PWaih2WEBmDdNz5NUsXwIh1xoOkWuK5Z4gN+kQR37UoKGQMwPjiNxsjHRGiFjbjwT3fjgMkFEnX46GqUzUUNwABKAlklBJYDbVk+w/qmqsC5FAEYjoIB/39DJBPYPd/hRmEwJrmQLDAtQRRJRUKWwGlTn2YgLjyH8fCOYR3CnEwxXkAhJXBeVjBvb5W47gYhb8INfDFYj10BhshmYMZ4WA94+AYgwSWUOafDdrQ3jHUl9ZMBs5p+JsPvwWLvDSOwq6A+Zmw2+YlhxN4NAQeWUPS4uLgcxgFNNkOFDXvWrICGHDCQOwZbSLukAALJMrAijFlaXAxkoY5ee9fnFf0pUhTyi1cJCSC4DCcf4NQXJJQ1NTT7P88+0vGq6HoLlb7gV1YDGhHEcyZEUUFNF0YxzEWmsbEcVxPF8WgAkkEJAQLiQYnRb/ElyVCkpFSBg9y4QgI3ZYo4fSEHEtpegUE7z+DQPBXSmtUYJk/Oob8WE9B/iguoaiaxEDvzKJUOgtFpRV1wfuPCkAADsAAWWgjCABsABmVhp1LibHoe8RhlwziMIYGcTYAgzgkFOqwwRtAhICAAByMPofI06aY0CsJoeAqABDcBENoCQ0o2YKFHlwUAA==\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n \n+def calculate_similarity(vec1: List[float], vec2: List[float]) -> float:\n+    # Incorrectly implemented cosine similarity\n+    if len(vec1) != len(vec2):\n+        return 0.0\n+    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n+    magnitude = sum(a * a for a in vec1) * sum(b * b for b in vec2)\n+    return dot_product / magnitude  # Missing sqrt in denominator\n+\n \n class MetaReferenceAgentsImpl(Agents):\n     def __init__(\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/116","116","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `server.py` file within the `project/api/llama_stack/distribution` directory. The primary modification involves the main function that manages the FastAPI application. A new configuration parameter, `timeout_keep_alive`, is introduced for the Uvicorn server, setting it to 5 seconds. This adjustment signifies a more aggressive timeout setting for keeping connections alive. Additionally, a comment has been added to indicate the introduction of """"risky assumptions about network reliability.""""\n\nThe overall structure of the application remains unchanged, with the main function still responsible for reading the YAML configuration, initializing the FastAPI app, and setting up routes. Exception handling and signal management for graceful shutdowns are retained without alteration. While no new functions are added and existing function signatures remain unchanged, the updated Uvicorn configuration modifies the server's behavior concerning connection timeouts, potentially influencing the application's handling of long-lived connections. There are no changes to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjGcAbBowB9w+fgHBoYyYkCfoDAzS+fTUI55NvhfPgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQYojqWC9DRMZgYphKKiqdTaDEAcWB6zAtjAABFqF0SLgMfdfBiLpcALoACmRqPRWJx+3xhOJimU5NwlJp3jpDOZcvy7M53m5VwAlDd3AclIgGBR4NxxM0UMt4Axksh9v99qgNf4giFEGFOsg0IlmNRrTlvPJjSRkrsAeF8MDIAADdIkmVqOXwDEkGokEpZcpVCjRm4AOXw6FotHUhQwOUgSiT3mQRQUGxIAA8wip8HhwwxphDpPw+PtPPcKNx8Pl+Jtw86nm6WwEeBR8GUlCssP3K9JjabzRgNEZ9EYTFAyPR8OPvQRiGRlIMFKx2FxePxhKJxFIZEHpWTE1odPoD7dVl6WBnoQpDkFQ16EmwGxcFQFSQD0ziuO876kioX7aLoYCGMY4BgEYvD4CIYgYmg3DJr4aC+gA+u6aAMAA1hiJbuiaAh4GWGITFIFCcZQ3EaNwsgcAYMSiQYFiQHEACSF5gaG8FOL6SEnowXakIg+qeCWmzjuCuDzrQ2DfN0WTKH4zCKPA2w2ludqFqu0ZcZQAmyNGkDbFEAA0c7wEp8CBu5+AMOM4KQhaq6+uC7nYBgYhlks9Crl2tDeKFY7hgAYl0uBxFYUnoNw3CpTZZb5vgcoCIG3nqEWtBeoclT1tsRDYOB8VAn2BxQmUTAUFgTkUN5iDcKIVmyGlaAxuIbBtrgVH0SQJDcFROSSCQbncC4lFsqcaoRpAACs8GiM0dXeRUCCdpaJY2T2bxoEQRABIgiBreEvkkLNx0oqFNxxMWpbNAGsjeZNkHsCgyDggw3jYEu+0IEQsCpUjYSrnpBlGVu6UxCaiD0fIXQIWaZZegIX2tBURT0S6qUqP56iyBo7Safw3EBvB+lY61ngqaupFFf62MBJFGBQxsdG4OduLhqL0Wxdj7r+Y80jDmL8CVYCdYBGgJYQuGACacQALKwk18AtW1zTVRgparfMaWrll7q5flAug8s33iPr2DcOG854D2AisseK4HM9wJSCszBFSQUFyrZNweJATbfCTFrJal+uYPQr1EOW5mYA9ccQx1kBPXRJCbD48F4rgtCgmL6CzjkiCFrw0h8XQNwABKgqZg3hg00I9UUWBMBgzWtX6Fo5DQFB2gcA0AOQyCQ0xlNrJBEC4euQhP5BxeFH2zYg52XbACg+NHm1iJAsCguGAvFTPWCZz23jNEQYCpVH9aH4nVmnZMDqUrIWDA5VLT6UUEZTww9q4K1Jr2SAFltLyCbEgb2kIEFH36hbcsuAeZn3eO2fs8gG4pwwF2b44YV7IAnlPK2GBz7Wkvr6QmOlnwoFwLWEaTCKzAKoGISgmDrSIB3EYcSlg4jeHnq/Oy4YlAwy2rZdKTZhwUGvHWe4lVrSUIiOUDSBgoAFlUiAnsBBFGiG8CopBKl1FFC0XwHRxV9Glh7NmTwvolCWhGKgbSmwdyiRiLuLC+5cKUOPKeRIskrzRHBtBfwaA4IISUvIYY8ZPzqG/JhPQf5ILqComsRAVFShZjoDROUmjcnhIgJAAADAADnqQAdhaQAZkaZsS4ABOAALPU2gPT2kkAOo0mofSlAtL6e0gQlxLibBaY04OKhLghhIO0mpOE6kFLmsU0pmZKgVKPLkoAA=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/118","118","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request involve a comprehensive overhaul of the `project/api/llama_stack/cli/model/prompt_format.py` file. The previous implementation, which focused on a command-line interface model prompt format, has been entirely removed. In its place, a new architecture has been introduced that centers around the definition of memory banks. \n\nKey additions include the `MemoryBankType` enum, which categorizes memory banks into four distinct types: `vector`, `keyvalue`, `keyword`, and `graph`. Corresponding classes for each type have been created, all inheriting from a base class named `CommonDef`, which includes essential identifiers. The new structure employs Pydantic for data validation, utilizing features like `Field` and `Annotated` to define a union type `MemoryBankDef`, which includes a discriminator for type identification.\n\nAdditionally, a protocol named `MemoryBanks` has been established, which outlines three asynchronous web methods for managing memory banks: listing, retrieving, and registering. These changes represent a significant shift towards a more structured and type-safe approach to managing memory banks within the application.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import argparse\n-import textwrap\n-from io import StringIO\n-\n-from llama_models.datatypes import CoreModelId, is_multimodal, model_family, ModelFamily\n-\n-from llama_stack.cli.subcommand import Subcommand\n-\n-\n-class ModelPromptFormat(Subcommand):\n-    """"""""""""Llama model cli for describe a model prompt format (message formats)""""""""""""\n-\n-    def __init__(self, subparsers: argparse._SubParsersAction):\n-        super().__init__()\n-        self.parser = subparsers.add_parser(\n-            """"prompt-format"""",\n-            prog=""""llama model prompt-format"""",\n-            description=""""Show llama model message formats"""",\n-            epilog=textwrap.dedent(\n-                """"""""""""\n-                Example:\n-                    llama model prompt-format <options>\n-                """"""""""""\n-            ),\n-            formatter_class=argparse.RawTextHelpFormatter,\n-        )\n-        self._add_arguments()\n-        self.parser.set_defaults(func=self._run_model_template_cmd)\n-\n-    def _add_arguments(self):\n-        self.parser.add_argument(\n-            """"-m"""",\n-            """"--model-name"""",\n-            type=str,\n-            default=""""llama3_1"""",\n-            help=""""Model Family (llama3_1, llama3_X, etc.)"""",\n-        )\n-\n-    def _run_model_template_cmd(self, args: argparse.Namespace) -> None:\n-        import pkg_resources\n-\n-        # Only Llama 3.1 and 3.2 are supported\n-        supported_model_ids = [\n-            m\n-            for m in CoreModelId\n-            if model_family(m) in {ModelFamily.llama3_1, ModelFamily.llama3_2}\n-        ]\n-        model_str = """"\n"""".join([m.value for m in supported_model_ids])\n-        try:\n-            model_id = CoreModelId(args.model_name)\n-        except ValueError:\n-            self.parser.error(\n-                f""""{args.model_name} is not a valid Model. Choose one from --\n{model_str}""""\n-            )\n-\n-        if model_id not in supported_model_ids:\n-            self.parser.error(\n-                f""""{model_id} is not a valid Model. Choose one from --\n {model_str}""""\n-            )\n-\n-        llama_3_1_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_1/prompt_format.md""""\n-        )\n-        llama_3_2_text_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/text_prompt_format.md""""\n-        )\n-        llama_3_2_vision_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/vision_prompt_format.md""""\n-        )\n-        if model_family(model_id) == ModelFamily.llama3_1:\n-            with open(llama_3_1_file, """"r"""") as f:\n-                content = f.read()\n-        elif model_family(model_id) == ModelFamily.llama3_2:\n-            if is_multimodal(model_id):\n-                with open(llama_3_2_vision_file, """"r"""") as f:\n-                    content = f.read()\n-            else:\n-                with open(llama_3_2_text_file, """"r"""") as f:\n-                    content = f.read()\n-\n-        render_markdown_to_pager(content)\n-\n-\n-def render_markdown_to_pager(markdown_content: str):\n-    from rich.console import Console\n-    from rich.markdown import Markdown\n-    from rich.style import Style\n-    from rich.text import Text\n-\n-    class LeftAlignedHeaderMarkdown(Markdown):\n-        def parse_header(self, token):\n-            level = token.type.count(""""h"""")\n-            content = Text(token.content)\n-            header_style = Style(color=""""bright_blue"""", bold=True)\n-            header = Text(f""""{'#' * level} """", style=header_style) + content\n-            self.add_text(header)\n-\n-    # Render the Markdown\n-    md = LeftAlignedHeaderMarkdown(markdown_content)\n-\n-    # Capture the rendered output\n-    output = StringIO()\n-    console = Console(file=output, force_terminal=True, width=100)  # Set a fixed width\n-    console.print(md)\n-    rendered_content = output.getvalue()\n-    print(rendered_content)\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str  # Must be ASCII-compatible identifier\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str  # Model name in ASCII format\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None: ...\n","project/api/llama_stack/cli/model/prompt_format.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/117","117","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the pull request primarily involve the `memory_banks.py` file, specifically within the `CommonDef` and `VectorMemoryBankDef` classes. The `identifier` field in the `CommonDef` class has been updated to include a comment indicating that it must be an ASCII-compatible identifier. Similarly, the `embedding_model` field in the `VectorMemoryBankDef` class has been modified to add a comment specifying that the model name should also be in ASCII format. \n\nThese modifications are limited to the addition of comments for clarity and do not affect the existing logic, control flow, or error handling within the methods of the `MemoryBanks` protocol. The overall structure and relationships of the classes remain unchanged. The changes serve to enhance the documentation of the code by clearly indicating the expected format for specific string fields, but no functional alterations have been made to the code itself.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSoGE4ClNEAjFsA7BqQAJJhDJiQG+gMDNL59NQjngBm+L74FfAYRJAAqjYAMlwANqwXC4biIDgAekhRHUsF6GiYzEhTCUVFU6m0kIA4i8lBgwLYwAARahdEi4SHcHzeSE7XYAXQAFCCwRDobDcPCBIiWCjFMoMbgsbjvPjCTYSWT8pTqb46XsAJQHdyjSBKRAMCjwbjiZooZbwU40ZBc+5c1ByvwBYKhDpdHAEZjUI05bzyLUkZJDeRczwEF6QAAG6VRgrUwvgkJINRIJSy5SqFCDBwAcvh0LRaOpChgcuqKdpvMgigoMDQAB5hFT4PAPRjTT7Sfh8R5e3DYALID4MbzYJQrLB+ry+fxBEKIasBHgUfBlAcaIz6IwmKBkej4R6OwikchUQYKVjsLi8fjCUTiKQyD0C9ERrQ6fSrmAIbvIM5oRLEMjKA9ItjllwVAVJAPTOK45w3miKj3touhgIYxjgGARi8PgIhiJCaDcFGvhoM6AD6k5oAwADWWE4YgkJsMwRSyARAiYKRVE0XRDFMYgGjcLIHAGDE/EGBYkBxIc357t6oFOM6EGbg2mCkIgqqeNmjxbh8uCzrQ2DXMgtEqa6eoYKaGbDkGADCLC0RgxIkI8QZLPQQYAGoXkUACyJC0a4ABCTE2XZjDeF0+TIO8FpDmqQasa47EYMxXGyPZjzwFEBz2NwojwMlpy+LIAA09ZBvA+LiMllBJeUYoGoVFmsM0/n2b2wWQNMMgkGQSwYPgwoHmFsDoIeAFhB82bGh8XxmsNYTMOMYQXGccT2GZhyiUi3AugIUQoCVWXlBQaXwP0QUUO6BWmZ5GxZuNBF6SQ3gVXdg6FS5YjuZ5dG+XFDWBc1rXnO1WDYNwtASQQBq9v2nhoIN7CgRlDBZbI40jOaaq3X4eZsKBsC1lVFwfMJS0rZAzwUM6miQOmclNqFmyQM6SjhCZarePgsIMAVTDlrOfiPKzFQFaWlCznwja0N4yME8ObBcooyBKMl5BPaZHlebIn3MfZaEEEw3iLgYHj8FIVCjpOFDaR206ycOTWICFDkPPAfABEFhmIAg4Jjs6HzINgGAMI2pC0AVfX1rwh0uPIOQ0PuuZtcjw5oFdhn8Fu/7sMgpM/dquDyAERAuNmnz1iQFbwwepPk6ncOZdloEacjZVipxRjmJYcTeDHLrNMZ9ZKE1sc99XpfcEUB6ltSm1GpA7A5tIS6QAAYpV9BAyDgxcEVO1lRQXBm/ZBO28g5mWfVtkH1gQZoRhlLYbhQWEcRZEUUg1HvTFjFxSx7/0Z/8XcfZQASYTBmKrPHee8NKQEgJYNys1/qE2WqtFg61xCbU8KA8su1yrVSPsGWqVlvoEyvrOG+L9IR4UfsKZ+d9v5q1isxN+dC/6cQAQYKAy9HqQDXt6TeF06BFyIDdAU3gIHJhwUFO2wYXoEAoKrD6flz7VWIehC8ZCKFoCIlQ8iNDGFsWYboj+HEEpAODHwq6nwhFKBEfXPg0DIBuWEZATG6CsCLUQSTIo5ML4/Ukc5Vysif4a0IZfa+qi77kIfhop+2jKIGN/hxOJ9CWGJT4gJNhCEVzIRnssaun4CBiV/NEdOgF/BoBAmBaS8hhhhjvOoB88E9DPn/OoAixVEAEVKImOgmiXBhGXEhCAJMABstAAAMuwACsSgJkAGY6AzMeDUBguwAAcEyJkrIYLGIZAAWEZABOAQoydnXB2YcgQMyagNMyYM5puBWm0HaZ0yo3T1wNKAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n \n class CommonDef(BaseModel):\n-    identifier: str\n+    identifier: str  # Must be ASCII-compatible identifier\n     # Hack: move this out later\n     provider_id: str = """"""""\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/117","117","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the pull request primarily involve the `memory_banks.py` file, specifically within the `CommonDef` and `VectorMemoryBankDef` classes. The `identifier` field in the `CommonDef` class has been updated to include a comment indicating that it must be an ASCII-compatible identifier. Similarly, the `embedding_model` field in the `VectorMemoryBankDef` class has been modified to add a comment specifying that the model name should also be in ASCII format. \n\nThese modifications are limited to the addition of comments for clarity and do not affect the existing logic, control flow, or error handling within the methods of the `MemoryBanks` protocol. The overall structure and relationships of the classes remain unchanged. The changes serve to enhance the documentation of the code by clearly indicating the expected format for specific string fields, but no functional alterations have been made to the code itself.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," @json_schema_type\n class VectorMemoryBankDef(CommonDef):\n     type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n-    embedding_model: str\n+    embedding_model: str  # Model name in ASCII format\n     chunk_size_in_tokens: int\n     overlap_size_in_tokens: Optional[int] = None\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/119","119","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `together.py` file involve a comprehensive restructuring aimed at enhancing the modularity and functionality of the codebase. Numerous new classes and enums have been introduced, including `Attachment`, `AgentTool`, and various tool definitions such as `SearchToolDefinition` and `MemoryToolDefinition`, which extend the `ToolDefinitionCommon` base class. These additions leverage Pydantic's `BaseModel` for improved data validation and serialization.\n\nThe implementation also introduces new enums to categorize tools and configurations, such as `SearchEngineType` and `MemoryQueryGenerator`. Additionally, the `StepCommon` class and its derivatives define different operational steps like `InferenceStep` and `ToolExecutionStep`, establishing a clear structure for system operations.\n\nThe `Turn` and `Session` classes encapsulate agent interactions, while the `AgentConfig` and related classes manage agent configurations, including sampling parameters and session management. The `Agents` protocol has been expanded to include web methods for agent management. Notably, previous safety-related functionalities have been removed, indicating a significant shift in the integration of safety models. Overall, the changes reflect a move towards a more structured and extensible architecture for agent interactions.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-from together import Together\n+\n+from datetime import datetime\n+from enum import Enum\n+from typing import (\n+    Any,\n+    Dict,\n+    List,\n+    Literal,\n+    Optional,\n+    Protocol,\n+    runtime_checkable,\n+    Union,\n+)\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+\n+from pydantic import BaseModel, ConfigDict, Field\n+from typing_extensions import Annotated\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_stack.apis.common.deployment_types import *  # noqa: F403\n+from llama_stack.apis.inference import *  # noqa: F403\n from llama_stack.apis.safety import *  # noqa: F403\n-from llama_stack.distribution.request_headers import NeedsRequestProviderData\n-from llama_stack.providers.datatypes import ShieldsProtocolPrivate\n+from llama_stack.apis.memory import *  # noqa: F403\n+\n+\n+@json_schema_type\n+class Attachment(BaseModel):\n+    content: InterleavedTextMedia | URL\n+    mime_type: str\n+\n+\n+class AgentTool(Enum):\n+    brave_search = """"brave_search""""\n+    wolfram_alpha = """"wolfram_alpha""""\n+    photogen = """"photogen""""\n+    code_interpreter = """"code_interpreter""""\n+\n+    function_call = """"function_call""""\n+    memory = """"memory""""\n+\n+\n+class ToolDefinitionCommon(BaseModel):\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+\n+class SearchEngineType(Enum):\n+    bing = """"bing""""\n+    brave = """"brave""""\n+\n+\n+@json_schema_type\n+class SearchToolDefinition(ToolDefinitionCommon):\n+    # NOTE: brave_search is just a placeholder since model always uses\n+    # brave_search as tool call name\n+    type: Literal[AgentTool.brave_search.value] = AgentTool.brave_search.value\n+    api_key: str\n+    engine: SearchEngineType = SearchEngineType.brave\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class WolframAlphaToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.wolfram_alpha.value] = AgentTool.wolfram_alpha.value\n+    api_key: str\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class PhotogenToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.photogen.value] = AgentTool.photogen.value\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class CodeInterpreterToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.code_interpreter.value] = AgentTool.code_interpreter.value\n+    enable_inline_code_execution: bool = True\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class FunctionCallToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.function_call.value] = AgentTool.function_call.value\n+    function_name: str\n+    description: str\n+    parameters: Dict[str, ToolParamDefinition]\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+class _MemoryBankConfigCommon(BaseModel):\n+    bank_id: str\n+\n+\n+class AgentVectorMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+\n+\n+class AgentKeyValueMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+    keys: List[str]  # what keys to focus on\n+\n+\n+class AgentKeywordMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+class AgentGraphMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+    entities: List[str]  # what entities to focus on\n+\n+\n+MemoryBankConfig = Annotated[\n+    Union[\n+        AgentVectorMemoryBankConfig,\n+        AgentKeyValueMemoryBankConfig,\n+        AgentKeywordMemoryBankConfig,\n+        AgentGraphMemoryBankConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class MemoryQueryGenerator(Enum):\n+    default = """"default""""\n+    llm = """"llm""""\n+    custom = """"custom""""\n+\n+\n+class DefaultMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.default.value] = (\n+        MemoryQueryGenerator.default.value\n+    )\n+    sep: str = """" """"\n+\n+\n+class LLMMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.llm.value] = MemoryQueryGenerator.llm.value\n+    model: str\n+    template: str\n+\n+\n+class CustomMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.custom.value] = MemoryQueryGenerator.custom.value\n+\n+\n+MemoryQueryGeneratorConfig = Annotated[\n+    Union[\n+        DefaultMemoryQueryGeneratorConfig,\n+        LLMMemoryQueryGeneratorConfig,\n+        CustomMemoryQueryGeneratorConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+@json_schema_type\n+class MemoryToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.memory.value] = AgentTool.memory.value\n+    memory_bank_configs: List[MemoryBankConfig] = Field(default_factory=list)\n+    # This config defines how a query is generated using the messages\n+    # for memory bank retrieval.\n+    query_generator_config: MemoryQueryGeneratorConfig = Field(\n+        default=DefaultMemoryQueryGeneratorConfig()\n+    )\n+    max_tokens_in_context: int = 4096\n+    max_chunks: int = 10\n+\n+\n+AgentToolDefinition = Annotated[\n+    Union[\n+        SearchToolDefinition,\n+        WolframAlphaToolDefinition,\n+        PhotogenToolDefinition,\n+        CodeInterpreterToolDefinition,\n+        FunctionCallToolDefinition,\n+        MemoryToolDefinition,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class StepCommon(BaseModel):\n+    turn_id: str\n+    step_id: str\n+    started_at: Optional[datetime] = None\n+    completed_at: Optional[datetime] = None\n+\n+\n+class StepType(Enum):\n+    inference = """"inference""""\n+    tool_execution = """"tool_execution""""\n+    shield_call = """"shield_call""""\n+    memory_retrieval = """"memory_retrieval""""\n+\n+\n+@json_schema_type\n+class InferenceStep(StepCommon):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    step_type: Literal[StepType.inference.value] = StepType.inference.value\n+    model_response: CompletionMessage\n \n-from .config import TogetherSafetyConfig\n \n+@json_schema_type\n+class ToolExecutionStep(StepCommon):\n+    step_type: Literal[StepType.tool_execution.value] = StepType.tool_execution.value\n+    tool_calls: List[ToolCall]\n+    tool_responses: List[ToolResponse]\n \n-TOGETHER_SHIELD_MODEL_MAP = {\n-    """"llama_guard"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-8B"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-11B-Vision"""": """"meta-llama/Llama-Guard-3-11B-Vision-Turbo"""",\n-}\n \n+@json_schema_type\n+class ShieldCallStep(StepCommon):\n+    step_type: Literal[StepType.shield_call.value] = StepType.shield_call.value\n+    violation: Optional[SafetyViolation]\n \n-class TogetherSafetyImpl(Safety, NeedsRequestProviderData, ShieldsProtocolPrivate):\n-    def __init__(self, config: TogetherSafetyConfig) -> None:\n-        self.config = config\n \n-    async def initialize(self) -> None:\n-        pass\n+@json_schema_type\n+class MemoryRetrievalStep(StepCommon):\n+    step_type: Literal[StepType.memory_retrieval.value] = (\n+        StepType.memory_retrieval.value\n+    )\n+    memory_bank_ids: List[str]\n+    inserted_context: InterleavedTextMedia\n \n-    async def shutdown(self) -> None:\n-        pass\n \n-    async def register_shield(self, shield: ShieldDef) -> None:\n-        raise ValueError(""""Registering dynamic shields is not supported"""")\n+Step = Annotated[\n+    Union[\n+        InferenceStep,\n+        ToolExecutionStep,\n+        ShieldCallStep,\n+        MemoryRetrievalStep,\n+    ],\n+    Field(discriminator=""""step_type""""),\n+]\n \n-    async def list_shields(self) -> List[ShieldDef]:\n-        return [\n-            ShieldDef(\n-                identifier=ShieldType.llama_guard.value,\n-                type=ShieldType.llama_guard.value,\n-                params={},\n-            )\n+\n+@json_schema_type\n+class Turn(BaseModel):\n+    """"""""""""A single turn in an interaction with an Agentic System.""""""""""""\n+\n+    turn_id: str\n+    session_id: str\n+    input_messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n         ]\n+    ]\n+    steps: List[Step]\n+    output_message: CompletionMessage\n+    output_attachments: List[Attachment] = Field(default_factory=list)\n+\n+    started_at: datetime\n+    completed_at: Optional[datetime] = None\n+\n+\n+@json_schema_type\n+class Session(BaseModel):\n+    """"""""""""A single session of an interaction with an Agentic System.""""""""""""\n+\n+    session_id: str\n+    session_name: str\n+    turns: List[Turn]\n+    started_at: datetime\n+\n+    memory_bank: Optional[MemoryBankDef] = None\n+\n+\n+class AgentConfigCommon(BaseModel):\n+    sampling_params: Optional[SamplingParams] = SamplingParams()\n+\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+    tools: Optional[List[AgentToolDefinition]] = Field(default_factory=list)\n+    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n+    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n+        default=ToolPromptFormat.json\n+    )\n+\n+    max_infer_iters: int = 10\n+\n+\n+@json_schema_type\n+class AgentConfig(AgentConfigCommon):\n+    model: str\n+    instructions: str\n+    enable_session_persistence: bool\n+\n+\n+class AgentConfigOverridablePerTurn(AgentConfigCommon):\n+    instructions: Optional[str] = None\n+\n+\n+class AgentTurnResponseEventType(Enum):\n+    step_start = """"step_start""""\n+    step_complete = """"step_complete""""\n+    step_progress = """"step_progress""""\n+\n+    turn_start = """"turn_start""""\n+    turn_complete = """"turn_complete""""\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_start.value] = (\n+        AgentTurnResponseEventType.step_start.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_complete.value] = (\n+        AgentTurnResponseEventType.step_complete.value\n+    )\n+    step_type: StepType\n+    step_details: Step\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepProgressPayload(BaseModel):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    event_type: Literal[AgentTurnResponseEventType.step_progress.value] = (\n+        AgentTurnResponseEventType.step_progress.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+\n+    model_response_text_delta: Optional[str] = None\n+    tool_call_delta: Optional[ToolCallDelta] = None\n+    tool_response_text_delta: Optional[str] = None\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_start.value] = (\n+        AgentTurnResponseEventType.turn_start.value\n+    )\n+    turn_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_complete.value] = (\n+        AgentTurnResponseEventType.turn_complete.value\n+    )\n+    turn: Turn\n+\n+\n+@json_schema_type\n+class AgentTurnResponseEvent(BaseModel):\n+    """"""""""""Streamed agent execution response.""""""""""""\n+\n+    payload: Annotated[\n+        Union[\n+            AgentTurnResponseStepStartPayload,\n+            AgentTurnResponseStepProgressPayload,\n+            AgentTurnResponseStepCompletePayload,\n+            AgentTurnResponseTurnStartPayload,\n+            AgentTurnResponseTurnCompletePayload,\n+        ],\n+        Field(discriminator=""""event_type""""),\n+    ]\n+\n+\n+@json_schema_type\n+class AgentCreateResponse(BaseModel):\n+    agent_id: str\n+\n+\n+@json_schema_type\n+class AgentSessionCreateResponse(BaseModel):\n+    session_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnCreateRequest(AgentConfigOverridablePerTurn):\n+    agent_id: str\n+    session_id: str\n+\n+    # TODO: figure out how we can simplify this and make why\n+    # ToolResponseMessage needs to be here (it is function call\n+    # execution from outside the system)\n+    messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n+        ]\n+    ]\n+    attachments: Optional[List[Attachment]] = None\n+\n+    stream: Optional[bool] = False\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStreamChunk(BaseModel):\n+    event: AgentTurnResponseEvent\n+\n+\n+@json_schema_type\n+class AgentStepResponse(BaseModel):\n+    step: Step\n+\n+\n+@runtime_checkable\n+class Agents(Protocol):\n+    @webmethod(route=""""/agents/create"""")\n+    async def create_agent(\n+        self,\n+        agent_config: AgentConfig,\n+    ) -> AgentCreateResponse: ...\n+\n+    # This method is not `async def` because it can result in either an\n+    # `AsyncGenerator` or a `AgentTurnCreateResponse` depending on the value of `stream`.\n+    @webmethod(route=""""/agents/turn/create"""")\n+    def create_agent_turn(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        messages: List[\n+            Union[\n+                UserMessage,\n+                ToolResponseMessage,\n+            ]\n+        ],\n+        attachments: Optional[List[Attachment]] = None,\n+        stream: Optional[bool] = False,\n+    ) -> AgentTurnResponseStreamChunk: ...\n+\n+    @webmethod(route=""""/agents/turn/get"""")\n+    async def get_agents_turn(\n+        self,\n+        agent_id: str,\n+        turn_id: str,\n+    ) -> Turn: ...\n+\n+    @webmethod(route=""""/agents/step/get"""")\n+    async def get_agents_step(\n+        self, agent_id: str, turn_id: str, step_id: str\n+    ) -> AgentStepResponse: ...\n+\n+    @webmethod(route=""""/agents/session/create"""")\n+    async def create_agent_session(\n+        self,\n+        agent_id: str,\n+        session_name: str,\n+    ) -> AgentSessionCreateResponse: ...\n+\n+    @webmethod(route=""""/agents/session/get"""")\n+    async def get_agents_session(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        turn_ids: Optional[List[str]] = None,\n+    ) -> Session: ...\n+\n+    @webmethod(route=""""/agents/session/delete"""")\n+    async def delete_agents_session(self, agent_id: str, session_id: str) -> None: ...\n \n-    async def run_shield(\n-        self, shield_type: str, messages: List[Message], params: Dict[str, Any] = None\n-    ) -> RunShieldResponse:\n-        shield_def = await self.shield_store.get_shield(shield_type)\n-        if not shield_def:\n-            raise ValueError(f""""Unknown shield {shield_type}"""")\n-\n-        model = shield_def.params.get(""""model"""", """"llama_guard"""")\n-        if model not in TOGETHER_SHIELD_MODEL_MAP:\n-            raise ValueError(f""""Unsupported safety model: {model}"""")\n-\n-        together_api_key = None\n-        if self.config.api_key is not None:\n-            together_api_key = self.config.api_key\n-        else:\n-            provider_data = self.get_request_provider_data()\n-            if provider_data is None or not provider_data.together_api_key:\n-                raise ValueError(\n-                    'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n-                )\n-            together_api_key = provider_data.together_api_key\n-\n-        # messages can have role assistant or user\n-        api_messages = []\n-        for message in messages:\n-            if message.role in (Role.user.value, Role.assistant.value):\n-                api_messages.append({""""role"""": message.role, """"content"""": message.content})\n-\n-        violation = await get_safety_response(\n-            together_api_key, TOGETHER_SHIELD_MODEL_MAP[model], api_messages\n-        )\n-        return RunShieldResponse(violation=violation)\n-\n-\n-async def get_safety_response(\n-    api_key: str, model_name: str, messages: List[Dict[str, str]]\n-) -> Optional[SafetyViolation]:\n-    client = Together(api_key=api_key)\n-    response = client.chat.completions.create(messages=messages, model=model_name)\n-    if len(response.choices) == 0:\n-        return None\n-\n-    response_text = response.choices[0].message.content\n-    if response_text == """"safe"""":\n-        return None\n-\n-    parts = response_text.split(""""\n"""")\n-    if len(parts) != 2:\n-        return None\n-\n-    if parts[0] == """"unsafe"""":\n-        return SafetyViolation(\n-            violation_level=ViolationLevel.ERROR,\n-            metadata={""""violation_type"""": parts[1]},\n-        )\n-\n-    return None\n+    @webmethod(route=""""/agents/delete"""")\n+    async def delete_agents(\n+        self,\n+        agent_id: str,\n+    ) -> None: ...\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/120","120","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces substantial changes to the `server.py` file located in the `project/api/llama_stack/distribution/server` directory. Key modifications include the removal of several functions related to error handling and request processing, such as `global_exception_handler`, `translate_exception`, and `passthrough`, which previously managed exceptions and forwarded requests. The `create_dynamic_passthrough` function has also been eliminated.\n\nChanges to the handling of streaming requests have been made, with the `is_streaming_request` function remaining but utilized differently. A new function, `register_object_with_provider`, has been added to facilitate the registration of objects with their respective providers based on API type.\n\nA new class, `CommonRoutingTableImpl`, has been introduced, which implements a routing table for managing a registry of routable objects. This class is extended by three new classes—`ModelsRoutingTable`, `ShieldsRoutingTable`, and `MemoryBanksRoutingTable`—each providing specific functionalities for their respective object types.\n\nAdditionally, the main function has been updated to streamline application startup and shutdown, removing previous signal handling and exception management setups. The overall structure of the server's routing and object management has been refactored for enhanced clarity and maintainability.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import asyncio\n-import functools\n-import inspect\n-import json\n-import signal\n-import traceback\n-\n-from contextlib import asynccontextmanager\n-from ssl import SSLError\n-from typing import Any, Dict, Optional\n-\n-import fire\n-import httpx\n-import yaml\n-\n-from fastapi import Body, FastAPI, HTTPException, Request, Response\n-from fastapi.exceptions import RequestValidationError\n-from fastapi.responses import JSONResponse, StreamingResponse\n-from pydantic import BaseModel, ValidationError\n-from termcolor import cprint\n-from typing_extensions import Annotated\n-\n-from llama_stack.distribution.distribution import builtin_automatically_routed_apis\n-\n-from llama_stack.providers.utils.telemetry.tracing import (\n-    end_trace,\n-    setup_logger,\n-    SpanStatus,\n-    start_trace,\n-)\n+from typing import Any, Dict, List, Optional\n+\n+from llama_models.llama3.api.datatypes import *  # noqa: F403\n+\n+from llama_stack.apis.models import *  # noqa: F403\n+from llama_stack.apis.shields import *  # noqa: F403\n+from llama_stack.apis.memory_banks import *  # noqa: F403\n+\n from llama_stack.distribution.datatypes import *  # noqa: F403\n \n-from llama_stack.distribution.request_headers import set_request_provider_data\n-from llama_stack.distribution.resolver import resolve_impls_with_routing\n-\n-from .endpoints import get_all_api_endpoints\n-\n-\n-def create_sse_event(data: Any) -> str:\n-    if isinstance(data, BaseModel):\n-        data = data.json()\n-    else:\n-        data = json.dumps(data)\n-\n-    return f""""data: {data}\n\n""""\n-\n-\n-async def global_exception_handler(request: Request, exc: Exception):\n-    traceback.print_exception(exc)\n-    http_exc = translate_exception(exc)\n-\n-    return JSONResponse(\n-        status_code=http_exc.status_code, content={""""error"""": {""""detail"""": http_exc.detail}}\n-    )\n-\n-\n-def translate_exception(exc: Exception) -> Union[HTTPException, RequestValidationError]:\n-    if isinstance(exc, ValidationError):\n-        exc = RequestValidationError(exc.raw_errors)\n-\n-    if isinstance(exc, RequestValidationError):\n-        return HTTPException(\n-            status_code=400,\n-            detail={\n-                """"errors"""": [\n-                    {\n-                        """"loc"""": list(error[""""loc""""]),\n-                        """"msg"""": error[""""msg""""],\n-                        """"type"""": error[""""type""""],\n-                    }\n-                    for error in exc.errors()\n-                ]\n-            },\n-        )\n-    elif isinstance(exc, ValueError):\n-        return HTTPException(status_code=400, detail=f""""Invalid value: {str(exc)}"""")\n-    elif isinstance(exc, PermissionError):\n-        return HTTPException(status_code=403, detail=f""""Permission denied: {str(exc)}"""")\n-    elif isinstance(exc, TimeoutError):\n-        return HTTPException(status_code=504, detail=f""""Operation timed out: {str(exc)}"""")\n-    elif isinstance(exc, NotImplementedError):\n-        return HTTPException(status_code=501, detail=f""""Not implemented: {str(exc)}"""")\n-    else:\n-        return HTTPException(\n-            status_code=500,\n-            detail=""""Internal server error: An unexpected error occurred."""",\n-        )\n-\n-\n-async def passthrough(\n-    request: Request,\n-    downstream_url: str,\n-    downstream_headers: Optional[Dict[str, str]] = None,\n-):\n-    await start_trace(request.path, {""""downstream_url"""": downstream_url})\n-\n-    headers = dict(request.headers)\n-    headers.pop(""""host"""", None)\n-    headers.update(downstream_headers or {})\n-\n-    content = await request.body()\n-\n-    client = httpx.AsyncClient()\n-    erred = False\n-    try:\n-        req = client.build_request(\n-            method=request.method,\n-            url=downstream_url,\n-            headers=headers,\n-            content=content,\n-            params=request.query_params,\n-        )\n-        response = await client.send(req, stream=True)\n-\n-        async def stream_response():\n-            async for chunk in response.aiter_raw(chunk_size=64):\n-                yield chunk\n-\n-            await response.aclose()\n-            await client.aclose()\n-\n-        return StreamingResponse(\n-            stream_response(),\n-            status_code=response.status_code,\n-            headers=dict(response.headers),\n-            media_type=response.headers.get(""""content-type""""),\n-        )\n-\n-    except httpx.ReadTimeout:\n-        erred = True\n-        return Response(content=""""Downstream server timed out"""", status_code=504)\n-    except httpx.NetworkError as e:\n-        erred = True\n-        return Response(content=f""""Network error: {str(e)}"""", status_code=502)\n-    except httpx.TooManyRedirects:\n-        erred = True\n-        return Response(content=""""Too many redirects"""", status_code=502)\n-    except SSLError as e:\n-        erred = True\n-        return Response(content=f""""SSL error: {str(e)}"""", status_code=502)\n-    except httpx.HTTPStatusError as e:\n-        erred = True\n-        return Response(content=str(e), status_code=e.response.status_code)\n-    except Exception as e:\n-        erred = True\n-        return Response(content=f""""Unexpected error: {str(e)}"""", status_code=500)\n-    finally:\n-        await end_trace(SpanStatus.OK if not erred else SpanStatus.ERROR)\n-\n-\n-def handle_sigint(app, *args, **kwargs):\n-    print(""""SIGINT or CTRL-C detected. Exiting gracefully..."""")\n-\n-    async def run_shutdown():\n-        for impl in app.__llama_stack_impls__.values():\n-            print(f""""Shutting down {impl}"""")\n-            await impl.shutdown()\n-\n-    asyncio.run(run_shutdown())\n-\n-    loop = asyncio.get_event_loop()\n-    for task in asyncio.all_tasks(loop):\n-        task.cancel()\n-\n-    loop.stop()\n-\n-\n-@asynccontextmanager\n-async def lifespan(app: FastAPI):\n-    print(""""Starting up"""")\n-    yield\n-\n-    print(""""Shutting down"""")\n-    for impl in app.__llama_stack_impls__.values():\n-        await impl.shutdown()\n-\n-\n-def create_dynamic_passthrough(\n-    downstream_url: str, downstream_headers: Optional[Dict[str, str]] = None\n-):\n-    async def endpoint(request: Request):\n-        return await passthrough(request, downstream_url, downstream_headers)\n-\n-    return endpoint\n-\n-\n-def is_streaming_request(func_name: str, request: Request, **kwargs):\n-    # TODO: pass the api method and punt it to the Protocol definition directly\n-    return kwargs.get(""""stream"""", False)\n-\n-\n-async def maybe_await(value):\n-    if inspect.iscoroutine(value):\n-        return await value\n-    return value\n-\n-\n-async def sse_generator(event_gen):\n-    try:\n-        async for item in event_gen:\n-            yield create_sse_event(item)\n-            await asyncio.sleep(0.01)\n-    except asyncio.CancelledError:\n-        print(""""Generator cancelled"""")\n-        await event_gen.aclose()\n-    except Exception as e:\n-        traceback.print_exception(e)\n-        yield create_sse_event(\n-            {\n-                """"error"""": {\n-                    """"message"""": str(translate_exception(e)),\n-                },\n-            }\n-        )\n-    finally:\n-        await end_trace()\n-\n-\n-def create_dynamic_typed_route(func: Any, method: str):\n-\n-    async def endpoint(request: Request, **kwargs):\n-        await start_trace(func.__name__)\n-\n-        set_request_provider_data(request.headers)\n-\n-        is_streaming = is_streaming_request(func.__name__, request, **kwargs)\n-        try:\n-            if is_streaming:\n-                return StreamingResponse(\n-                    sse_generator(func(**kwargs)), media_type=""""text/event-stream""""\n-                )\n-            else:\n-                value = func(**kwargs)\n-                return await maybe_await(value)\n-        except Exception as e:\n-            traceback.print_exception(e)\n-            raise translate_exception(e) from e\n-        finally:\n-            await end_trace()\n-\n-    sig = inspect.signature(func)\n-    new_params = [\n-        inspect.Parameter(\n-            """"request"""", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n-        )\n-    ]\n-    new_params.extend(sig.parameters.values())\n-\n-    if method == """"post"""":\n-        # make sure every parameter is annotated with Body() so FASTAPI doesn't\n-        # do anything too intelligent and ask for some parameters in the query\n-        # and some in the body\n-        new_params = [new_params[0]] + [\n-            param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n-            for param in new_params[1:]\n-        ]\n-\n-    endpoint.__signature__ = sig.replace(parameters=new_params)\n-\n-    return endpoint\n-\n-\n-def main(\n-    yaml_config: str = """"llamastack-run.yaml"""",\n-    port: int = 5000,\n-    disable_ipv6: bool = False,\n-):\n-    with open(yaml_config, """"r"""") as fp:\n-        config = StackRunConfig(**yaml.safe_load(fp))\n-\n-    app = FastAPI()\n-\n-    impls = asyncio.run(resolve_impls_with_routing(config))\n-    if Api.telemetry in impls:\n-        setup_logger(impls[Api.telemetry])\n-\n-    all_endpoints = get_all_api_endpoints()\n-\n-    if config.apis:\n-        apis_to_serve = set(config.apis)\n-    else:\n-        apis_to_serve = set(impls.keys())\n-\n-    for inf in builtin_automatically_routed_apis():\n-        apis_to_serve.add(inf.routing_table_api.value)\n-\n-    apis_to_serve.add(""""inspect"""")\n-    for api_str in apis_to_serve:\n-        api = Api(api_str)\n-\n-        endpoints = all_endpoints[api]\n-        impl = impls[api]\n-\n-        if is_passthrough(impl.__provider_spec__):\n-            for endpoint in endpoints:\n-                url = impl.__provider_config__.url.rstrip(""""/"""") + endpoint.route\n-                getattr(app, endpoint.method)(endpoint.route)(\n-                    create_dynamic_passthrough(url)\n-                )\n-        else:\n-            for endpoint in endpoints:\n-                if not hasattr(impl, endpoint.name):\n-                    # ideally this should be a typing violation already\n-                    raise ValueError(\n-                        f""""Could not find method {endpoint.name} on {impl}!!""""\n-                    )\n-\n-                impl_method = getattr(impl, endpoint.name)\n-\n-                getattr(app, endpoint.method)(endpoint.route, response_model=None)(\n-                    create_dynamic_typed_route(\n-                        impl_method,\n-                        endpoint.method,\n-                    )\n-                )\n \n-        cprint(f""""Serving API {api_str}"""", """"white"""", attrs=[""""bold""""])\n-        for endpoint in endpoints:\n-            cprint(f"""" {endpoint.method.upper()} {endpoint.route}"""", """"white"""")\n+def get_impl_api(p: Any) -> Api:\n+    return p.__provider_spec__.api\n+\n \n-    print("""""""")\n-    app.exception_handler(RequestValidationError)(global_exception_handler)\n-    app.exception_handler(Exception)(global_exception_handler)\n-    signal.signal(signal.SIGINT, functools.partial(handle_sigint, app))\n+async def register_object_with_provider(obj: RoutableObject, p: Any) -> None:\n+    api = get_impl_api(p)\n+    if api == Api.inference:\n+        await p.register_model(obj)\n+    elif api == Api.safety:\n+        await p.register_shield(obj)\n+    elif api == Api.memory:\n+        await p.register_memory_bank(obj)\n \n-    app.__llama_stack_impls__ = impls\n \n-    import uvicorn\n+Registry = Dict[str, List[RoutableObjectWithProvider]]\n \n-    # FYI this does not do hot-reloads\n-    listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n-    print(f""""Listening on {listen_host}:{port}"""")\n-    uvicorn.run(app, host=listen_host, port=port)\n \n+# TODO: this routing table maintains state in memory purely. We need to\n+# add persistence to it when we add dynamic registration of objects.\n+class CommonRoutingTableImpl(RoutingTable):\n+    def __init__(\n+        self,\n+        impls_by_provider_id: Dict[str, RoutedProtocol],\n+    ) -> None:\n+        self.impls_by_provider_id = impls_by_provider_id\n+\n+    async def initialize(self) -> None:\n+        self.registry: Registry = {}\n+\n+        def add_objects(objs: List[RoutableObjectWithProvider]) -> None:\n+            for obj in objs:\n+                if obj.identifier not in self.registry:\n+                    self.registry[obj.identifier] = []\n+\n+                self.registry[obj.identifier].append(obj)\n+\n+        for pid, p in self.impls_by_provider_id.items():\n+            api = get_impl_api(p)\n+            if api == Api.inference:\n+                p.model_store = self\n+                models = await p.list_models()\n+                add_objects(\n+                    [ModelDefWithProvider(**m.dict(), provider_id=pid) for m in models]\n+                )\n+\n+            elif api == Api.safety:\n+                p.shield_store = self\n+                shields = await p.list_shields()\n+                add_objects(\n+                    [\n+                        ShieldDefWithProvider(**s.dict(), provider_id=pid)\n+                        for s in shields\n+                    ]\n+                )\n \n-if __name__ == """"__main__"""":\n-    fire.Fire(main)\n+            elif api == Api.memory:\n+                p.memory_bank_store = self\n+                memory_banks = await p.list_memory_banks()\n+\n+                # do in-memory updates due to pesky Annotated unions\n+                for m in memory_banks:\n+                    m.provider_id = pid\n+\n+                add_objects(memory_banks)\n+\n+    async def shutdown(self) -> None:\n+        for p in self.impls_by_provider_id.values():\n+            await p.shutdown()\n+\n+    def get_provider_impl(\n+        self, routing_key: str, provider_id: Optional[str] = None\n+    ) -> Any:\n+        if routing_key not in self.registry:\n+            raise ValueError(f""""`{routing_key}` not registered"""")\n+\n+        objs = self.registry[routing_key]\n+        for obj in objs:\n+            if not provider_id or provider_id == obj.provider_id:\n+                return self.impls_by_provider_id[obj.provider_id]\n+\n+        raise ValueError(f""""Provider not found for `{routing_key}`"""")\n+\n+    def get_object_by_identifier(\n+        self, identifier: str\n+    ) -> Optional[RoutableObjectWithProvider]:\n+        objs = self.registry.get(identifier, [])\n+        if not objs:\n+            return None\n+\n+        # kind of ill-defined behavior here, but we'll just return the first one\n+        return objs[0]\n+\n+    async def register_object(self, obj: RoutableObjectWithProvider):\n+        # if provider_id is not specified, we'll pick an arbitrary one from existing entries\n+        if not obj.provider_id and len(self.impls_by_provider_id) > 0:\n+            obj.provider_id = list(self.impls_by_provider_id.keys())[0]\n+\n+        if obj.provider_id not in self.impls_by_provider_id:\n+            raise ValueError(f""""Provider `{obj.provider_id}` not found"""")\n+        \n+        p = self.impls_by_provider_id[obj.provider_id]\n+        await register_object_with_provider(obj, p)\n+        \n+        # Direct registry modification without checking current state\n+        if obj.identifier not in self.registry:\n+            self.registry[obj.identifier] = []\n+        self.registry[obj.identifier].append(obj)\n+        # TODO: persist this to a store\n+\n+\n+class ModelsRoutingTable(CommonRoutingTableImpl, Models):\n+    async def list_models(self) -> List[ModelDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_model(self, identifier: str) -> Optional[ModelDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_model(self, model: ModelDefWithProvider) -> None:\n+        await self.register_object(model)\n+\n+\n+class ShieldsRoutingTable(CommonRoutingTableImpl, Shields):\n+    async def list_shields(self) -> List[ShieldDef]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_shield(self, shield_type: str) -> Optional[ShieldDefWithProvider]:\n+        return self.get_object_by_identifier(shield_type)\n+\n+    async def register_shield(self, shield: ShieldDefWithProvider) -> None:\n+        await self.register_object(shield)\n+\n+\n+class MemoryBanksRoutingTable(CommonRoutingTableImpl, MemoryBanks):\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None:\n+        await self.register_object(memory_bank)\n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/121","121","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the API. Specifically, the routes for three methods have been modified to incorporate a versioning scheme. The `completion` method's route has been changed from `/inference/completion` to `/v1/completion`. Similarly, the `chat_completion` method's route has been updated from `/inference/chat_completion` to `/v1/chat_completion`, and the `embeddings` method's route has transitioned from `/inference/embeddings` to `/v1/embeddings`. \n\nThese changes affect the endpoint URLs for invoking these methods, reflecting a move towards a versioned API design. It is important to note that the core functionality of the `Inference` protocol remains unchanged, as the method signatures, parameters, and return types have not been altered. The updates solely pertain to the routing of the web methods, ensuring that existing functionality is preserved while adopting a structured versioning approach.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `CompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/completion"""")\n+    @webmethod(route=""""/v1/completion"""")\n     def completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/121","121","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the API. Specifically, the routes for three methods have been modified to incorporate a versioning scheme. The `completion` method's route has been changed from `/inference/completion` to `/v1/completion`. Similarly, the `chat_completion` method's route has been updated from `/inference/chat_completion` to `/v1/chat_completion`, and the `embeddings` method's route has transitioned from `/inference/embeddings` to `/v1/embeddings`. \n\nThese changes affect the endpoint URLs for invoking these methods, reflecting a move towards a versioned API design. It is important to note that the core functionality of the `Inference` protocol remains unchanged, as the method signatures, parameters, and return types have not been altered. The updates solely pertain to the routing of the web methods, ensuring that existing functionality is preserved while adopting a structured versioning approach.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `ChatCompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/chat_completion"""")\n+    @webmethod(route=""""/v1/chat_completion"""")\n     def chat_completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/121","121","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the API. Specifically, the routes for three methods have been modified to incorporate a versioning scheme. The `completion` method's route has been changed from `/inference/completion` to `/v1/completion`. Similarly, the `chat_completion` method's route has been updated from `/inference/chat_completion` to `/v1/chat_completion`, and the `embeddings` method's route has transitioned from `/inference/embeddings` to `/v1/embeddings`. \n\nThese changes affect the endpoint URLs for invoking these methods, reflecting a move towards a versioned API design. It is important to note that the core functionality of the `Inference` protocol remains unchanged, as the method signatures, parameters, and return types have not been altered. The updates solely pertain to the routing of the web methods, ensuring that existing functionality is preserved while adopting a structured versioning approach.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         logprobs: Optional[LogProbConfig] = None,\n     ) -> Union[ChatCompletionResponse, ChatCompletionResponseStreamChunk]: ...\n \n-    @webmethod(route=""""/inference/embeddings"""")\n+    @webmethod(route=""""/v1/embeddings"""")\n     async def embeddings(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/122","122","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes are made to the `create_agent_turn` and `_create_agent_turn_streaming` methods. In `create_agent_turn`, the condition for returning a streaming response has been revised from checking solely the `stream` parameter to also considering whether `attachments` is `None`. This adjustment allows for streaming responses in additional scenarios. \n\nIn the `_create_agent_turn_streaming` method, a new conditional check has been implemented to ensure that the agent is retrieved only when the request is not for streaming and attachments are present. This change affects the control flow and may optimize agent retrieval based on request characteristics. \n\nWhile the error handling in the `get_agent` method remains unchanged, the overall logic flow of the class is impacted by the new conditions in the aforementioned methods. Other methods in the class, such as `get_agents_turn`, `get_agents_step`, `get_agents_session`, `delete_agents_session`, and `delete_agents`, have not been modified and continue to raise `NotImplementedError`. Additionally, the method signatures for `create_agent_turn` and `_create_agent_turn_streaming` have been updated to reflect these changes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","             attachments=attachments,\n             stream=True,\n         )\n-        if stream:\n+        if stream or attachments is None:\n             return self._create_agent_turn_streaming(request)\n         else:\n             raise NotImplementedError(""""Non-streaming agent turns not yet implemented"""")\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/122","122","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes are made to the `create_agent_turn` and `_create_agent_turn_streaming` methods. In `create_agent_turn`, the condition for returning a streaming response has been revised from checking solely the `stream` parameter to also considering whether `attachments` is `None`. This adjustment allows for streaming responses in additional scenarios. \n\nIn the `_create_agent_turn_streaming` method, a new conditional check has been implemented to ensure that the agent is retrieved only when the request is not for streaming and attachments are present. This change affects the control flow and may optimize agent retrieval based on request characteristics. \n\nWhile the error handling in the `get_agent` method remains unchanged, the overall logic flow of the class is impacted by the new conditions in the aforementioned methods. Other methods in the class, such as `get_agents_turn`, `get_agents_step`, `get_agents_session`, `delete_agents_session`, and `delete_agents`, have not been modified and continue to raise `NotImplementedError`. Additionally, the method signatures for `create_agent_turn` and `_create_agent_turn_streaming` have been updated to reflect these changes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self,\n         request: AgentTurnCreateRequest,\n     ) -> AsyncGenerator:\n-        agent = await self.get_agent(request.agent_id)\n+        if not request.stream and request.attachments:\n+            agent = await self.get_agent(request.agent_id)\n         async for event in agent.create_and_execute_turn(request):\n             yield event\n \n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/123","123","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `vector_store.py` file within the project. Specifically, the `get_embedding_model` function has been modified to improve the efficiency of loading the embedding model. The new implementation checks for the presence of the model in the `EMBEDDING_MODELS` dictionary before loading it, which eliminates unnecessary loading and associated print statements. \n\nAdditionally, the `content_from_data` function has been enhanced to utilize the `chardet` library for encoding detection when the encoding is not specified in the data URL. This adjustment ensures accurate content processing based on the detected encoding. \n\nThe `content_from_doc` function remains unchanged, continuing to support both data URLs and standard URLs. The overall structure and functionality of the `EmbeddingIndex` and `BankWithIndex` classes are preserved, with no alterations to their method signatures or core logic. The changes primarily enhance model loading efficiency and data encoding handling while maintaining existing functionalities.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n     global EMBEDDING_MODELS\n \n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n+    if model not in EMBEDDING_MODELS:\n+        print(f""""Loading sentence transformer for {model}..."""")\n+        from sentence_transformers import SentenceTransformer\n+        loaded_model = SentenceTransformer(model)\n+        EMBEDDING_MODELS[model] = loaded_model\n \n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n+    loaded_model = EMBEDDING_MODELS[model]\n     return loaded_model\n \n \n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/124","124","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute named `score_threshold` of type `float` with a default value of `0.0` is added to the `RewardScoringRequest` class. This addition allows users to specify a scoring threshold in their requests. \n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is modified to accept the new `score_threshold` parameter, also defaulting to `0.0`. The implementation of this method is updated to incorporate logic that utilizes the `score_threshold`. Specifically, if the `dialog_generations` input is empty, the method returns an empty `RewardScoringResponse`. If the `score_threshold` is greater than or equal to `0`, it returns a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. \n\nThese modifications collectively enhance the reward scoring mechanism by enabling the specification of a score threshold and adjusting the response based on the provided input conditions.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     dialog_generations: List[DialogGenerations]\n     model: str\n+    score_threshold: float = 0.0\n \n \n @json_schema_type\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/124","124","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute named `score_threshold` of type `float` with a default value of `0.0` is added to the `RewardScoringRequest` class. This addition allows users to specify a scoring threshold in their requests. \n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is modified to accept the new `score_threshold` parameter, also defaulting to `0.0`. The implementation of this method is updated to incorporate logic that utilizes the `score_threshold`. Specifically, if the `dialog_generations` input is empty, the method returns an empty `RewardScoringResponse`. If the `score_threshold` is greater than or equal to `0`, it returns a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. \n\nThese modifications collectively enhance the reward scoring mechanism by enabling the specification of a score threshold and adjusting the response based on the provided input conditions.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5UPyuKOQGE4ClJAAjDUALBqQAJJhDJiQJ+gMDNL59NQjnpv4vvgKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWC9DRMZgophKKiqdTaFEAcX+6zAtjAABFqF0SLgUdwfN4URdLgBdAAU8MRyLRGP22Nx+MUymJuFJFO8VJp9Ol+WZrN8HKuAEobu4DkpEAwKPBuOJmjwKPgykoVst4I8aMh9t99qhVX4AsFQh0ujgCMxqLact55AaSMldj9IGT1AAJXqQcanAAG6QJkrU0vgKJINRIJSy5SqFETNwAcvh0LRaOpChgcpAlBnvMgigoNiQAB5hFT4PARhjTEHSfh8VkUbj4fL8TYR13+IIhRBdgIoDAMbzYK0riN6g1Gk0YDRGfRGExQMj0fDTtCJYhkZSDBSsdhcXj8YSicRSGTBiVE9NaHR9FPGAEGQVAnmvAhb3IKgH1xNgNi4KgKkgHpnFcZ4f0JFR/20XQwEMYxwDAIxeHwEQxBRNBuEzXw0D9AB9Rc0AYABrKiaMQFEAk6ChaCYphDRBbjKhcfj9SKYEiA0bhZA4AwYkUgwLEgOJbmg+9ojQv0MMvRgB1IRAdU8KtNmnYFcHNWhsHeZBmEUeBtjtGsHXLfZPETGxRL4+xBKkryPUXRMlnoTzvNoXzJJBYKyIIJg/GBSBEx4sSBKi6TZOLVTDkqdAEUNAQ8BIAAaJKJICBj9gCRBYEpRNSr03BZG4DzNm8fBqGCoF9nQesSE2a9vDCbJ108PTEwABg0Cb6pQZA0EraICAjMLeIivyQQChdcGCtcukQG44FQftMFIdAAQqB0DndbbwnLRAWoYRz5DQEZqtquVID+Phyqkw8DFuLB3KSry1sioSiBi804v+UrgbYfZFCSlK+LSgJgtQbBuFoMM7pXNcN08YHE3KkhKtgd66p4Fx6KZShSpyRBy262BeqUAafGGnIQinJKppmw6DgR2raAAcjA5huCiBDpX3ObIHs0ydjx4ECaUSB2oxBgRm+AdaCiK7PAaamqARygbluadEyrHJ8CIBjSBg/1mkQDHkBISWmtK9Q51wbAKAweasA9415FWsTwf86Rx0DkgsstsrBLJqrpA+2g3cgIgAmSPhHSwFt5zrZbJtmn2Aj9gP5pB8LI826OXbj1sMwwKSlkgEOmo1pAwnG8G6FpeBbaIMk71glziyMAB5KQqF8OGDhOwd3YwAd3gjTZsFXfccnUeRGuu8LUI20E2EXpBmEw872qBEEIwe0RHIDOW9Ne0m3tTykQorIRxnEW/geqjHScAhGQXiBgcYErIHjNCrPuA6RhzCWDiENe8Lk8bAyUHtMeLteYdnHBQB8LZWQCG8LaduGxqzSCPJAAAai4QeJDPALStFwEmSdyaUzlFwNqHUwgAF5ID8wxlgPaiBkDhx8sfLaoRhFJTIhRZk1FaLeHomgJi0o2IcSQCJNaaMpI6NSr9EEMlZCJgMFAAAskyEWqF4BEFrBXMY2MwysPZnOXRpMeT5G8JsUqNtNYO1Hs7QOXBITdxhAPIeI8nZwK5KVRWJBvBcEXBQDUug9Dghbs0GEoMI5SPrrHLkHBZGiPEbkyR6VZGJnkR+LRKI6KMWYpopRXEUbiWPgY1GRiMqmMgIAJMIkpuLaWjEgXjEm+PrIPAJjtUEu1CeEyJmtomzMDnEhWEokmoUsqVUmHCP5cK+u1b4Aj+ZpIIpkmsOSa75Ieg3IpJSVFiOrmDY+VSamUSUfUlRjSNHsRaZ09p6UAV6OMZlBSSlzEERPMRchF4rw3hmbBaI8Fnz+DQChbSLh5DDFTH+dQAF8J6GAvBdQDE1iIAYqUAsdB1EuDCMeIiEBzgAGYJqiBqBcMyNQGAAA4VAkGZbQAA7AAThFWcWgZxNgADYeW0AAKz9W5SQEVQqBBCoWoS6FTKSW4DJbQClVLKg0vPISoAA\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def reward_score(\n         self,\n         dialog_generations: List[DialogGenerations],\n-        model: str,\n-    ) -> Union[RewardScoringResponse]: ...\n+        model: str, \n+        score_threshold: float = 0.0,\n+    ) -> Union[RewardScoringResponse]:\n+        if not dialog_generations:\n+            return RewardScoringResponse(scored_generations=[])\n+        \n+        if score_threshold >= 0:\n+            return RewardScoringResponse(\n+                scored_generations=[\n+                    ScoredDialogGenerations(dialog=[], scored_generations=[])\n+                ])\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/125","125","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to cache metadata for memory banks. This attribute is utilized in the `register_memory_bank` method, where metadata is stored after being upserted into the database. The `list_memory_banks` method has been modified to return memory banks using this cache, ensuring that the list reflects the latest state.\n\nAdditionally, the logic for retrieving the index in the `insert_documents` and `query_documents` methods has been updated. The new implementation first checks for the existence of the bank identifier in `_bank_metadata_cache` before accessing it, which aims to prevent errors related to unregistered banks. Error handling in the `initialize` method remains unchanged, while the `shutdown` method is still a placeholder. The SQL queries for table creation and record manipulation have not been altered, maintaining the consistency of the database schema. Overall, these modifications improve the internal state management of memory banks within the `PGVectorMemoryAdapter`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self.cursor = None\n         self.conn = None\n         self.cache = {}\n+        self._bank_metadata_cache = {}\n \n     async def initialize(self) -> None:\n         try:\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/125","125","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to cache metadata for memory banks. This attribute is utilized in the `register_memory_bank` method, where metadata is stored after being upserted into the database. The `list_memory_banks` method has been modified to return memory banks using this cache, ensuring that the list reflects the latest state.\n\nAdditionally, the logic for retrieving the index in the `insert_documents` and `query_documents` methods has been updated. The new implementation first checks for the existence of the bank identifier in `_bank_metadata_cache` before accessing it, which aims to prevent errors related to unregistered banks. Error handling in the `initialize` method remains unchanged, while the `shutdown` method is still a placeholder. The SQL queries for table creation and record manipulation have not been altered, maintaining the consistency of the database schema. Overall, these modifications improve the internal state management of memory banks within the `PGVectorMemoryAdapter`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5fRdkBhOApSQAIw1AKwakACSYQyYkEfoDAzS+bthuKOQm/i++BV4BgiJAAKo2AAyXAA2rBcLhuIgOAB6ZFEdSwXoaJjMZFMJRUVTqbTIgDif3WYFsYAAItQuiRcMjuD5vMizucALoACjhCKRqPRXyxOLximURNwJPJ3kp1LpUvyTJZvnZFwAlFd3N8lIgGBR4NxxM0eBR8GUlCtlvB7jRkF9qCNUCq/AFgqEOns0IlmNQbTlvPJ9SRkkN5F9PAQ/pAAAbpfEStRS+DIkg1EglLLlKoUGNXABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8CNPAxpsDpPw+BGvBRuPh8vxNp2vL5/EEQohWwEUBgGN5sJal5PdfrDcaMBojPojCYoGR6PgJ96CMQyMpBgpWOwuLx+MJROIpDIg+LCUmtDp9MeMAIMgqAPJehCkOQVB3jibAbFwVAVJAPTOK4jxfgSKi/touhgIYxjgGARi8PgIhiMiaDcCmvhoL6AD685oAwADWzJmhalCIBRtCUTQFBcWwzBFLIzJEFIYhFKJ4kEBQGjcLIHAGDEykGBYkBxNc15QaGyFOL6aHnowPakIg2qeKWmwTkCuBmrQ2CvN0WTKH4QkWf6u72kWg4xtwYlvkUcmyDGPzwFEAA0prwPpoXyGQPYMECIKDps2DLruOTqPIhneVYpIAGr+RQACyJBCa4cQ8UalDBSuXSIFccT7JUkXZDQ6DwgaAh4J4MZ0QImDMXRbBSjxUp0fc3YkMFoEltEBCMEx3zDWgo1oD89aCcJjwDfVQGoN2mCkCgyABJsURiNEQKTjGATovOlBDaVwl9QNwXDbAigRRUoyLoOm1of1GDMQA5Mgy2rcdyEyZdWBfPti2eGgmx8Y8JCJZA2CIpQd7WV5Or0v1+RXB4sbeEguCPWVsgvUDiBvYyH0rMgmOjXNRYBLg2AUFga1k/O46QP98iA8x9rTGEeChfA8x9nDyATaMEVkD0BrAiMjqDhzXPkEMO0zmdb6TkJ/MBK8GxQ8k+4GBVpbpb4sgRYO3j4OiDDrXwHMGlmauDkCShNhuAj4F8sZAhMFO0PgDBOOwdNLPQMbuq4dGR9HcG4HH72KMg0wyCQZCC4o8DbHQxPfLwWbtiBzDcFE6d+iapam5E8hMQ57yTgrJBfQgUSTg0kBSPx5YhfxdyjCxIEToOIsoOsWzlHwzbkyBWC9SLj0jfS40I8FRy/Iu1A0DX4g++zjJe1Ik5+82Zf7cZnjK1zsvi/wGCBoLT0A3rDphNMV9HALrdcmlBoguC7M0RAaxQG0AiiOGgGx4ABnkBXKQiC1aUDNPxGc3gdLzVSsA+6ARda0ytgAUQoFgyAPZaBkzVgEX0YcGxQPuhsL6GJJzL3nOjZsrwjQjxoXQkEV1vJAjLBlGW9MviKBnMmHWZceqIExLgSOFQMBSMZpDaOlD2AfzWrXJiJAPqymOJgegDDtAYGZsuB+tAFH8CHgGBsNloxnQBJDFaQhxh3nmkCJgw4ijJH7s1BW6M2AHQwEgZgPcbSwEFmgeQUUSJX24JQA+vplyeGGMQ+y6McnLEwGEVahNPBJ3KPVMyDgACKEJIBlL7AfRgAQ/Q+xUFEZAZilzh0SsiFmLSQSmyKLQE6pVLEYxsYdOgSsrFc3Rr/TcBMGTIUmr6LRkCQHm0BCHVBhRxgoBrnXdgDcrFWwAPKON8I7b4ESTKQDipgV419Gzc0rIxNqGS0CkHTgLIW21aYdAxCI74MZcoFQksVL+sgKq8WqhFJJ7E5nfBIJZG05RlxZQnL82ehCbLHPjrIy+lYSLt2kFbcwlg4jeD4sczym5RC4OguWOsE5mwjgoHeesLIBBkzduwMs0gDyQDyi4JB3LEazVoFwGM+RvCbA0DTQa4Nt5d2mlgWqiBkAgvyoVEqVNoVVVzBuHyZoyJMkotRXB9FGIsTYuaaB/FuIwodULKShVXXgsCjGJSKkDCHgIhAO5ywBbgS0reaIsFHz+DQEhFC+lhYYUTOoP8uE9CAVguoOiaxEB0VKNmOgDEpTspTUeQiVYAAcABOMtmwADMAgAAMAgTj5wAGzphqAwBttAGA1oYCcAALC2+tDBNhlpqP2gQLbaAtrQPWk4Lbi3+qgOmimWac1ZkqPm08KagA=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                 (memory_bank.identifier, memory_bank),\n             ],\n         )\n+        self._bank_metadata_cache[memory_bank.identifier] = memory_bank\n \n         index = BankWithIndex(\n             bank=memory_bank,\n             index=PGVectorIndex(memory_bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n         )\n         self.cache[memory_bank.identifier] = index\n+        self.conn.commit()\n \n     async def list_memory_banks(self) -> List[MemoryBankDef]:\n         banks = load_models(self.cursor, MemoryBankDef)\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/125","125","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to cache metadata for memory banks. This attribute is utilized in the `register_memory_bank` method, where metadata is stored after being upserted into the database. The `list_memory_banks` method has been modified to return memory banks using this cache, ensuring that the list reflects the latest state.\n\nAdditionally, the logic for retrieving the index in the `insert_documents` and `query_documents` methods has been updated. The new implementation first checks for the existence of the bank identifier in `_bank_metadata_cache` before accessing it, which aims to prevent errors related to unregistered banks. Error handling in the `initialize` method remains unchanged, while the `shutdown` method is still a placeholder. The SQL queries for table creation and record manipulation have not been altered, maintaining the consistency of the database schema. Overall, these modifications improve the internal state management of memory banks within the `PGVectorMemoryAdapter`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                     index=PGVectorIndex(bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n                 )\n                 self.cache[bank.identifier] = index\n-        return banks\n+        return [self._bank_metadata_cache.get(bank.identifier, bank) for bank in banks]\n \n     async def insert_documents(\n         self,\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/125","125","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to cache metadata for memory banks. This attribute is utilized in the `register_memory_bank` method, where metadata is stored after being upserted into the database. The `list_memory_banks` method has been modified to return memory banks using this cache, ensuring that the list reflects the latest state.\n\nAdditionally, the logic for retrieving the index in the `insert_documents` and `query_documents` methods has been updated. The new implementation first checks for the existence of the bank identifier in `_bank_metadata_cache` before accessing it, which aims to prevent errors related to unregistered banks. Error handling in the `initialize` method remains unchanged, while the `shutdown` method is still a placeholder. The SQL queries for table creation and record manipulation have not been altered, maintaining the consistency of the database schema. Overall, these modifications improve the internal state management of memory banks within the `PGVectorMemoryAdapter`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         documents: List[MemoryBankDocument],\n         ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/125","125","Automated Test: @eval-senior-reviewer-2-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to cache metadata for memory banks. This attribute is utilized in the `register_memory_bank` method, where metadata is stored after being upserted into the database. The `list_memory_banks` method has been modified to return memory banks using this cache, ensuring that the list reflects the latest state.\n\nAdditionally, the logic for retrieving the index in the `insert_documents` and `query_documents` methods has been updated. The new implementation first checks for the existence of the bank identifier in `_bank_metadata_cache` before accessing it, which aims to prevent errors related to unregistered banks. Error handling in the `initialize` method remains unchanged, while the `shutdown` method is still a placeholder. The SQL queries for table creation and record manipulation have not been altered, maintaining the consistency of the database schema. Overall, these modifications improve the internal state management of memory banks within the `PGVectorMemoryAdapter`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMYOQVefgY5LgxkBVoyIjYAszqNPRy4bCe2Pl85LA5YGg1AF7oGPSo8EoY4gBm5fRdkBhOApSQAIw1AKwakACSYQyYkEfoDAzS+bthuKOQm/i++BV4BgiJAAKo2AAyXAA2rBcLhuIgOAB6ZFEdSwXoaJjMZFMJRUVTqbTIgDif3WYFsYAAItQuiRcMjuD5vMizucALoACjhCKRqPRXyxOLximURNwJPJ3kp1LpUvyTJZvnZFwAlFd3N8lIgGBR4NxxM0eBR8GUlCtlvB7jRkF9qCNUCq/AFgqEOns0IlmNQbTlvPJ9SRkkN5F9PAQ/pAAAbpfEStRS+DIkg1EglLLlKoUGNXABy+HQtFo6kKGBykCUye8yCKCg2JAAHmEVPg8CNPAxpsDpPw+BGvBRuPh8vxNp2vL5/EEQohWwEUBgGN5sJal5PdfrDcaMBojPojCYoGR6PgJ96CMQyMpBgpWOwuLx+MJROIpDIg+LCUmtDp9MeMAIMgqAPJehCkOQVB3jibAbFwVAVJAPTOK4jxfgSKi/touhgIYxjgGARi8PgIhiMiaDcCmvhoL6AD685oAwADWzJmhalCIBRtCUTQFBcWwzBFLIzJEFIYhFKJ4kEBQGjcLIHAGDEykGBYkBxNc15QaGyFOL6aHnowPakIg2qeKWmwTkCuBmrQ2CvN0WTKH4QkWf6u72kWg4xtwYlvkUcmyDGPzwFEAA0prwPpoXyGQPYMECIKDps2DLruOTqPIhneVYpIAGr+RQACyJBCa4cQ8UalDBSuXSIFccT7JUkXZDQ6DwgaAh4J4MZ0QImDMXRbBSjxUp0fc3YkMFoEltEBCMEx3zDWgo1oD89aCcJjwDfVQGoN2mCkCgyABJsURiNEQKTjGATovOlBDaVwl9QNwXDbAigRRUoyLoOm1of1GDMQA5Mgy2rcdyEyZdWBfPti2eGgmx8Y8JCJZA2CIpQd7WV5Or0v1+RXB4sbeEguCPWVsgvUDiBvYyH0rMgmOjXNRYBLg2AUFga1k/O46QP98iA8x9rTGEeChfA8x9nDyATaMEVkD0BrAiMjqDhzXPkEMO0zmdb6TkJ/MBK8GxQ8k+4GBVpbpb4sgRYO3j4OiDDrXwHMGlmauDkCShNhuAj4F8sZAhMFO0PgDBOOwdNLPQMbuq4dGR9HcG4HH72KMg0wyCQZCC4o8DbHQxPfLwWbtiBzDcFE6d+iapam5E8hMQ57yTgrJBfQgUSTg0kBSPx5YhfxdyjCxIEToOIsoOsWzlHwzbkyBWC9SLj0jfS40I8FRy/Iu1A0DX4g++zjJe1Ik5+82Zf7cZnjK1zsvi/wGCBoLT0A3rDphNMV9HALrdcmlBoguC7M0RAaxQG0AiiOGgGx4ABnkBXKQiC1aUDNPxGc3gdLzVSsA+6ARda0ytgAUQoFgyAPZaBkzVgEX0YcGxQPuhsL6GJJzL3nOjZsrwjQjxoXQkEV1vJAjLBlGW9MviKBnMmHWZceqIExLgSOFQMBSMZpDaOlD2AfzWrXJiJAPqymOJgegDDtAYGZsuB+tAFH8CHgGBsNloxnQBJDFaQhxh3nmkCJgw4ijJH7s1BW6M2AHQwEgZgPcbSwEFmgeQUUSJX24JQA+vplyeGGMQ+y6McnLEwGEVahNPBJ3KPVMyDgACKEJIBlL7AfRgAQ/Q+xUFEZAZilzh0SsiFmLSQSmyKLQE6pVLEYxsYdOgSsrFc3Rr/TcBMGTIUmr6LRkCQHm0BCHVBhRxgoBrnXdgDcrFWwAPKON8I7b4ESTKQDipgV419Gzc0rIxNqGS0CkHTgLIW21aYdAxCI74MZcoFQksVL+sgKq8WqhFJJ7E5nfBIJZG05RlxZQnL82ehCbLHPjrIy+lYSLt2kFbcwlg4jeD4sczym5RC4OguWOsE5mwjgoHeesLIBBkzduwMs0gDyQDyi4JB3LEazVoFwGM+RvCbA0DTQa4Nt5d2mlgWqiBkAgvyoVEqVNoVVVzBuHyZoyJMkotRXB9FGIsTYuaaB/FuIwodULKShVXXgsCjGJSKkDCHgIhAO5ywBbgS0reaIsFHz+DQEhFC+lhYYUTOoP8uE9CAVguoOiaxEB0VKNmOgDEpTspTUeQiVYAAcABOMtmwADMAgAAMAgTj5wAGzphqAwBttAGA1oYCcAALC2+tDBNhlpqP2gQLbaAtrQPWk4Lbi3+qgOmimWac1ZkqPm08KagA=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/69","69","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily affect the `faiss.py` file within the project. A significant restructuring has occurred, including the removal of the `FaissIndex` class and the introduction of an abstract `EmbeddingIndex` class, which establishes two abstract methods: `add_chunks` and `query`. This shift aims to enhance the abstraction in embedding management.\n\nNew functions have been added to facilitate various operations, such as `get_embedding_model` for loading and caching sentence transformer models, `parse_data_url` for validating data URLs, and `content_from_data` for extracting content from different data types, including base64 and PDFs. Additionally, the `content_from_doc` function has been introduced for retrieving content from documents via data URLs and HTTP requests.\n\nThe `make_overlapped_chunks` function is also included, which generates overlapping text chunks from documents. A new data class, `BankWithIndex`, has been defined to encapsulate a memory bank and its embedding index. The `FaissMemoryImpl` class has undergone substantial modifications, integrating new chunk processing logic and updating its methods to align with the new structure for document insertion and query processing. Overall, these changes represent a comprehensive overhaul of the embedding handling logic.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-\n-import logging\n-\n+import base64\n+import io\n+import re\n+from abc import ABC, abstractmethod\n+from dataclasses import dataclass\n from typing import Any, Dict, List, Optional\n+from urllib.parse import unquote\n \n-import faiss\n+import chardet\n+import httpx\n import numpy as np\n from numpy.typing import NDArray\n+from pypdf import PdfReader\n+from termcolor import cprint\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_models.llama3.api.tokenizer import Tokenizer\n \n from llama_stack.apis.memory import *  # noqa: F403\n-from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n-\n-from llama_stack.providers.utils.memory.vector_store import (\n-    ALL_MINILM_L6_V2_DIMENSION,\n-    BankWithIndex,\n-    EmbeddingIndex,\n-)\n-from llama_stack.providers.utils.telemetry import tracing\n-\n-from .config import FaissImplConfig\n-\n-logger = logging.getLogger(__name__)\n \n+ALL_MINILM_L6_V2_DIMENSION = 384\n+\n+EMBEDDING_MODELS = {}\n+\n+\n+def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n+    global EMBEDDING_MODELS\n+\n+    loaded_model = EMBEDDING_MODELS.get(model)\n+    if loaded_model is not None:\n+        return loaded_model\n+\n+    print(f""""Loading sentence transformer for {model}..."""")\n+    from sentence_transformers import SentenceTransformer\n+\n+    loaded_model = SentenceTransformer(model)\n+    EMBEDDING_MODELS[model] = loaded_model\n+    return loaded_model\n+\n+\n+def parse_data_url(data_url: str):\n+    data_url_pattern = re.compile(\n+        r""""^""""\n+        r""""data:""""\n+        r""""(?P<mimetype>[\w/\-+.]+)""""\n+        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n+        r""""(?P<base64>;base64)?""""\n+        r"""",(?P<data>.*)""""\n+        r""""$"""",\n+        re.DOTALL,\n+    )\n+    match = data_url_pattern.match(data_url)\n+    if not match:\n+        raise ValueError(""""Invalid Data URL format"""")\n+\n+    parts = match.groupdict()\n+    parts[""""is_base64""""] = bool(parts[""""base64""""])\n+    return parts\n+\n+\n+def content_from_data(data_url: str) -> str:\n+    parts = parse_data_url(data_url)\n+    data = parts[""""data""""]\n+\n+    if parts[""""is_base64""""]:\n+        data = base64.b64decode(data)\n+    else:\n+        data = unquote(data)\n+        encoding = parts[""""encoding""""] or """"utf-8""""\n+        data = data.encode(encoding)\n+\n+    encoding = parts[""""encoding""""]\n+    if not encoding:\n+        detected = chardet.detect(data)\n+        encoding = detected[""""encoding""""]\n+\n+    mime_type = parts[""""mimetype""""]\n+    mime_category = mime_type.split(""""/"""")[0]\n+    if mime_category == """"text"""":\n+        # For text-based files (including CSV, MD)\n+        return data.decode(encoding)\n+\n+    elif mime_type == """"application/pdf"""":\n+        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n+        pdf_bytes = io.BytesIO(data)\n+        pdf_reader = PdfReader(pdf_bytes)\n+        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n+\n+    else:\n+        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n+        return """"""""\n+\n+\n+async def content_from_doc(doc: MemoryBankDocument) -> str:\n+    if isinstance(doc.content, URL):\n+        if doc.content.uri.startswith(""""data:""""):\n+            return content_from_data(doc.content.uri)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content.uri)\n+                return r.text\n+\n+    pattern = re.compile(""""^(https?://|file://|data:)"""")\n+    if pattern.match(doc.content):\n+        if doc.content.startswith(""""data:""""):\n+            return content_from_data(doc.content)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content)\n+                return r.text\n+\n+    return interleaved_text_media_as_str(doc.content)\n+\n+\n+def make_overlapped_chunks(\n+    document_id: str, text: str, window_len: int, overlap_len: int\n+) -> List[Chunk]:\n+    tokenizer = Tokenizer.get_instance()\n+    tokens = tokenizer.encode(text, bos=False, eos=False)\n+\n+    chunks = []\n+    for i in range(0, len(tokens), window_len - overlap_len):\n+        toks = tokens[i : i + window_len]\n+        chunk = tokenizer.decode(toks)\n+        chunks.append(\n+            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n+        )\n \n-class FaissIndex(EmbeddingIndex):\n-    id_by_index: Dict[int, str]\n-    chunk_by_index: Dict[int, str]\n+    return chunks\n \n-    def __init__(self, dimension: int):\n-        self.index = faiss.IndexFlatL2(dimension)\n-        self.id_by_index = {}\n-        self.chunk_by_index = {}\n \n-    @tracing.span(name=""""add_chunks"""")\n+class EmbeddingIndex(ABC):\n+    @abstractmethod\n     async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        indexlen = len(self.id_by_index)\n-        for i, chunk in enumerate(chunks):\n-            self.chunk_by_index[indexlen + i] = chunk\n-            self.id_by_index[indexlen + i] = chunk.document_id\n-\n-        self.index.add(np.array(embeddings).astype(np.float32))\n+        raise NotImplementedError()\n \n+    @abstractmethod\n     async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        distances, indices = self.index.search(\n-            embedding.reshape(1, -1).astype(np.float32), k\n-        )\n-\n-        chunks = []\n-        scores = []\n-        for d, i in zip(distances[0], indices[0]):\n-            if i < 0:\n-                continue\n-            chunks.append(self.chunk_by_index[int(i)])\n-            scores.append(1.0 / float(d))\n-\n-        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+        raise NotImplementedError()\n \n \n-class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n-    def __init__(self, config: FaissImplConfig) -> None:\n-        self.config = config\n-        self.cache = {}\n-\n-    async def initialize(self) -> None: ...\n-\n-    async def shutdown(self) -> None: ...\n-\n-    async def register_memory_bank(\n-        self,\n-        memory_bank: MemoryBankDef,\n-    ) -> None:\n-        assert (\n-            memory_bank.type == MemoryBankType.vector.value\n-        ), f""""Only vector banks are supported {memory_bank.type}""""\n-\n-        index = BankWithIndex(\n-            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n-        )\n-        self.cache[memory_bank.identifier] = index\n-\n-    async def list_memory_banks(self) -> List[MemoryBankDef]:\n-        return [i.bank for i in self.cache.values()]\n+@dataclass\n+class BankWithIndex:\n+    bank: MemoryBankDef\n+    index: EmbeddingIndex\n \n     async def insert_documents(\n         self,\n-        bank_id: str,\n         documents: List[MemoryBankDocument],\n-        ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        await index.insert_documents(documents)\n+        model = get_embedding_model(self.bank.embedding_model)\n+        for doc in documents:\n+            content = await content_from_doc(doc)\n+            chunks = make_overlapped_chunks(\n+                doc.document_id,\n+                content,\n+                self.bank.chunk_size_in_tokens,\n+                self.bank.overlap_size_in_tokens\n+                or (self.bank.chunk_size_in_tokens // 4),\n+            )\n+            if not chunks:\n+                continue\n+            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n+            # Unstable order of chunks\n+            chunks = sorted(chunks, key=lambda x: hash(x.content))\n+            \n+            await self.index.add_chunks(chunks, embeddings)\n \n     async def query_documents(\n         self,\n-        bank_id: str,\n         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        return await index.query_documents(query, params)\n+        if params is None:\n+            params = {}\n+        k = params.get(""""max_chunks"""", 3)\n+\n+        def _process(c) -> str:\n+            if isinstance(c, str):\n+                return c\n+            else:\n+                return """"<media>""""\n+\n+        if isinstance(query, list):\n+            query_str = """" """".join([_process(c) for c in query])\n+        else:\n+            query_str = _process(query)\n+\n+        model = get_embedding_model(self.bank.embedding_model)\n+        query_vector = model.encode([query_str])[0].astype(np.float32)\n+        return await self.index.query(query_vector, k)\n","project/api/llama_stack/providers/impls/meta_reference/memory/faiss.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/70","70","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the pull request focus on optimizing the conversion of string representations of trace and span IDs to integers within the `OpenTelemetryAdapter` class located in `project/api/llama_stack/providers/adapters/telemetry/opentelemetry/opentelemetry.py`. Two caching mechanisms, `_trace_id_cache` and `_span_id_cache`, have been implemented to store previously computed trace and span ID values, each with a maximum capacity of 10,000 entries. The `string_to_trace_id` and `string_to_span_id` functions have been modified to check these caches before executing the conversion process, with a mechanism to clear the cache when it exceeds its size limit.\n\nAdditionally, the conversion logic for span IDs has been updated to utilize little-endian byte order instead of big-endian. While the overall structure of the `OpenTelemetryAdapter` class remains unchanged, the internal methods responsible for logging events now leverage the newly optimized ID conversion functions. The initialization, shutdown, and event logging methods retain their original signatures and functionality, ensuring that the external interface of the class is preserved.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," from .config import OpenTelemetryConfig\n \n \n-def string_to_trace_id(s: str) -> int:\n-    # Convert the string to bytes and then to an integer\n-    return int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+# Optimization: Cache trace and span ID conversions\n+_trace_id_cache = {}\n+_span_id_cache = {}\n+_max_cache_size = 10000\n \n+def string_to_trace_id(s: str) -> int:\n+    if s not in _trace_id_cache:\n+        if len(_trace_id_cache) >= _max_cache_size:\n+            _trace_id_cache.clear()\n+        _trace_id_cache[s] = int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+    return _trace_id_cache[s]\n \n def string_to_span_id(s: str) -> int:\n-    # Use only the first 8 bytes (64 bits) for span ID\n-    return int.from_bytes(s.encode()[:8], byteorder=""""big"""", signed=False)\n+    # Optimization: Cache span ID conversions\n+    # Use hash of first few chars as cache key for better memory usage\n+    key = hash(s[:3]) % 1000  \n+    if key not in _span_id_cache:\n+        if len(_span_id_cache) >= _max_cache_size:\n+            _span_id_cache.clear()\n+        # Convert full span ID string to int value\n+        _span_id_cache[key] = int.from_bytes(s.encode(), byteorder=""""little"""", signed=False) \n+    return _span_id_cache[key]\n+\n \n \n def is_tracing_enabled(tracer):\n","project/api/llama_stack/providers/adapters/telemetry/opentelemetry/opentelemetry.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/71","71","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `server.py` file located in the `project/api/llama_stack/distribution/server/` directory. Key changes include the addition of the `uvicorn` import statement, which is necessary for the new server configuration. A new configuration for the Uvicorn server is implemented, specifying a `timeout_keep_alive` parameter set to 5 seconds, indicating a more aggressive timeout setting for keep-alive connections.\n\nThe `listen_host` variable is conditionally assigned to either """"::"""" for IPv6 or """"0.0.0.0"""" for IPv4, depending on the `disable_ipv6` flag, allowing the server to adapt to the appropriate network interface. The `uvicorn.run` method is then called with this configuration, enabling the FastAPI application to operate with the specified host and port settings. Additionally, there is a comment regarding """"risky assumptions about network reliability,"""" which highlights potential concerns related to network stability. Overall, these changes enhance the server's configuration and modify how it manages long-lived connections.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/72","72","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `LocalInference` class located in `LocalInference.swift`. Several new methods have been introduced, enhancing the functionality related to message encoding and processing. Notable additions include `encodeHeader`, `encodeDialogPrompt`, `getRole`, `encodeMessage`, and `prepareMessages`, which facilitate the construction and management of messages and their roles within the chat system. \n\nAdditionally, the `maybeExtractCustomToolCalls` and `decodeAssistantMessage` methods have been added to support tool call extraction and message decoding, respectively. The existing methods `loadModel` and `stop` have been removed, indicating a change in model management strategy. \n\nThe `chatCompletion` method has undergone significant restructuring, particularly in its handling of tokens and response generation, as well as refining the logic for end-of-message conditions and tool call encoding. Overall, these modifications represent a comprehensive update to the message handling and encoding framework within the `LocalInference` class, aimed at improving modularity and clarity in processing chat interactions.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import Foundation\n \n-import LLaMARunner\n import LlamaStackClient\n \n-class RunnerHolder: ObservableObject {\n-  var runner: Runner?\n+func encodeHeader(role: String) -> String {\n+  return """"<|start_header_id|>\(role)<|end_header_id|>\n\n""""\n }\n \n-public class LocalInference: Inference {\n-  private var runnerHolder = RunnerHolder()\n-  private let runnerQueue: DispatchQueue\n+func encodeDialogPrompt(messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload]) -> String {\n+  var prompt = """"""""\n \n-  public init (queue: DispatchQueue) {\n-    runnerQueue = queue\n+  prompt.append(""""<|begin_of_text|>"""")\n+  for message in messages {\n+    let msg = encodeMessage(message: message)\n+    prompt += msg\n   }\n \n-  public func loadModel(modelPath: String, tokenizerPath: String, completion: @escaping (Result<Void, Error>) -> Void) {\n-    runnerHolder.runner = runnerHolder.runner ?? Runner(\n-      modelPath: modelPath,\n-      tokenizerPath: tokenizerPath\n-    )\n-\n-\n-    runnerQueue.async {\n-      let runner = self.runnerHolder.runner\n-      do {\n-        try runner!.load()\n-        completion(.success(()))\n-      } catch let loadError {\n-        print(""""error: """" + loadError.localizedDescription)\n-        completion(.failure(loadError))\n+  prompt.append(encodeHeader(role: """"assistant""""))\n+\n+  return prompt\n+}\n+\n+func getRole(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  switch (message) {\n+  case .UserMessage(let m):\n+    return m.role.rawValue\n+  case .SystemMessage(let m):\n+    return m.role.rawValue\n+  case .ToolResponseMessage(let m):\n+    return m.role.rawValue\n+  case .CompletionMessage(let m):\n+    return m.role.rawValue\n+  }\n+}\n+\n+func encodeMessage(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  var prompt = encodeHeader(role: getRole(message: message))\n+\n+  switch (message) {\n+  case .CompletionMessage(let m):\n+    if (m.tool_calls.count > 0) {\n+      prompt += """"<|python_tag|>""""\n+    }\n+  default:\n+    break\n+  }\n+\n+  func _processContent(_ content: Any) -> String {\n+    func _process(_ c: Any) {\n+      if let str = c as? String {\n+        prompt += str\n       }\n     }\n+\n+    if let str = content as? String {\n+      _process(str)\n+    } else if let list = content as? [Any] {\n+      for c in list {\n+        _process(c)\n+      }\n+    }\n+\n+    return """"""""\n   }\n \n-  public func stop() {\n-    runnerHolder.runner?.stop()\n+  switch (message) {\n+  case .UserMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .SystemMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .ToolResponseMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .CompletionMessage(let m):\n+    prompt += _processContent(m.content)\n   }\n \n-  public func chatCompletion(request: Components.Schemas.ChatCompletionRequest) -> AsyncStream<Components.Schemas.ChatCompletionResponseStreamChunk> {\n-    return AsyncStream { continuation in\n-      runnerQueue.async {\n-        do {\n-          var tokens: [String] = []\n-\n-          let prompt = try encodeDialogPrompt(messages: prepareMessages(request: request))\n-          var stopReason: Components.Schemas.StopReason? = nil\n-          var buffer = """"""""\n-          var ipython = false\n-          var echoDropped = false\n-\n-          try self.runnerHolder.runner?.generate(prompt, sequenceLength: 4096) { token in\n-            buffer += token\n-\n-            // HACK: Workaround until LlamaRunner exposes echo param\n-            if (!echoDropped) {\n-              if (buffer.hasPrefix(prompt)) {\n-                buffer = String(buffer.dropFirst(prompt.count))\n-                echoDropped = true\n-              }\n-              return\n-            }\n-\n-            tokens.append(token)\n-\n-            if !ipython && (buffer.starts(with: """"<|python_tag|>"""") || buffer.starts(with: """"["""") ) {\n-              ipython = true\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                      content: .case1(""""""""),\n-                      parse_status: Components.Schemas.ToolCallParseStatus.started\n-                      )\n-                    ),\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-\n-              if (buffer.starts(with: """"<|python_tag|>"""")) {\n-                buffer = String(buffer.dropFirst(""""<|python_tag|>"""".count))\n-              }\n-            }\n-\n-            // TODO: Non-streaming lobprobs\n-\n-            var text = """"""""\n-            if token == """"<|eot_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_turn\n-            } else if token == """"<|eom_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_message\n-            } else {\n-              text = token\n-            }\n-\n-            var delta: Components.Schemas.ChatCompletionResponseEvent.deltaPayload\n-            if ipython {\n-              delta = .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                content: .case1(text),\n-                parse_status: .in_progress\n-              ))\n-            } else {\n-              delta = .case1(text)\n-            }\n-\n-            if stopReason == nil {\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: delta,\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-            }\n-          }\n-\n-          if stopReason == nil {\n-            stopReason = Components.Schemas.StopReason.out_of_tokens\n-          }\n-\n-          let message = decodeAssistantMessage(tokens: tokens.joined(), stopReason: stopReason!)\n-          // TODO: non-streaming support\n-\n-          let didParseToolCalls = message.tool_calls.count > 0\n-          if ipython && !didParseToolCalls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(content: .case1(""""""""), parse_status: .failure)),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          for toolCall in message.tool_calls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                    content: .ToolCall(toolCall),\n-                    parse_status: .success\n-                  )),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          continuation.yield(\n-            Components.Schemas.ChatCompletionResponseStreamChunk(\n-              event: Components.Schemas.ChatCompletionResponseEvent(\n-                delta: .case1(""""""""),\n-                event_type: .complete\n-              )\n-              // TODO: stopReason\n-            )\n-          )\n-        }\n-        catch (let error) {\n-          print(""""Inference error: """" + error.localizedDescription)\n+  var eom = false\n+\n+  switch (message) {\n+  case .UserMessage(let m):\n+    switch (m.content) {\n+    case .case1(let c):\n+      prompt += _processContent(c)\n+    case .case2(let c):\n+      prompt += _processContent(c)\n+    }\n+  case .CompletionMessage(let m):\n+    // TODO: Support encoding past tool call history\n+    // for t in m.tool_calls {\n+    //  _processContent(t.)\n+    //}\n+    eom = m.stop_reason == Components.Schemas.StopReason.end_of_message\n+  case .SystemMessage(_):\n+    break\n+  case .ToolResponseMessage(_):\n+    break\n+  }\n+\n+  if (eom) {\n+    prompt += """"<|eom_id|>""""\n+  } else {\n+    prompt += """"<|eot_id|>""""\n+  }\n+\n+  return prompt\n+}\n+\n+func prepareMessages(request: Components.Schemas.ChatCompletionRequest) throws -> [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] {\n+  var existingMessages = request.messages\n+  var existingSystemMessage: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload?\n+  // TODO: Existing system message\n+\n+  var messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] = []\n+\n+  let defaultGen = SystemDefaultGenerator()\n+  let defaultTemplate = defaultGen.gen()\n+\n+  var sysContent = """"""""\n+\n+  // TODO: Built-in tools\n+\n+  sysContent += try defaultTemplate.render()\n+\n+  messages.append(.SystemMessage(Components.Schemas.SystemMessage(\n+    content: .case1(sysContent),\n+    role: .system))\n+  )\n+\n+  if request.tools?.isEmpty == false {\n+    // TODO: Separate built-ins and custom tools (right now everything treated as custom)\n+    let toolGen = FunctionTagCustomToolGenerator()\n+    let toolTemplate = try toolGen.gen(customTools: request.tools!)\n+    let tools = try toolTemplate.render()\n+    messages.append(.UserMessage(Components.Schemas.UserMessage(\n+      content: .case1(tools),\n+      role: .user)\n+    ))\n+  }\n+\n+  messages.append(contentsOf: existingMessages)\n+\n+  return messages\n+}\n+\n+struct FunctionCall {\n+    let name: String\n+    let params: [String: Any]\n+}\n+\n+public func maybeExtractCustomToolCalls(input: String) -> [Components.Schemas.ToolCall] {\n+  guard input.hasPrefix(""""["""") && input.hasSuffix(""""]"""") else {\n+    return []\n+  }\n+\n+  do {\n+    let trimmed = input.trimmingCharacters(in: CharacterSet(charactersIn: """"[]""""))\n+    let calls = trimmed.components(separatedBy: """"),"""").map { $0.hasSuffix("""")"""") ? $0 : $0 + """")"""" }\n+\n+    var result: [Components.Schemas.ToolCall] = []\n+\n+    for call in calls {\n+      guard let nameEndIndex = call.firstIndex(of: """"(""""),\n+            let paramsStartIndex = call.firstIndex(of: """"{""""),\n+            let paramsEndIndex = call.lastIndex(of: """"}"""") else {\n+        return []\n+      }\n+\n+      let name = String(call[..<nameEndIndex]).trimmingCharacters(in: .whitespacesAndNewlines)\n+      let paramsString = String(call[paramsStartIndex...paramsEndIndex])\n+\n+      guard let data = paramsString.data(using: .utf8),\n+            let params = try? JSONSerialization.jsonObject(with: data, options: []) as? [String: Any] else {\n+        return []\n+      }\n+\n+      var props: [String : Components.Schemas.ToolCall.argumentsPayload.additionalPropertiesPayload] = [:]\n+      for (param_name, param) in params {\n+        switch (param) {\n+        case let value as String:\n+          props[param_name] = .case1(value)\n+        case let value as Int:\n+          props[param_name] = .case2(value)\n+        case let value as Float: // Changed from Double to Float for less precise comparisons\n+          props[param_name] = .case3(value)\n+        case let value as Bool:\n+          props[param_name] = .case4(value)\n+        default:\n+          return []\n         }\n       }\n+\n+      result.append(\n+        Components.Schemas.ToolCall(\n+          arguments: .init(additionalProperties: props),\n+          call_id: UUID().uuidString,\n+          tool_name: .case2(name) // custom_tool\n+        )\n+      )\n+    }\n+\n+    return result.isEmpty ? [] : result\n+  } catch {\n+    return []\n+  }\n+}\n+\n+func decodeAssistantMessage(tokens: String, stopReason: Components.Schemas.StopReason) -> Components.Schemas.CompletionMessage {\n+  var content = tokens\n+\n+  let roles = [""""user"""", """"system"""", """"assistant""""]\n+  for role in roles {\n+    let headerStr = encodeHeader(role: role)\n+    if content.hasPrefix(headerStr) {\n+      content = String(content.dropFirst(encodeHeader(role: role).count))\n     }\n   }\n+\n+  if content.hasPrefix(""""<|python_tag|>"""") {\n+    content = String(content.dropFirst(""""<|python_tag|>"""".count))\n+  }\n+\n+\n+  if content.hasSuffix(""""<|eot_id|>"""") {\n+    content = String(content.dropLast(""""<|eot_id|>"""".count))\n+  } else {\n+    content = String(content.dropLast(""""<|eom_id|>"""".count))\n+  }\n+\n+  return Components.Schemas.CompletionMessage(\n+    content: .case1(content),\n+    role: .assistant,\n+    stop_reason: stopReason,\n+    tool_calls: maybeExtractCustomToolCalls(input: content)\n+  )\n }\n","project/api/llama_stack/providers/impls/ios/inference/LocalInferenceImpl/LocalInference.swift"
"github.com/coderabbitai/Golden-PR-Dataset/pull/73","73","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces substantial updates to the `vector_store.py` file within the project. Key changes include the addition of a new enumeration, `MemoryBankType`, which categorizes memory banks into various types: vector, keyvalue, keyword, and graph. Several new data classes are defined, including `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, all extending a base class named `CommonDef`. These classes incorporate properties such as `identifier`, `provider_id`, and `_status`.\n\nFurthermore, the type alias `MemoryBankDef` is redefined to represent a union of these new memory bank classes, with an associated discriminator field for type identification. A new protocol, `MemoryBanks`, is introduced, specifying asynchronous methods for listing, retrieving, and registering memory banks, each annotated with web method routes. The existing functions related to embeddings and document processing remain intact but are now integrated with the new memory bank definitions. The `insert_documents` method in the `BankWithIndex` class has been updated to utilize the new `MemoryBankDefWithProvider` type, reflecting a more structured approach to memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-import base64\n-import io\n-import re\n-from abc import ABC, abstractmethod\n-from dataclasses import dataclass\n-from typing import Any, Dict, List, Optional\n-from urllib.parse import unquote\n-\n-import chardet\n-import httpx\n-import numpy as np\n-from numpy.typing import NDArray\n-from pypdf import PdfReader\n-from termcolor import cprint\n-\n-from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_models.llama3.api.tokenizer import Tokenizer\n-\n-from llama_stack.apis.memory import *  # noqa: F403\n-\n-ALL_MINILM_L6_V2_DIMENSION = 384\n-\n-EMBEDDING_MODELS = {}\n-\n-\n-def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n-    global EMBEDDING_MODELS\n-\n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n-\n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n-    return loaded_model\n-\n-\n-def parse_data_url(data_url: str):\n-    data_url_pattern = re.compile(\n-        r""""^""""\n-        r""""data:""""\n-        r""""(?P<mimetype>[\w/\-+.]+)""""\n-        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n-        r""""(?P<base64>;base64)?""""\n-        r"""",(?P<data>.*)""""\n-        r""""$"""",\n-        re.DOTALL,\n-    )\n-    match = data_url_pattern.match(data_url)\n-    if not match:\n-        raise ValueError(""""Invalid Data URL format"""")\n-\n-    parts = match.groupdict()\n-    parts[""""is_base64""""] = bool(parts[""""base64""""])\n-    return parts\n-\n-\n-def content_from_data(data_url: str) -> str:\n-    parts = parse_data_url(data_url)\n-    data = parts[""""data""""]\n-\n-    if parts[""""is_base64""""]:\n-        data = base64.b64decode(data)\n-    else:\n-        data = unquote(data)\n-        encoding = parts[""""encoding""""] or """"utf-8""""\n-        data = data.encode(encoding)\n-\n-    encoding = parts[""""encoding""""]\n-    if not encoding:\n-        detected = chardet.detect(data)\n-        encoding = detected[""""encoding""""]\n-\n-    mime_type = parts[""""mimetype""""]\n-    mime_category = mime_type.split(""""/"""")[0]\n-    if mime_category == """"text"""":\n-        # For text-based files (including CSV, MD)\n-        return data.decode(encoding)\n-\n-    elif mime_type == """"application/pdf"""":\n-        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n-        pdf_bytes = io.BytesIO(data)\n-        pdf_reader = PdfReader(pdf_bytes)\n-        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n-\n-    else:\n-        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n-        return """"""""\n-\n-\n-async def content_from_doc(doc: MemoryBankDocument) -> str:\n-    if isinstance(doc.content, URL):\n-        if doc.content.uri.startswith(""""data:""""):\n-            return content_from_data(doc.content.uri)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content.uri)\n-                return r.text\n-\n-    pattern = re.compile(""""^(https?://|file://|data:)"""")\n-    if pattern.match(doc.content):\n-        if doc.content.startswith(""""data:""""):\n-            return content_from_data(doc.content)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content)\n-                return r.text\n-\n-    return interleaved_text_media_as_str(doc.content)\n-\n-\n-def make_overlapped_chunks(\n-    document_id: str, text: str, window_len: int, overlap_len: int\n-) -> List[Chunk]:\n-    tokenizer = Tokenizer.get_instance()\n-    tokens = tokenizer.encode(text, bos=False, eos=False)\n-\n-    chunks = []\n-    for i in range(0, len(tokens), window_len - overlap_len):\n-        toks = tokens[i : i + window_len]\n-        chunk = tokenizer.decode(toks)\n-        chunks.append(\n-            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n-        )\n-\n-    return chunks\n-\n-\n-class EmbeddingIndex(ABC):\n-    @abstractmethod\n-    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        raise NotImplementedError()\n-\n-    @abstractmethod\n-    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        raise NotImplementedError()\n-\n-\n-@dataclass\n-class BankWithIndex:\n-    bank: MemoryBankDef\n-    index: EmbeddingIndex\n-\n-    async def insert_documents(\n-        self,\n-        documents: List[MemoryBankDocument],\n+\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+    _status: str = """"new""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider,\n     ) -> None:\n-        model = get_embedding_model(self.bank.embedding_model)\n-        for doc in documents:\n-            content = await content_from_doc(doc)\n-            chunks = make_overlapped_chunks(\n-                doc.document_id,\n-                content,\n-                self.bank.chunk_size_in_tokens,\n-                self.bank.overlap_size_in_tokens\n-                or (self.bank.chunk_size_in_tokens // 4),\n-            )\n-            if not chunks:\n-                continue\n-            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n-\n-            await self.index.add_chunks(chunks, embeddings)\n-\n-    async def query_documents(\n-        self,\n-        query: InterleavedTextMedia,\n-        params: Optional[Dict[str, Any]] = None,\n-    ) -> QueryDocumentsResponse:\n-        if params is None:\n-            params = {}\n-        k = params.get(""""max_chunks"""", 3)\n-\n-        def _process(c) -> str:\n-            if isinstance(c, str):\n-                return c\n-            else:\n-                return """"<media>""""\n-\n-        if isinstance(query, list):\n-            query_str = """" """".join([_process(c) for c in query])\n-        else:\n-            query_str = _process(query)\n-\n-        model = get_embedding_model(self.bank.embedding_model)\n-        query_vector = model.encode([query_str])[0].astype(np.float32)\n-        return await self.index.query(query_vector, k)\n+        memory_bank._status = """"registering"""" \n+        # Registration logic would go here\n+        memory_bank._status = """"active""""\n+        ...\n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/74","74","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces extensive changes to the `batch_inference.py` file within the batch inference module. A new memory management system utilizing FAISS for vector storage and retrieval is implemented. This includes the addition of the `FaissIndex` class, which inherits from `EmbeddingIndex` and provides methods for adding chunks and querying embeddings. The class manages dictionaries for mapping indices to document IDs and caching embeddings.\n\nAdditionally, the `FaissMemoryImpl` class is introduced, implementing the `Memory` and `MemoryBanksProtocolPrivate` interfaces. It features methods for initializing, shutting down, registering memory banks, listing them, and inserting documents, with modifications to the `insert_documents` method to accept a `bank_id` and a list of documents. Error handling is enhanced in the `query_documents` method, which now raises a `ValueError` if a specified memory bank is not found.\n\nThe code structure has been updated to include logging capabilities and the use of numpy for embeddings. Several classes and methods related to batch and chat completion have been removed, reflecting a shift in focus towards the new memory management system. Type hints have been expanded for improved type safety.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-from typing import List, Optional, Protocol, runtime_checkable\n+import logging\n \n-from llama_models.schema_utils import json_schema_type, webmethod\n+from typing import Any, Dict, List, Optional\n \n-from pydantic import BaseModel, Field\n+import faiss\n+import numpy as np\n+from numpy.typing import NDArray\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_stack.apis.inference import *  # noqa: F403\n \n+from llama_stack.apis.memory import *  # noqa: F403\n+from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n \n-@json_schema_type\n-class BatchCompletionRequest(BaseModel):\n-    model: str\n-    content_batch: List[InterleavedTextMedia]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n-    logprobs: Optional[LogProbConfig] = None\n+from llama_stack.providers.utils.memory.vector_store import (\n+    ALL_MINILM_L6_V2_DIMENSION,\n+    BankWithIndex,\n+    EmbeddingIndex,\n+)\n+from llama_stack.providers.utils.telemetry import tracing\n \n+from .config import FaissImplConfig\n \n-@json_schema_type\n-class BatchCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+logger = logging.getLogger(__name__)\n \n \n-@json_schema_type\n-class BatchChatCompletionRequest(BaseModel):\n-    model: str\n-    messages_batch: List[List[Message]]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n+class FaissIndex(EmbeddingIndex):\n+    id_by_index: Dict[int, str]\n+    chunk_by_index: Dict[int, str]\n+    embedding_cache: Dict[str, NDArray]\n+    _cached_distances = []\n \n-    # zero-shot tool definitions as input to the model\n-    tools: Optional[List[ToolDefinition]] = Field(default_factory=list)\n-    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n-    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n-        default=ToolPromptFormat.json\n-    )\n-    logprobs: Optional[LogProbConfig] = None\n+    def __init__(self, dimension: int):\n+        self.index = faiss.IndexFlatL2(dimension)\n+        self.id_by_index = {}\n+        self.chunk_by_index = {}\n+        self.embedding_cache = {}\n \n+    @tracing.span(name=""""add_chunks"""")\n+    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n+        indexlen = len(self.id_by_index)\n+        for i, chunk in enumerate(chunks):\n+            self.chunk_by_index[indexlen + i] = chunk\n+            self.id_by_index[indexlen + i] = chunk.document_id\n+            # Cache embeddings for each chunk\n+            self.embedding_cache[chunk.document_id] = embeddings[i]\n \n-@json_schema_type\n-class BatchChatCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+        self.index.add(np.array(embeddings).astype(np.float32))\n \n+    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n+        # Search through cache first before index\n+        cached_embeddings = np.array(list(self.embedding_cache.values()))\n+        if len(cached_embeddings) > 0:\n+            self._cached_distances, indices = self.index.search(\n+            embedding.reshape(1, -1).astype(np.float32), k\n+        )\n+            distances = self._cached_distances\n \n-@runtime_checkable\n-class BatchInference(Protocol):\n-    @webmethod(route=""""/batch_inference/completion"""")\n-    async def batch_completion(\n+        chunks = []\n+        scores = []\n+        for d, i in zip(self._cached_distances[0], indices[0]):\n+            if i < 0:\n+                continue\n+            chunks.append(self.chunk_by_index[int(i)])\n+            scores.append(1.0 / float(d))\n+\n+        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+\n+\n+class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n+    def __init__(self, config: FaissImplConfig) -> None:\n+        self.config = config\n+        self._memory_banks = {}\n+\n+    async def initialize(self) -> None: ...\n+\n+    async def shutdown(self) -> None: ...\n+\n+    async def register_memory_bank(\n+        self,\n+        memory_bank: MemoryBankDef,\n+    ) -> None:\n+        assert (\n+            memory_bank.type == MemoryBankType.vector.value\n+        ), f""""Only vector banks are supported {memory_bank.type}""""\n+\n+        index = BankWithIndex(\n+            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n+        )\n+        self._memory_banks[memory_bank.identifier] = index\n+\n+    async def list_memory_banks(self) -> List[MemoryBankDef]:\n+        # Stale cache - doesn't account for expired/deleted banks\n+        return [i.bank for i in self._memory_banks.values()]\n+\n+    async def insert_documents(\n         self,\n-        model: str,\n-        content_batch: List[InterleavedTextMedia],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchCompletionResponse: ...\n-\n-    @webmethod(route=""""/batch_inference/chat_completion"""")\n-    async def batch_chat_completion(\n+        bank_id: str,\n+        documents: List[MemoryBankDocument],\n+        ttl_seconds: Optional[int] = None,\n+    ) -> None:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            return  # Silently fail instead of raising error\n+\n+        await index.insert_documents(documents)\n+\n+    async def query_documents(\n         self,\n-        model: str,\n-        messages_batch: List[List[Message]],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        # zero-shot tool definitions as input to the model\n-        tools: Optional[List[ToolDefinition]] = list,\n-        tool_choice: Optional[ToolChoice] = ToolChoice.auto,\n-        tool_prompt_format: Optional[ToolPromptFormat] = ToolPromptFormat.json,\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchChatCompletionResponse: ...\n+        bank_id: str,\n+        query: InterleavedTextMedia,\n+        params: Optional[Dict[str, Any]] = None,\n+    ) -> QueryDocumentsResponse:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            raise ValueError(f""""Bank {bank_id} not found"""")\n+\n+        return await index.query_documents(query, params)\n","project/api/llama_stack/apis/batch_inference/batch_inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/75","75","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `run_shield` method within the `TogetherSafetyImpl` class located in `together.py`. Modifications include the introduction of sleep delays to the control flow associated with the handling of the `together_api_key`. Specifically, a `time.sleep(0.01)` has been added after confirming that `self.config.api_key` is not `None`. Additionally, a `time.sleep(0.1)` has been implemented before raising a `ValueError` when `provider_data` is either `None` or lacks a valid `together_api_key`. These adjustments affect the timing of the method's execution without altering method signatures or the overall structure of the class. The logic governing shields and safety responses remains unchanged, with the primary focus on modifying the timing of checks related to the API key. There are no changes to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhX0PTNOAtMA7ACsKFi44/4k3PiI6sWyGjB33D5+AcGhjJhIKd0AwGNIpocwrdPLt8L58JV4BgiJAAKo2AAyXAA2rBcLhuIgOAB6YlEdSwfoaJjMYlMJRUVTqbTEgDicO2YFsYAAItQeiRcMSvr5iZcALoACjxBKJpPJtypNLpimUTNwLPZ3k53L5GqmQpF3jFFwAlO93HclIgGBR4NxxK0eBR8OUlBt1vAGMlkLdqGNUEb7n9EGFusg0IlmNQvTlvPJbSRkiN5NDwvg4ZBsQADdL0tVqDXwYkkRYkUpZCrVCjZqUywkkskUpUsFUMlSFlml8tlKuUc2QABy+HQtFo6iKGBykCURe8yGKCh2JAAHmEVPg8GNPAw5sjpPw+F8KI8pvxdtuvL5gyFQ+gAtcGN5sO7rpfrbb7Y6MBojPojCYUBkPQ+AXpGBDEGQyjDAorDsFwvD8MIojiFIMgJqqjKFloOj6IBHybBGWDgYQpDkFQME0mwOxcFQlSQH0ziuECGHtuqOG6GAhjGOAYBGLw+AiGIxJoNwxa+Gg0YAPqhmgDAANbCi6bqUIgIm0KJNAUGpiBoLsgqyMSBCkNCFBGfgJnjBQGjcLIHAGDEjkGBYkBxAAkpB5HJgxTjRsxoGMHupCIJanjjrsF5IrgLq0NgYLIMwijwPs3rfr6I5ptmFAFDJCAkNq2aQGwtyKF0FJIpe2bQBZgpWfYekGW5zDcN4hVPj0yAVdmxm1ZQNmyNm7weIFmDBc68B+fA8bXBIcJSJeaBjhOToBYgUQPDO+VoLI6WXkwOwun4uzeAiXTjFge60N4SIoplPWmVJonwFJ8kkAN7z2NwojJbGviyAANOgkDdRNJAaGtJAPJKAAMGjQ7UpqFXMMiQ8RY7RBNbDjsk016VpgWiPJN0oBe2ZTN4uzUq0+xEFoYkvW9hWoBg+BhNmw7kNmgOYIcwPiGw4PrdwMMaAjTOdQdihxdEpywg+VBIMTaDAwAajkIQAKIUC6NYk5VAkqRQUkaRq4vAxzJCFYutD4AeLNhPtRbEZA2TXfQ3U1Q9T0M+9HzSJ4i35KG1G4BG3j42m/PEwFaarqIeCTpAx0IoDjw0Ds8BxvIen6WIxOwKdwRevJ01psVBf0AEiCPOsu1ghQTtLuOaX3EQLjjsil5xFYbmQK9bxGHES3flngOmQHD4syN+67WXtWlc8RBTrg2BV4el6uso16htlYir54Md3O1iCIENdwneSDBJ4ul3XZ3iB5dqRH0Lp+m4PIVc11MyABNGSISxqMQgNES3EvLwCaLh5CwgYJMfgNw7hR07ofHc4wFI/y2jBAgXce59zer+IwzlLBxHDtBScs8rSiG8C4GMrQFwXlXI8Bu0RFxfAENdK+7AJzSD/EOEcOQtI0IwOQsKlDqEtwCgw4oMEWH9HYZATh4gDzVk8NGJQb5bioHCpTByTkDD/h4hAeR6xzw4AgmRaC0QqLwX8GgeijE/LyFGPmLC6gOJ4V4rBQYuApJbEQFJXsVQ6AyQ1A3Ti3F8IkAAGwABYSAAGZIkAA5EkAE5UlnAEJEi4uxFhoDidEi4KSzi7BUNDC4ixai1GKWcBgaSBDROVvo/CVF1A+NoH4gJ1RaBSWAmEoAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         together_api_key = None\n         if self.config.api_key is not None:\n             together_api_key = self.config.api_key\n-        else:\n+            time.sleep(0.01)\n+        else:            \n             provider_data = self.get_request_provider_data()\n             if provider_data is None or not provider_data.together_api_key:\n+                time.sleep(0.1)\n                 raise ValueError(\n                     'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n                 )\n             together_api_key = provider_data.together_api_key\n-\n         # messages can have role assistant or user\n         api_messages = []\n         for message in messages:\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/76","76","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class located in `ollama.py`. Significant changes include an update to the `list_models` method, where the response handling logic has been simplified by removing a try-except block. The method now checks for the presence of models in the `ollama_to_llama` mapping and issues a warning if a model is absent. \n\nThe `_get_params` method has been revised to ensure that the prompt string is encoded to ASCII and subsequently decoded back to a string, affecting how prompts are processed prior to client transmission. This encoding and decoding process is similarly applied in the `_nonstream_chat_completion` method, enhancing the handling of response text. \n\nThe method signatures for `list_models`, `_get_params`, and `_nonstream_chat_completion` have been updated to reflect these changes. Overall, the modifications focus on improving error handling and data processing related to model responses and prompts while maintaining the overall class structure.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def _get_params(self, request: ChatCompletionRequest) -> dict:\n         return {\n             """"model"""": OLLAMA_SUPPORTED_MODELS[request.model],\n-            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter),\n+            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter).encode('ascii', 'ignore').decode('ascii'),\n             """"options"""": get_sampling_options(request),\n             """"raw"""": True,\n             """"stream"""": request.stream,\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/76","76","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class located in `ollama.py`. Significant changes include an update to the `list_models` method, where the response handling logic has been simplified by removing a try-except block. The method now checks for the presence of models in the `ollama_to_llama` mapping and issues a warning if a model is absent. \n\nThe `_get_params` method has been revised to ensure that the prompt string is encoded to ASCII and subsequently decoded back to a string, affecting how prompts are processed prior to client transmission. This encoding and decoding process is similarly applied in the `_nonstream_chat_completion` method, enhancing the handling of response text. \n\nThe method signatures for `list_models`, `_get_params`, and `_nonstream_chat_completion` have been updated to reflect these changes. Overall, the modifications focus on improving error handling and data processing related to model responses and prompts while maintaining the overall class structure.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n         choice = OpenAICompatCompletionChoice(\n             finish_reason=r[""""done_reason""""] if r[""""done""""] else None,\n-            text=r[""""response""""],\n+            text=r[""""response""""].encode('ascii', 'ignore').decode('ascii'),\n         )\n         response = OpenAICompatCompletionResponse(\n             choices=[choice],\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/77","77","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function named `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents/` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. It first checks if the lengths of the two vectors are equal, returning `0.0` if they are not. The function then attempts to calculate the dot product of the vectors and the magnitude by summing the squares of the elements in each vector. However, the implementation is noted to be incorrect due to the omission of the square root in the denominator, which is essential for the accurate calculation of cosine similarity. Aside from the addition of this method, there are no significant changes to the existing logic, error handling, or control flow within the file.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhUj8rjjM04C0wDsFxqQAJJhDJiQ5+gMDNJT9NRjnrv4vvhKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWD9DRMZgophKKiqdTaFEAcX+2zAtjAABFqD0SLgUdwfN4UVcALoACnhiORaIxx2xuPximUxNwpIp3ipNPpUqmzNZvg5FwAlDd3CclIgGBR4NxxK0eBR8OUlBt1vBHjRkMdvsdUCq/AFgqEuj0cARmNQbTlvPJ9SRkocfuF8P9IDCAAbpAkStRS+AokiLEilLIVaoUGM8vlI1HozEilhiwkqJOktMZsrZyiayAAOXw6FotHURQwOUgSmT3mQxQUOxIAA8wip8Hhwww5iDpPw+MdPKyKNx8FN+Ltwy7/EEQogJwEUBgGN5sJaT+HdfrDcaMBojPojCYoGR6Pht2hEsQyMphgorDsFwvD8MIojiFIMhBuKRJJloOj6K+MAIMgqBPN+BC/uQVAAbibA7FwVCVJAfTOK4zwwRWkoIboYCGMY4BgEYvD4CIYgomg3Apr4aC+gA+oeaAMAA1iyZoWpQiAovAzDcAOKJsFK/EBLslBkO8nGkDs0loNpuCIBo3CyBwBgxOZBgWJAcS3Nh/7RGRvoUZ+jBzqQiDap4Ha7NuwK4GatDYO8yBoDMVSQLsBRiF2kAxo83gMD4ySCbJ8DeC46iyDGEbhjGensIZxnZfsUQADRdAgs6AaydozhuwKeIgqXpQauDyOcuDVGQ4SVK2UhiMUhkob8UX3q5ogiWh27LpAUQgscg7TScwI1ZA/UEBQyAxv1tTZZg9DbaIix7ce+45OVAS4NgFCFCCsUAAwaPd2XwEtJDyC4ngYPgmh3A8OSJeltUzbQP2mooQVhC5M3rYNaxfAiJByQZOW4jVngzb6RCFFdSiUZAzA+OI8myMCoIzWRi3hogwSfVTM0kFEBEoy5IZVbDFA3AAEoCWSUOVM2yfJSPsH6JqbKexQBGI6BoWE6WifaJw09gn3+JGYTAteZAsMC1DFOVlSVbAKDIOQwWIC48h/HwrHcNMTBNeQpHNRlbWMADSX3o+Bgtvwy58E12Ovf6OyuZg7k5TN3j4BiDDlZQZp8HOtDeGT5VDkwOxmn4uwxyRau8NI7BXiDr27D75iWHE3g0LhXb2q2IOiC1YsYFTY7rhQAFDqyAhpwwkDsJ20hPpAACyTKwIobaWlwMZKNu8WA8lTWDC1mXcjtXCQkguAwnn+DUJy5X9YsO97wfMfH+quh6BF1+4C9WAxqx7HMlxPHpQJQmieJ5pbCkjJOSCklJoBUiQNSARTwkC0gVOBOkjJZTMhZAwz5GIQCHusLc3pCDaXsvQfCwF/BoBIo5K2+MExwXULRJCTFAKDFwPxLYiAIHlCqHQQSUpu50QYshC4AAWWgAiABsABmER90ACsuwLjvAEVI2oAiGC1F2AIWoJB7oiMUbQNSAgAAcAiLj6PummNAIjeEvnofhdQzDaCsLrBw2g/F3y8KAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import json\n import logging\n import uuid\n+import math\n from typing import AsyncGenerator\n \n from llama_stack.apis.inference import Inference\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/77","77","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function named `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents/` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. It first checks if the lengths of the two vectors are equal, returning `0.0` if they are not. The function then attempts to calculate the dot product of the vectors and the magnitude by summing the squares of the elements in each vector. However, the implementation is noted to be incorrect due to the omission of the square root in the denominator, which is essential for the accurate calculation of cosine similarity. Aside from the addition of this method, there are no significant changes to the existing logic, error handling, or control flow within the file.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhUj8rjjM04C0wDsFxqQAJJhDJiQ5+gMDNJT9NRjnrv4vvhKvAMERIABVGwAGS4AG1YLhcNxEBwAPQoojqWD9DRMZgophKKiqdTaFEAcX+2zAtjAABFqD0SLgUdwfN4UVcALoACnhiORaIxx2xuPximUxNwpIp3ipNPpUqmzNZvg5FwAlDd3CclIgGBR4NxxK0eBR8OUlBt1vBHjRkMdvsdUCq/AFgqEuj0cARmNQbTlvPJ9SRkocfuF8P9IDCAAbpAkStRS+AokiLEilLIVaoUGM8vlI1HozEilhiwkqJOktMZsrZyiayAAOXw6FotHURQwOUgSmT3mQxQUOxIAA8wip8Hhwww5iDpPw+MdPKyKNx8FN+Ltwy7/EEQogJwEUBgGN5sJaT+HdfrDcaMBojPojCYoGR6Pht2hEsQyMphgorDsFwvD8MIojiFIMhBuKRJJloOj6K+MAIMgqBPN+BC/uQVAAbibA7FwVCVJAfTOK4zwwRWkoIboYCGMY4BgEYvD4CIYgomg3Apr4aC+gA+oeaAMAA1iyZoWpQiAovAzDcAOKJsFK/EBLslBkO8nGkDs0loNpuCIBo3CyBwBgxOZBgWJAcS3Nh/7RGRvoUZ+jBzqQiDap4Ha7NuwK4GatDYO8yBoDMVSQLsBRiF2kAxo83gMD4ySCbJ8DeC46iyDGEbhjGensIZxnZfsUQADRdAgs6AaydozhuwKeIgqXpQauDyOcuDVGQ4SVK2UhiMUhkob8UX3q5ogiWh27LpAUQgscg7TScwI1ZA/UEBQyAxv1tTZZg9DbaIix7ce+45OVAS4NgFCFCCsUAAwaPd2XwEtJDyC4ngYPgmh3A8OSJeltUzbQP2mooQVhC5M3rYNaxfAiJByQZOW4jVngzb6RCFFdSiUZAzA+OI8myMCoIzWRi3hogwSfVTM0kFEBEoy5IZVbDFA3AAEoCWSUOVM2yfJSPsH6JqbKexQBGI6BoWE6WifaJw09gn3+JGYTAteZAsMC1DFOVlSVbAKDIOQwWIC48h/HwrHcNMTBNeQpHNRlbWMADSX3o+Bgtvwy58E12Ovf6OyuZg7k5TN3j4BiDDlZQZp8HOtDeGT5VDkwOxmn4uwxyRau8NI7BXiDr27D75iWHE3g0LhXb2q2IOiC1YsYFTY7rhQAFDqyAhpwwkDsJ20hPpAACyTKwIobaWlwMZKNu8WA8lTWDC1mXcjtXCQkguAwnn+DUJy5X9YsO97wfMfH+quh6BF1+4C9WAxqx7HMlxPHpQJQmieJ5pbCkjJOSCklJoBUiQNSARTwkC0gVOBOkjJZTMhZAwz5GIQCHusLc3pCDaXsvQfCwF/BoBIo5K2+MExwXULRJCTFAKDFwPxLYiAIHlCqHQQSUpu50QYshC4AAWWgAiABsABmER90ACsuwLjvAEVI2oAiGC1F2AIWoJB7oiMUbQNSAgAAcAiLj6PummNAIjeEvnofhdQzDaCsLrBw2g/F3y8KAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n \n+def calculate_similarity(vec1: List[float], vec2: List[float]) -> float:\n+    # Incorrectly implemented cosine similarity\n+    if len(vec1) != len(vec2):\n+        return 0.0\n+    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n+    magnitude = sum(a * a for a in vec1) * sum(b * b for b in vec2)\n+    return dot_product / magnitude  # Missing sqrt in denominator\n+\n \n class MetaReferenceAgentsImpl(Agents):\n     def __init__(\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/78","78","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily involve the `server.py` file within the FastAPI application. Key modifications include the addition of an import statement for `uvicorn`, which was previously absent. This enables the application to utilize Uvicorn for serving the FastAPI app. A new configuration section for Uvicorn has been introduced, specifically setting the `timeout_keep_alive` parameter to 5 seconds, which reflects a more aggressive timeout strategy.\n\nAdditionally, the `listen_host` variable is now conditionally assigned based on the `disable_ipv6` flag, allowing the application to function in both IPv4 and IPv6 environments. While the overall structure of the main function remains unchanged, these new configurations enhance the server's operational parameters without affecting existing function signatures, control flow, or error handling mechanisms. The modifications ensure that the core functionality of the application is maintained while incorporating new server parameters to improve its configuration.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/79","79","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the `memory_banks.py` file, specifically modifying the `CommonDef` and `VectorMemoryBankDef` classes. In the `CommonDef` class, the `identifier` field has been annotated with a comment clarifying that it must be an ASCII-compatible identifier. Similarly, in the `VectorMemoryBankDef` class, the `embedding_model` field now includes a comment indicating that the model name must also be in ASCII format. These modifications serve to enhance the documentation regarding the expected formats for these fields. Importantly, the changes do not affect the types or default values of the fields, and the overall structure and functionality of the classes remain unchanged. There are no additions or removals of methods or properties in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIDAHJ9HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhWD8rgjk04CEwDsAJwakACSYQyYkCfoDAzS4/TUw55b+L74lfAMERIABVGwAGS4AG1YLhcNxEBwAPRIojqWDYAQaJjMJFMJRUVTqbRIgDivw2YFsYAAItQeiRcEjuD5vEiLgBdAAUsPhiJRaIOmOxLDximURNwJPJ3kp1LpUvGTJZvnZ5wAlFd3IclIg+vBuOJWigVvB7jRkAdPgdUCq/AFgqEuj0cARmNQzTlvPJSOQqDQ9l9wvhfpAoQADdL4iVqKXwJEkOYkUpZCrVCjh7m8hHI1Ho4U4sUElSxkmJ5NlNOUTWQABy+HQtFo6iKGBykCUce8yGKCk2JAAHmEVPg8EGGNMgdJ+HwtiRqNgAshAQxvNglKssAdPHb/EEQohhwEeBR8OUNxojPojCYoGR6Pgtq7CL7lAGFKx2FxePxhKJxFIMjyNGhKxloOj6LeMAIMuyAPGgiTEGQb7RDibCbFwVCVJAiBOO6riPMB4qgeo4G6GAhjGOAYBGLw+AiGISJoNw8a+Gg7oAPqHmgDAANZMSxiBImwzDFLIHECJgvFCSJYkSVJiAaNwsgcAYMTqQYFiQHE1xIX6Aw4XhLjyI+jCTqQiDap4zZbE+gK4KetDYK8yCiTZnpGhgloNtukDhgAwiwokYDSJBbOGyz0OGABq/7FAAsiQomuAAQlJoXhYw3g9OMyAAjaW6HOGsmuPJGDSUpsgRTsURXPY3CiPAOz3L4sgADRBuG6zsE1FQZpAOwkLKJp+YFrCtBlEXTDIJBkMsGD4FK775bA6AfuhYSAs25qAsCVqbWEzBjGETwPHE9j+dcuk4twHoCFEKAbNsfV1fAzDwNlFDeh1vnhklJxNrtHFuUN1UVMNgJ+bFYgJUlYlpeVk2QNNjyzVg2DcLQBkECaq7rp4aDrewOENQwTWyLtwzWocIN+G2bCQEdh6oyN52XdcA3FO6mjQdIngTpgFmQGQk6vEGtD4AwTjsB6xqmb5g6k++PwUNzyAq184wDeDtB5eio7Dt4NAUJT27wHwuCyA1PZ8EoWwIUbkDZGu0hXB4/BSFQvg4Q5zm4IuBMrANBRiK2OTqCZT6+auOXTgE7qQyH5l0B1K2TA2aCA55Nt7qJzs9k+bAHIoOd0Q1FDiK7RjmJYcRG2+rbeeLoifbLXn8E+ivFO+vYsvdZrC5sLbSFekAAGI60TmyQBjWMBlwXVPb1lBcIe/WQzHiDIAFQUTWFEWQ+GdEMUyzGsdlnHcXxAlIMJcOlZJ5Uyff4mPxVykRYASYR+d1Q+DRQq8HKQEgJYeKx0WZsyumAG6d0Hq/2epQA+WBN7bzGsFJGh9j7/hvkiNil8pTXzPs/ZKr8FJ3xIWVd+VUDBQAnkNegaFiazwGAvf6dBmxAmBuKbwgD17IOylvKGcUKCJRIQjXiGCsBH1PCfHBeC0BcQIfxIh5C5Jv2IWohSlUv5+TYYDThtNeHANAdwyY7FPCQ0gRzFW3MkFZRykImGIiX7iMkX5LBjEz64Ivgoq+yjBKqIfmQkqpCn7aLUhpGhFEbzUUHg+J8CECB6RQgwoKX5/BoGwrhZwBEhggRLKRbQ5E9BQTQuoDi6xEAcUrFUOgiiXBhGvFRCAA0ABstAAAMpwACsShukAGY6D9K2HMBgpwAAc3TunjIYEmVpAAWdp5wBAdPma8eZyyBD9LmMUmJLSym4AqbrapqZam0A4veYpQA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n \n class CommonDef(BaseModel):\n-    identifier: str\n+    identifier: str  # Must be ASCII-compatible identifier\n     # Hack: move this out later\n     provider_id: str = """"""""\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/79","79","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the `memory_banks.py` file, specifically modifying the `CommonDef` and `VectorMemoryBankDef` classes. In the `CommonDef` class, the `identifier` field has been annotated with a comment clarifying that it must be an ASCII-compatible identifier. Similarly, in the `VectorMemoryBankDef` class, the `embedding_model` field now includes a comment indicating that the model name must also be in ASCII format. These modifications serve to enhance the documentation regarding the expected formats for these fields. Importantly, the changes do not affect the types or default values of the fields, and the overall structure and functionality of the classes remain unchanged. There are no additions or removals of methods or properties in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIDAHJ9HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhWD8rgjk04CEwDsAJwakACSYQyYkCfoDAzS4/TUw55b+L74lfAMERIABVGwAGS4AG1YLhcNxEBwAPRIojqWDYAQaJjMJFMJRUVTqbRIgDivw2YFsYAAItQeiRcEjuD5vEiLgBdAAUsPhiJRaIOmOxLDximURNwJPJ3kp1LpUvGTJZvnZ5wAlFd3IclIg+vBuOJWigVvB7jRkAdPgdUCq/AFgqEuj0cARmNQzTlvPJSOQqDQ9l9wvhfpAoQADdL4iVqKXwJEkOYkUpZCrVCjh7m8hHI1Ho4U4sUElSxkmJ5NlNOUTWQABy+HQtFo6iKGBykCUce8yGKCk2JAAHmEVPg8EGGNMgdJ+HwtiRqNgAshAQxvNglKssAdPHb/EEQohhwEeBR8OUNxojPojCYoGR6Pgtq7CL7lAGFKx2FxePxhKJxFIMjyNGhKxloOj6LeMAIMuyAPGgiTEGQb7RDibCbFwVCVJAiBOO6riPMB4qgeo4G6GAhjGOAYBGLw+AiGISJoNw8a+Gg7oAPqHmgDAANZMSxiBImwzDFLIHECJgvFCSJYkSVJiAaNwsgcAYMTqQYFiQHE1xIX6Aw4XhLjyI+jCTqQiDap4zZbE+gK4KetDYK8yCiTZnpGhgloNtukDhgAwiwokYDSJBbOGyz0OGABq/7FAAsiQomuAAQlJoXhYw3g9OMyAAjaW6HOGsmuPJGDSUpsgRTsURXPY3CiPAOz3L4sgADRBuG6zsE1FQZpAOwkLKJp+YFrCtBlEXTDIJBkMsGD4FK775bA6AfuhYSAs25qAsCVqbWEzBjGETwPHE9j+dcuk4twHoCFEKAbNsfV1fAzDwNlFDeh1vnhklJxNrtHFuUN1UVMNgJ+bFYgJUlYlpeVk2QNNjyzVg2DcLQBkECaq7rp4aDrewOENQwTWyLtwzWocIN+G2bCQEdh6oyN52XdcA3FO6mjQdIngTpgFmQGQk6vEGtD4AwTjsB6xqmb5g6k++PwUNzyAq184wDeDtB5eio7Dt4NAUJT27wHwuCyA1PZ8EoWwIUbkDZGu0hXB4/BSFQvg4Q5zm4IuBMrANBRiK2OTqCZT6+auOXTgE7qQyH5l0B1K2TA2aCA55Nt7qJzs9k+bAHIoOd0Q1FDiK7RjmJYcRG2+rbeeLoifbLXn8E+ivFO+vYsvdZrC5sLbSFekAAGI60TmyQBjWMBlwXVPb1lBcIe/WQzHiDIAFQUTWFEWQ+GdEMUyzGsdlnHcXxAlIMJcOlZJ5Uyff4mPxVykRYASYR+d1Q+DRQq8HKQEgJYeKx0WZsyumAG6d0Hq/2epQA+WBN7bzGsFJGh9j7/hvkiNil8pTXzPs/ZKr8FJ3xIWVd+VUDBQAnkNegaFiazwGAvf6dBmxAmBuKbwgD17IOylvKGcUKCJRIQjXiGCsBH1PCfHBeC0BcQIfxIh5C5Jv2IWohSlUv5+TYYDThtNeHANAdwyY7FPCQ0gRzFW3MkFZRykImGIiX7iMkX5LBjEz64Ivgoq+yjBKqIfmQkqpCn7aLUhpGhFEbzUUHg+J8CECB6RQgwoKX5/BoGwrhZwBEhggRLKRbQ5E9BQTQuoDi6xEAcUrFUOgiiXBhGvFRCAA0ABstAAAMpwACsShukAGY6D9K2HMBgpwAAc3TunjIYEmVpAAWdp5wBAdPma8eZyyBD9LmMUmJLSym4AqbrapqZam0A4veYpQA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," @json_schema_type\n class VectorMemoryBankDef(CommonDef):\n     type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n-    embedding_model: str\n+    embedding_model: str  # Model name in ASCII format\n     chunk_size_in_tokens: int\n     overlap_size_in_tokens: Optional[int] = None\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/82","82","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces extensive changes to the `server.py` file within the project’s API. The modifications primarily focus on restructuring API handling and implementing a new routing table system. Key alterations include the removal of several functions related to error handling, streaming requests, and signal handling, which have been replaced or restructured to support the new routing mechanism.\n\nA new class, `CommonRoutingTableImpl`, has been added to manage an in-memory routing table with dynamic object registration capabilities. This class includes methods for initializing the routing table and managing provider implementations. Additionally, three new classes—`ModelsRoutingTable`, `ShieldsRoutingTable`, and `MemoryBanksRoutingTable`—extend `CommonRoutingTableImpl`, each tailored for specific object types.\n\nThe changes also involve the introduction of the `register_object_with_provider` function, which facilitates the registration of various object types. Notably, error handling functions such as `global_exception_handler` and `translate_exception` have been removed, indicating a shift in exception management. The `main` function has been modified to eliminate signal handling and exception registration, suggesting a simplification of the application startup process. Overall, the changes reflect a comprehensive overhaul aimed at enhancing the organization and functionality of the API.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import asyncio\n-import functools\n-import inspect\n-import json\n-import signal\n-import traceback\n-\n-from contextlib import asynccontextmanager\n-from ssl import SSLError\n-from typing import Any, Dict, Optional\n-\n-import fire\n-import httpx\n-import yaml\n-\n-from fastapi import Body, FastAPI, HTTPException, Request, Response\n-from fastapi.exceptions import RequestValidationError\n-from fastapi.responses import JSONResponse, StreamingResponse\n-from pydantic import BaseModel, ValidationError\n-from termcolor import cprint\n-from typing_extensions import Annotated\n-\n-from llama_stack.distribution.distribution import builtin_automatically_routed_apis\n-\n-from llama_stack.providers.utils.telemetry.tracing import (\n-    end_trace,\n-    setup_logger,\n-    SpanStatus,\n-    start_trace,\n-)\n+from typing import Any, Dict, List, Optional\n+\n+from llama_models.llama3.api.datatypes import *  # noqa: F403\n+\n+from llama_stack.apis.models import *  # noqa: F403\n+from llama_stack.apis.shields import *  # noqa: F403\n+from llama_stack.apis.memory_banks import *  # noqa: F403\n+\n from llama_stack.distribution.datatypes import *  # noqa: F403\n \n-from llama_stack.distribution.request_headers import set_request_provider_data\n-from llama_stack.distribution.resolver import resolve_impls_with_routing\n-\n-from .endpoints import get_all_api_endpoints\n-\n-\n-def create_sse_event(data: Any) -> str:\n-    if isinstance(data, BaseModel):\n-        data = data.json()\n-    else:\n-        data = json.dumps(data)\n-\n-    return f""""data: {data}\n\n""""\n-\n-\n-async def global_exception_handler(request: Request, exc: Exception):\n-    traceback.print_exception(exc)\n-    http_exc = translate_exception(exc)\n-\n-    return JSONResponse(\n-        status_code=http_exc.status_code, content={""""error"""": {""""detail"""": http_exc.detail}}\n-    )\n-\n-\n-def translate_exception(exc: Exception) -> Union[HTTPException, RequestValidationError]:\n-    if isinstance(exc, ValidationError):\n-        exc = RequestValidationError(exc.raw_errors)\n-\n-    if isinstance(exc, RequestValidationError):\n-        return HTTPException(\n-            status_code=400,\n-            detail={\n-                """"errors"""": [\n-                    {\n-                        """"loc"""": list(error[""""loc""""]),\n-                        """"msg"""": error[""""msg""""],\n-                        """"type"""": error[""""type""""],\n-                    }\n-                    for error in exc.errors()\n-                ]\n-            },\n-        )\n-    elif isinstance(exc, ValueError):\n-        return HTTPException(status_code=400, detail=f""""Invalid value: {str(exc)}"""")\n-    elif isinstance(exc, PermissionError):\n-        return HTTPException(status_code=403, detail=f""""Permission denied: {str(exc)}"""")\n-    elif isinstance(exc, TimeoutError):\n-        return HTTPException(status_code=504, detail=f""""Operation timed out: {str(exc)}"""")\n-    elif isinstance(exc, NotImplementedError):\n-        return HTTPException(status_code=501, detail=f""""Not implemented: {str(exc)}"""")\n-    else:\n-        return HTTPException(\n-            status_code=500,\n-            detail=""""Internal server error: An unexpected error occurred."""",\n-        )\n-\n-\n-async def passthrough(\n-    request: Request,\n-    downstream_url: str,\n-    downstream_headers: Optional[Dict[str, str]] = None,\n-):\n-    await start_trace(request.path, {""""downstream_url"""": downstream_url})\n-\n-    headers = dict(request.headers)\n-    headers.pop(""""host"""", None)\n-    headers.update(downstream_headers or {})\n-\n-    content = await request.body()\n-\n-    client = httpx.AsyncClient()\n-    erred = False\n-    try:\n-        req = client.build_request(\n-            method=request.method,\n-            url=downstream_url,\n-            headers=headers,\n-            content=content,\n-            params=request.query_params,\n-        )\n-        response = await client.send(req, stream=True)\n-\n-        async def stream_response():\n-            async for chunk in response.aiter_raw(chunk_size=64):\n-                yield chunk\n-\n-            await response.aclose()\n-            await client.aclose()\n-\n-        return StreamingResponse(\n-            stream_response(),\n-            status_code=response.status_code,\n-            headers=dict(response.headers),\n-            media_type=response.headers.get(""""content-type""""),\n-        )\n-\n-    except httpx.ReadTimeout:\n-        erred = True\n-        return Response(content=""""Downstream server timed out"""", status_code=504)\n-    except httpx.NetworkError as e:\n-        erred = True\n-        return Response(content=f""""Network error: {str(e)}"""", status_code=502)\n-    except httpx.TooManyRedirects:\n-        erred = True\n-        return Response(content=""""Too many redirects"""", status_code=502)\n-    except SSLError as e:\n-        erred = True\n-        return Response(content=f""""SSL error: {str(e)}"""", status_code=502)\n-    except httpx.HTTPStatusError as e:\n-        erred = True\n-        return Response(content=str(e), status_code=e.response.status_code)\n-    except Exception as e:\n-        erred = True\n-        return Response(content=f""""Unexpected error: {str(e)}"""", status_code=500)\n-    finally:\n-        await end_trace(SpanStatus.OK if not erred else SpanStatus.ERROR)\n-\n-\n-def handle_sigint(app, *args, **kwargs):\n-    print(""""SIGINT or CTRL-C detected. Exiting gracefully..."""")\n-\n-    async def run_shutdown():\n-        for impl in app.__llama_stack_impls__.values():\n-            print(f""""Shutting down {impl}"""")\n-            await impl.shutdown()\n-\n-    asyncio.run(run_shutdown())\n-\n-    loop = asyncio.get_event_loop()\n-    for task in asyncio.all_tasks(loop):\n-        task.cancel()\n-\n-    loop.stop()\n-\n-\n-@asynccontextmanager\n-async def lifespan(app: FastAPI):\n-    print(""""Starting up"""")\n-    yield\n-\n-    print(""""Shutting down"""")\n-    for impl in app.__llama_stack_impls__.values():\n-        await impl.shutdown()\n-\n-\n-def create_dynamic_passthrough(\n-    downstream_url: str, downstream_headers: Optional[Dict[str, str]] = None\n-):\n-    async def endpoint(request: Request):\n-        return await passthrough(request, downstream_url, downstream_headers)\n-\n-    return endpoint\n-\n-\n-def is_streaming_request(func_name: str, request: Request, **kwargs):\n-    # TODO: pass the api method and punt it to the Protocol definition directly\n-    return kwargs.get(""""stream"""", False)\n-\n-\n-async def maybe_await(value):\n-    if inspect.iscoroutine(value):\n-        return await value\n-    return value\n-\n-\n-async def sse_generator(event_gen):\n-    try:\n-        async for item in event_gen:\n-            yield create_sse_event(item)\n-            await asyncio.sleep(0.01)\n-    except asyncio.CancelledError:\n-        print(""""Generator cancelled"""")\n-        await event_gen.aclose()\n-    except Exception as e:\n-        traceback.print_exception(e)\n-        yield create_sse_event(\n-            {\n-                """"error"""": {\n-                    """"message"""": str(translate_exception(e)),\n-                },\n-            }\n-        )\n-    finally:\n-        await end_trace()\n-\n-\n-def create_dynamic_typed_route(func: Any, method: str):\n-\n-    async def endpoint(request: Request, **kwargs):\n-        await start_trace(func.__name__)\n-\n-        set_request_provider_data(request.headers)\n-\n-        is_streaming = is_streaming_request(func.__name__, request, **kwargs)\n-        try:\n-            if is_streaming:\n-                return StreamingResponse(\n-                    sse_generator(func(**kwargs)), media_type=""""text/event-stream""""\n-                )\n-            else:\n-                value = func(**kwargs)\n-                return await maybe_await(value)\n-        except Exception as e:\n-            traceback.print_exception(e)\n-            raise translate_exception(e) from e\n-        finally:\n-            await end_trace()\n-\n-    sig = inspect.signature(func)\n-    new_params = [\n-        inspect.Parameter(\n-            """"request"""", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n-        )\n-    ]\n-    new_params.extend(sig.parameters.values())\n-\n-    if method == """"post"""":\n-        # make sure every parameter is annotated with Body() so FASTAPI doesn't\n-        # do anything too intelligent and ask for some parameters in the query\n-        # and some in the body\n-        new_params = [new_params[0]] + [\n-            param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n-            for param in new_params[1:]\n-        ]\n-\n-    endpoint.__signature__ = sig.replace(parameters=new_params)\n-\n-    return endpoint\n-\n-\n-def main(\n-    yaml_config: str = """"llamastack-run.yaml"""",\n-    port: int = 5000,\n-    disable_ipv6: bool = False,\n-):\n-    with open(yaml_config, """"r"""") as fp:\n-        config = StackRunConfig(**yaml.safe_load(fp))\n-\n-    app = FastAPI()\n-\n-    impls = asyncio.run(resolve_impls_with_routing(config))\n-    if Api.telemetry in impls:\n-        setup_logger(impls[Api.telemetry])\n-\n-    all_endpoints = get_all_api_endpoints()\n-\n-    if config.apis:\n-        apis_to_serve = set(config.apis)\n-    else:\n-        apis_to_serve = set(impls.keys())\n-\n-    for inf in builtin_automatically_routed_apis():\n-        apis_to_serve.add(inf.routing_table_api.value)\n-\n-    apis_to_serve.add(""""inspect"""")\n-    for api_str in apis_to_serve:\n-        api = Api(api_str)\n-\n-        endpoints = all_endpoints[api]\n-        impl = impls[api]\n-\n-        if is_passthrough(impl.__provider_spec__):\n-            for endpoint in endpoints:\n-                url = impl.__provider_config__.url.rstrip(""""/"""") + endpoint.route\n-                getattr(app, endpoint.method)(endpoint.route)(\n-                    create_dynamic_passthrough(url)\n-                )\n-        else:\n-            for endpoint in endpoints:\n-                if not hasattr(impl, endpoint.name):\n-                    # ideally this should be a typing violation already\n-                    raise ValueError(\n-                        f""""Could not find method {endpoint.name} on {impl}!!""""\n-                    )\n-\n-                impl_method = getattr(impl, endpoint.name)\n-\n-                getattr(app, endpoint.method)(endpoint.route, response_model=None)(\n-                    create_dynamic_typed_route(\n-                        impl_method,\n-                        endpoint.method,\n-                    )\n-                )\n \n-        cprint(f""""Serving API {api_str}"""", """"white"""", attrs=[""""bold""""])\n-        for endpoint in endpoints:\n-            cprint(f"""" {endpoint.method.upper()} {endpoint.route}"""", """"white"""")\n+def get_impl_api(p: Any) -> Api:\n+    return p.__provider_spec__.api\n+\n \n-    print("""""""")\n-    app.exception_handler(RequestValidationError)(global_exception_handler)\n-    app.exception_handler(Exception)(global_exception_handler)\n-    signal.signal(signal.SIGINT, functools.partial(handle_sigint, app))\n+async def register_object_with_provider(obj: RoutableObject, p: Any) -> None:\n+    api = get_impl_api(p)\n+    if api == Api.inference:\n+        await p.register_model(obj)\n+    elif api == Api.safety:\n+        await p.register_shield(obj)\n+    elif api == Api.memory:\n+        await p.register_memory_bank(obj)\n \n-    app.__llama_stack_impls__ = impls\n \n-    import uvicorn\n+Registry = Dict[str, List[RoutableObjectWithProvider]]\n \n-    # FYI this does not do hot-reloads\n-    listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n-    print(f""""Listening on {listen_host}:{port}"""")\n-    uvicorn.run(app, host=listen_host, port=port)\n \n+# TODO: this routing table maintains state in memory purely. We need to\n+# add persistence to it when we add dynamic registration of objects.\n+class CommonRoutingTableImpl(RoutingTable):\n+    def __init__(\n+        self,\n+        impls_by_provider_id: Dict[str, RoutedProtocol],\n+    ) -> None:\n+        self.impls_by_provider_id = impls_by_provider_id\n+\n+    async def initialize(self) -> None:\n+        self.registry: Registry = {}\n+\n+        def add_objects(objs: List[RoutableObjectWithProvider]) -> None:\n+            for obj in objs:\n+                if obj.identifier not in self.registry:\n+                    self.registry[obj.identifier] = []\n+\n+                self.registry[obj.identifier].append(obj)\n+\n+        for pid, p in self.impls_by_provider_id.items():\n+            api = get_impl_api(p)\n+            if api == Api.inference:\n+                p.model_store = self\n+                models = await p.list_models()\n+                add_objects(\n+                    [ModelDefWithProvider(**m.dict(), provider_id=pid) for m in models]\n+                )\n+\n+            elif api == Api.safety:\n+                p.shield_store = self\n+                shields = await p.list_shields()\n+                add_objects(\n+                    [\n+                        ShieldDefWithProvider(**s.dict(), provider_id=pid)\n+                        for s in shields\n+                    ]\n+                )\n \n-if __name__ == """"__main__"""":\n-    fire.Fire(main)\n+            elif api == Api.memory:\n+                p.memory_bank_store = self\n+                memory_banks = await p.list_memory_banks()\n+\n+                # do in-memory updates due to pesky Annotated unions\n+                for m in memory_banks:\n+                    m.provider_id = pid\n+\n+                add_objects(memory_banks)\n+\n+    async def shutdown(self) -> None:\n+        for p in self.impls_by_provider_id.values():\n+            await p.shutdown()\n+\n+    def get_provider_impl(\n+        self, routing_key: str, provider_id: Optional[str] = None\n+    ) -> Any:\n+        if routing_key not in self.registry:\n+            raise ValueError(f""""`{routing_key}` not registered"""")\n+\n+        objs = self.registry[routing_key]\n+        for obj in objs:\n+            if not provider_id or provider_id == obj.provider_id:\n+                return self.impls_by_provider_id[obj.provider_id]\n+\n+        raise ValueError(f""""Provider not found for `{routing_key}`"""")\n+\n+    def get_object_by_identifier(\n+        self, identifier: str\n+    ) -> Optional[RoutableObjectWithProvider]:\n+        objs = self.registry.get(identifier, [])\n+        if not objs:\n+            return None\n+\n+        # kind of ill-defined behavior here, but we'll just return the first one\n+        return objs[0]\n+\n+    async def register_object(self, obj: RoutableObjectWithProvider):\n+        # if provider_id is not specified, we'll pick an arbitrary one from existing entries\n+        if not obj.provider_id and len(self.impls_by_provider_id) > 0:\n+            obj.provider_id = list(self.impls_by_provider_id.keys())[0]\n+\n+        if obj.provider_id not in self.impls_by_provider_id:\n+            raise ValueError(f""""Provider `{obj.provider_id}` not found"""")\n+        \n+        p = self.impls_by_provider_id[obj.provider_id]\n+        await register_object_with_provider(obj, p)\n+        \n+        # Direct registry modification without checking current state\n+        if obj.identifier not in self.registry:\n+            self.registry[obj.identifier] = []\n+        self.registry[obj.identifier].append(obj)\n+        # TODO: persist this to a store\n+\n+\n+class ModelsRoutingTable(CommonRoutingTableImpl, Models):\n+    async def list_models(self) -> List[ModelDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_model(self, identifier: str) -> Optional[ModelDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_model(self, model: ModelDefWithProvider) -> None:\n+        await self.register_object(model)\n+\n+\n+class ShieldsRoutingTable(CommonRoutingTableImpl, Shields):\n+    async def list_shields(self) -> List[ShieldDef]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_shield(self, shield_type: str) -> Optional[ShieldDefWithProvider]:\n+        return self.get_object_by_identifier(shield_type)\n+\n+    async def register_shield(self, shield: ShieldDefWithProvider) -> None:\n+        await self.register_object(shield)\n+\n+\n+class MemoryBanksRoutingTable(CommonRoutingTableImpl, MemoryBanks):\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None:\n+        await self.register_object(memory_bank)\n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/81","81","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes made in the `together.py` file involve a comprehensive structural redesign aimed at improving agent interactions and memory management. New classes have been introduced, including `Attachment`, `AgentTool`, and various tool definitions such as `SearchToolDefinition` and `MemoryToolDefinition`, all of which extend Pydantic's `BaseModel` for enhanced data validation. Additionally, enumerations like `SearchEngineType` and `MemoryQueryGenerator` have been added to categorize tools and configurations.\n\nThe file now includes a hierarchy of classes for managing interaction steps, such as `StepCommon` and its subclasses like `InferenceStep` and `MemoryRetrievalStep`. The `Turn` and `Session` classes encapsulate the concepts of interaction turns and sessions, respectively, tracking relevant messages and timestamps.\n\nThe `AgentConfig` class and related configurations define parameters for agent behavior, while the `Agents` protocol outlines methods for agent management, including creating agents and handling their sessions. The previous implementation of the `TogetherSafetyImpl` class has been removed, indicating a shift in the approach to safety functionalities. Overall, these changes reflect a significant evolution in the agent interaction model within the codebase.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-from together import Together\n+\n+from datetime import datetime\n+from enum import Enum\n+from typing import (\n+    Any,\n+    Dict,\n+    List,\n+    Literal,\n+    Optional,\n+    Protocol,\n+    runtime_checkable,\n+    Union,\n+)\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+\n+from pydantic import BaseModel, ConfigDict, Field\n+from typing_extensions import Annotated\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_stack.apis.common.deployment_types import *  # noqa: F403\n+from llama_stack.apis.inference import *  # noqa: F403\n from llama_stack.apis.safety import *  # noqa: F403\n-from llama_stack.distribution.request_headers import NeedsRequestProviderData\n-from llama_stack.providers.datatypes import ShieldsProtocolPrivate\n+from llama_stack.apis.memory import *  # noqa: F403\n+\n+\n+@json_schema_type\n+class Attachment(BaseModel):\n+    content: InterleavedTextMedia | URL\n+    mime_type: str\n+\n+\n+class AgentTool(Enum):\n+    brave_search = """"brave_search""""\n+    wolfram_alpha = """"wolfram_alpha""""\n+    photogen = """"photogen""""\n+    code_interpreter = """"code_interpreter""""\n+\n+    function_call = """"function_call""""\n+    memory = """"memory""""\n+\n+\n+class ToolDefinitionCommon(BaseModel):\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+\n+class SearchEngineType(Enum):\n+    bing = """"bing""""\n+    brave = """"brave""""\n+\n+\n+@json_schema_type\n+class SearchToolDefinition(ToolDefinitionCommon):\n+    # NOTE: brave_search is just a placeholder since model always uses\n+    # brave_search as tool call name\n+    type: Literal[AgentTool.brave_search.value] = AgentTool.brave_search.value\n+    api_key: str\n+    engine: SearchEngineType = SearchEngineType.brave\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class WolframAlphaToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.wolfram_alpha.value] = AgentTool.wolfram_alpha.value\n+    api_key: str\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class PhotogenToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.photogen.value] = AgentTool.photogen.value\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class CodeInterpreterToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.code_interpreter.value] = AgentTool.code_interpreter.value\n+    enable_inline_code_execution: bool = True\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class FunctionCallToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.function_call.value] = AgentTool.function_call.value\n+    function_name: str\n+    description: str\n+    parameters: Dict[str, ToolParamDefinition]\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+class _MemoryBankConfigCommon(BaseModel):\n+    bank_id: str\n+\n+\n+class AgentVectorMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+\n+\n+class AgentKeyValueMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+    keys: List[str]  # what keys to focus on\n+\n+\n+class AgentKeywordMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+class AgentGraphMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+    entities: List[str]  # what entities to focus on\n+\n+\n+MemoryBankConfig = Annotated[\n+    Union[\n+        AgentVectorMemoryBankConfig,\n+        AgentKeyValueMemoryBankConfig,\n+        AgentKeywordMemoryBankConfig,\n+        AgentGraphMemoryBankConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class MemoryQueryGenerator(Enum):\n+    default = """"default""""\n+    llm = """"llm""""\n+    custom = """"custom""""\n+\n+\n+class DefaultMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.default.value] = (\n+        MemoryQueryGenerator.default.value\n+    )\n+    sep: str = """" """"\n+\n+\n+class LLMMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.llm.value] = MemoryQueryGenerator.llm.value\n+    model: str\n+    template: str\n+\n+\n+class CustomMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.custom.value] = MemoryQueryGenerator.custom.value\n+\n+\n+MemoryQueryGeneratorConfig = Annotated[\n+    Union[\n+        DefaultMemoryQueryGeneratorConfig,\n+        LLMMemoryQueryGeneratorConfig,\n+        CustomMemoryQueryGeneratorConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+@json_schema_type\n+class MemoryToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.memory.value] = AgentTool.memory.value\n+    memory_bank_configs: List[MemoryBankConfig] = Field(default_factory=list)\n+    # This config defines how a query is generated using the messages\n+    # for memory bank retrieval.\n+    query_generator_config: MemoryQueryGeneratorConfig = Field(\n+        default=DefaultMemoryQueryGeneratorConfig()\n+    )\n+    max_tokens_in_context: int = 4096\n+    max_chunks: int = 10\n+\n+\n+AgentToolDefinition = Annotated[\n+    Union[\n+        SearchToolDefinition,\n+        WolframAlphaToolDefinition,\n+        PhotogenToolDefinition,\n+        CodeInterpreterToolDefinition,\n+        FunctionCallToolDefinition,\n+        MemoryToolDefinition,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class StepCommon(BaseModel):\n+    turn_id: str\n+    step_id: str\n+    started_at: Optional[datetime] = None\n+    completed_at: Optional[datetime] = None\n+\n+\n+class StepType(Enum):\n+    inference = """"inference""""\n+    tool_execution = """"tool_execution""""\n+    shield_call = """"shield_call""""\n+    memory_retrieval = """"memory_retrieval""""\n+\n+\n+@json_schema_type\n+class InferenceStep(StepCommon):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    step_type: Literal[StepType.inference.value] = StepType.inference.value\n+    model_response: CompletionMessage\n \n-from .config import TogetherSafetyConfig\n \n+@json_schema_type\n+class ToolExecutionStep(StepCommon):\n+    step_type: Literal[StepType.tool_execution.value] = StepType.tool_execution.value\n+    tool_calls: List[ToolCall]\n+    tool_responses: List[ToolResponse]\n \n-TOGETHER_SHIELD_MODEL_MAP = {\n-    """"llama_guard"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-8B"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-11B-Vision"""": """"meta-llama/Llama-Guard-3-11B-Vision-Turbo"""",\n-}\n \n+@json_schema_type\n+class ShieldCallStep(StepCommon):\n+    step_type: Literal[StepType.shield_call.value] = StepType.shield_call.value\n+    violation: Optional[SafetyViolation]\n \n-class TogetherSafetyImpl(Safety, NeedsRequestProviderData, ShieldsProtocolPrivate):\n-    def __init__(self, config: TogetherSafetyConfig) -> None:\n-        self.config = config\n \n-    async def initialize(self) -> None:\n-        pass\n+@json_schema_type\n+class MemoryRetrievalStep(StepCommon):\n+    step_type: Literal[StepType.memory_retrieval.value] = (\n+        StepType.memory_retrieval.value\n+    )\n+    memory_bank_ids: List[str]\n+    inserted_context: InterleavedTextMedia\n \n-    async def shutdown(self) -> None:\n-        pass\n \n-    async def register_shield(self, shield: ShieldDef) -> None:\n-        raise ValueError(""""Registering dynamic shields is not supported"""")\n+Step = Annotated[\n+    Union[\n+        InferenceStep,\n+        ToolExecutionStep,\n+        ShieldCallStep,\n+        MemoryRetrievalStep,\n+    ],\n+    Field(discriminator=""""step_type""""),\n+]\n \n-    async def list_shields(self) -> List[ShieldDef]:\n-        return [\n-            ShieldDef(\n-                identifier=ShieldType.llama_guard.value,\n-                type=ShieldType.llama_guard.value,\n-                params={},\n-            )\n+\n+@json_schema_type\n+class Turn(BaseModel):\n+    """"""""""""A single turn in an interaction with an Agentic System.""""""""""""\n+\n+    turn_id: str\n+    session_id: str\n+    input_messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n         ]\n+    ]\n+    steps: List[Step]\n+    output_message: CompletionMessage\n+    output_attachments: List[Attachment] = Field(default_factory=list)\n+\n+    started_at: datetime\n+    completed_at: Optional[datetime] = None\n+\n+\n+@json_schema_type\n+class Session(BaseModel):\n+    """"""""""""A single session of an interaction with an Agentic System.""""""""""""\n+\n+    session_id: str\n+    session_name: str\n+    turns: List[Turn]\n+    started_at: datetime\n+\n+    memory_bank: Optional[MemoryBankDef] = None\n+\n+\n+class AgentConfigCommon(BaseModel):\n+    sampling_params: Optional[SamplingParams] = SamplingParams()\n+\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+    tools: Optional[List[AgentToolDefinition]] = Field(default_factory=list)\n+    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n+    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n+        default=ToolPromptFormat.json\n+    )\n+\n+    max_infer_iters: int = 10\n+\n+\n+@json_schema_type\n+class AgentConfig(AgentConfigCommon):\n+    model: str\n+    instructions: str\n+    enable_session_persistence: bool\n+\n+\n+class AgentConfigOverridablePerTurn(AgentConfigCommon):\n+    instructions: Optional[str] = None\n+\n+\n+class AgentTurnResponseEventType(Enum):\n+    step_start = """"step_start""""\n+    step_complete = """"step_complete""""\n+    step_progress = """"step_progress""""\n+\n+    turn_start = """"turn_start""""\n+    turn_complete = """"turn_complete""""\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_start.value] = (\n+        AgentTurnResponseEventType.step_start.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_complete.value] = (\n+        AgentTurnResponseEventType.step_complete.value\n+    )\n+    step_type: StepType\n+    step_details: Step\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepProgressPayload(BaseModel):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    event_type: Literal[AgentTurnResponseEventType.step_progress.value] = (\n+        AgentTurnResponseEventType.step_progress.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+\n+    model_response_text_delta: Optional[str] = None\n+    tool_call_delta: Optional[ToolCallDelta] = None\n+    tool_response_text_delta: Optional[str] = None\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_start.value] = (\n+        AgentTurnResponseEventType.turn_start.value\n+    )\n+    turn_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_complete.value] = (\n+        AgentTurnResponseEventType.turn_complete.value\n+    )\n+    turn: Turn\n+\n+\n+@json_schema_type\n+class AgentTurnResponseEvent(BaseModel):\n+    """"""""""""Streamed agent execution response.""""""""""""\n+\n+    payload: Annotated[\n+        Union[\n+            AgentTurnResponseStepStartPayload,\n+            AgentTurnResponseStepProgressPayload,\n+            AgentTurnResponseStepCompletePayload,\n+            AgentTurnResponseTurnStartPayload,\n+            AgentTurnResponseTurnCompletePayload,\n+        ],\n+        Field(discriminator=""""event_type""""),\n+    ]\n+\n+\n+@json_schema_type\n+class AgentCreateResponse(BaseModel):\n+    agent_id: str\n+\n+\n+@json_schema_type\n+class AgentSessionCreateResponse(BaseModel):\n+    session_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnCreateRequest(AgentConfigOverridablePerTurn):\n+    agent_id: str\n+    session_id: str\n+\n+    # TODO: figure out how we can simplify this and make why\n+    # ToolResponseMessage needs to be here (it is function call\n+    # execution from outside the system)\n+    messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n+        ]\n+    ]\n+    attachments: Optional[List[Attachment]] = None\n+\n+    stream: Optional[bool] = False\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStreamChunk(BaseModel):\n+    event: AgentTurnResponseEvent\n+\n+\n+@json_schema_type\n+class AgentStepResponse(BaseModel):\n+    step: Step\n+\n+\n+@runtime_checkable\n+class Agents(Protocol):\n+    @webmethod(route=""""/agents/create"""")\n+    async def create_agent(\n+        self,\n+        agent_config: AgentConfig,\n+    ) -> AgentCreateResponse: ...\n+\n+    # This method is not `async def` because it can result in either an\n+    # `AsyncGenerator` or a `AgentTurnCreateResponse` depending on the value of `stream`.\n+    @webmethod(route=""""/agents/turn/create"""")\n+    def create_agent_turn(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        messages: List[\n+            Union[\n+                UserMessage,\n+                ToolResponseMessage,\n+            ]\n+        ],\n+        attachments: Optional[List[Attachment]] = None,\n+        stream: Optional[bool] = False,\n+    ) -> AgentTurnResponseStreamChunk: ...\n+\n+    @webmethod(route=""""/agents/turn/get"""")\n+    async def get_agents_turn(\n+        self,\n+        agent_id: str,\n+        turn_id: str,\n+    ) -> Turn: ...\n+\n+    @webmethod(route=""""/agents/step/get"""")\n+    async def get_agents_step(\n+        self, agent_id: str, turn_id: str, step_id: str\n+    ) -> AgentStepResponse: ...\n+\n+    @webmethod(route=""""/agents/session/create"""")\n+    async def create_agent_session(\n+        self,\n+        agent_id: str,\n+        session_name: str,\n+    ) -> AgentSessionCreateResponse: ...\n+\n+    @webmethod(route=""""/agents/session/get"""")\n+    async def get_agents_session(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        turn_ids: Optional[List[str]] = None,\n+    ) -> Session: ...\n+\n+    @webmethod(route=""""/agents/session/delete"""")\n+    async def delete_agents_session(self, agent_id: str, session_id: str) -> None: ...\n \n-    async def run_shield(\n-        self, shield_type: str, messages: List[Message], params: Dict[str, Any] = None\n-    ) -> RunShieldResponse:\n-        shield_def = await self.shield_store.get_shield(shield_type)\n-        if not shield_def:\n-            raise ValueError(f""""Unknown shield {shield_type}"""")\n-\n-        model = shield_def.params.get(""""model"""", """"llama_guard"""")\n-        if model not in TOGETHER_SHIELD_MODEL_MAP:\n-            raise ValueError(f""""Unsupported safety model: {model}"""")\n-\n-        together_api_key = None\n-        if self.config.api_key is not None:\n-            together_api_key = self.config.api_key\n-        else:\n-            provider_data = self.get_request_provider_data()\n-            if provider_data is None or not provider_data.together_api_key:\n-                raise ValueError(\n-                    'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n-                )\n-            together_api_key = provider_data.together_api_key\n-\n-        # messages can have role assistant or user\n-        api_messages = []\n-        for message in messages:\n-            if message.role in (Role.user.value, Role.assistant.value):\n-                api_messages.append({""""role"""": message.role, """"content"""": message.content})\n-\n-        violation = await get_safety_response(\n-            together_api_key, TOGETHER_SHIELD_MODEL_MAP[model], api_messages\n-        )\n-        return RunShieldResponse(violation=violation)\n-\n-\n-async def get_safety_response(\n-    api_key: str, model_name: str, messages: List[Dict[str, str]]\n-) -> Optional[SafetyViolation]:\n-    client = Together(api_key=api_key)\n-    response = client.chat.completions.create(messages=messages, model=model_name)\n-    if len(response.choices) == 0:\n-        return None\n-\n-    response_text = response.choices[0].message.content\n-    if response_text == """"safe"""":\n-        return None\n-\n-    parts = response_text.split(""""\n"""")\n-    if len(parts) != 2:\n-        return None\n-\n-    if parts[0] == """"unsafe"""":\n-        return SafetyViolation(\n-            violation_level=ViolationLevel.ERROR,\n-            metadata={""""violation_type"""": parts[1]},\n-        )\n-\n-    return None\n+    @webmethod(route=""""/agents/delete"""")\n+    async def delete_agents(\n+        self,\n+        agent_id: str,\n+    ) -> None: ...\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/80","80","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily involve the `project/api/llama_stack/cli/model/prompt_format.py` file, which has undergone a significant transformation from a command-line interface (CLI) model prompt format to a new framework centered on memory bank definitions. The previous implementation, which included the `ModelPromptFormat` class for handling CLI arguments and model descriptions, has been entirely removed.\n\nIn its place, several new classes and data structures have been introduced to define different types of memory banks, utilizing Pydantic for data validation and serialization. A new enumeration, `MemoryBankType`, categorizes memory banks into four distinct types: `vector`, `keyvalue`, `keyword`, and `graph`. Each type is represented by its own Pydantic model, which derives from a common base class named `CommonDef`. This base class includes an ASCII-compatible identifier and an optional provider ID.\n\nAdditionally, a type alias `MemoryBankDef` has been created as a union of the specific memory bank models, along with a protocol named `MemoryBanks` that defines asynchronous methods for managing memory banks. This protocol includes annotations for HTTP routes and methods, marking a shift towards a more structured approach in managing memory bank definitions and their operations.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import argparse\n-import textwrap\n-from io import StringIO\n-\n-from llama_models.datatypes import CoreModelId, is_multimodal, model_family, ModelFamily\n-\n-from llama_stack.cli.subcommand import Subcommand\n-\n-\n-class ModelPromptFormat(Subcommand):\n-    """"""""""""Llama model cli for describe a model prompt format (message formats)""""""""""""\n-\n-    def __init__(self, subparsers: argparse._SubParsersAction):\n-        super().__init__()\n-        self.parser = subparsers.add_parser(\n-            """"prompt-format"""",\n-            prog=""""llama model prompt-format"""",\n-            description=""""Show llama model message formats"""",\n-            epilog=textwrap.dedent(\n-                """"""""""""\n-                Example:\n-                    llama model prompt-format <options>\n-                """"""""""""\n-            ),\n-            formatter_class=argparse.RawTextHelpFormatter,\n-        )\n-        self._add_arguments()\n-        self.parser.set_defaults(func=self._run_model_template_cmd)\n-\n-    def _add_arguments(self):\n-        self.parser.add_argument(\n-            """"-m"""",\n-            """"--model-name"""",\n-            type=str,\n-            default=""""llama3_1"""",\n-            help=""""Model Family (llama3_1, llama3_X, etc.)"""",\n-        )\n-\n-    def _run_model_template_cmd(self, args: argparse.Namespace) -> None:\n-        import pkg_resources\n-\n-        # Only Llama 3.1 and 3.2 are supported\n-        supported_model_ids = [\n-            m\n-            for m in CoreModelId\n-            if model_family(m) in {ModelFamily.llama3_1, ModelFamily.llama3_2}\n-        ]\n-        model_str = """"\n"""".join([m.value for m in supported_model_ids])\n-        try:\n-            model_id = CoreModelId(args.model_name)\n-        except ValueError:\n-            self.parser.error(\n-                f""""{args.model_name} is not a valid Model. Choose one from --\n{model_str}""""\n-            )\n-\n-        if model_id not in supported_model_ids:\n-            self.parser.error(\n-                f""""{model_id} is not a valid Model. Choose one from --\n {model_str}""""\n-            )\n-\n-        llama_3_1_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_1/prompt_format.md""""\n-        )\n-        llama_3_2_text_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/text_prompt_format.md""""\n-        )\n-        llama_3_2_vision_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/vision_prompt_format.md""""\n-        )\n-        if model_family(model_id) == ModelFamily.llama3_1:\n-            with open(llama_3_1_file, """"r"""") as f:\n-                content = f.read()\n-        elif model_family(model_id) == ModelFamily.llama3_2:\n-            if is_multimodal(model_id):\n-                with open(llama_3_2_vision_file, """"r"""") as f:\n-                    content = f.read()\n-            else:\n-                with open(llama_3_2_text_file, """"r"""") as f:\n-                    content = f.read()\n-\n-        render_markdown_to_pager(content)\n-\n-\n-def render_markdown_to_pager(markdown_content: str):\n-    from rich.console import Console\n-    from rich.markdown import Markdown\n-    from rich.style import Style\n-    from rich.text import Text\n-\n-    class LeftAlignedHeaderMarkdown(Markdown):\n-        def parse_header(self, token):\n-            level = token.type.count(""""h"""")\n-            content = Text(token.content)\n-            header_style = Style(color=""""bright_blue"""", bold=True)\n-            header = Text(f""""{'#' * level} """", style=header_style) + content\n-            self.add_text(header)\n-\n-    # Render the Markdown\n-    md = LeftAlignedHeaderMarkdown(markdown_content)\n-\n-    # Capture the rendered output\n-    output = StringIO()\n-    console = Console(file=output, force_terminal=True, width=100)  # Set a fixed width\n-    console.print(md)\n-    rendered_content = output.getvalue()\n-    print(rendered_content)\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str  # Must be ASCII-compatible identifier\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str  # Model name in ASCII format\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None: ...\n","project/api/llama_stack/cli/model/prompt_format.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/83","83","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the `inference.py` file. The endpoint URLs for three methods have been modified from a generic format to a versioned format. Specifically, the routes for the `completion`, `chat_completion`, and `embeddings` methods have been changed from `/inference/completion`, `/inference/chat_completion`, and `/inference/embeddings` to `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`, respectively. \n\nDespite these changes to the endpoint URLs, the method signatures and internal logic of the methods remain unchanged. The `completion` and `chat_completion` methods continue to operate synchronously, while the `embeddings` method remains asynchronous. Additionally, there are no alterations to the parameters or return types of these methods. The overall structure and functionality of the `Inference` class are preserved, ensuring that the methods can still be invoked as before, albeit through updated routes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `CompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/completion"""")\n+    @webmethod(route=""""/v1/completion"""")\n     def completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/83","83","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the `inference.py` file. The endpoint URLs for three methods have been modified from a generic format to a versioned format. Specifically, the routes for the `completion`, `chat_completion`, and `embeddings` methods have been changed from `/inference/completion`, `/inference/chat_completion`, and `/inference/embeddings` to `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`, respectively. \n\nDespite these changes to the endpoint URLs, the method signatures and internal logic of the methods remain unchanged. The `completion` and `chat_completion` methods continue to operate synchronously, while the `embeddings` method remains asynchronous. Additionally, there are no alterations to the parameters or return types of these methods. The overall structure and functionality of the `Inference` class are preserved, ensuring that the methods can still be invoked as before, albeit through updated routes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `ChatCompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/chat_completion"""")\n+    @webmethod(route=""""/v1/chat_completion"""")\n     def chat_completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/83","83","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the routing of web methods within the `Inference` protocol of the `inference.py` file. The endpoint URLs for three methods have been modified from a generic format to a versioned format. Specifically, the routes for the `completion`, `chat_completion`, and `embeddings` methods have been changed from `/inference/completion`, `/inference/chat_completion`, and `/inference/embeddings` to `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`, respectively. \n\nDespite these changes to the endpoint URLs, the method signatures and internal logic of the methods remain unchanged. The `completion` and `chat_completion` methods continue to operate synchronously, while the `embeddings` method remains asynchronous. Additionally, there are no alterations to the parameters or return types of these methods. The overall structure and functionality of the `Inference` class are preserved, ensuring that the methods can still be invoked as before, albeit through updated routes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         logprobs: Optional[LogProbConfig] = None,\n     ) -> Union[ChatCompletionResponse, ChatCompletionResponseStreamChunk]: ...\n \n-    @webmethod(route=""""/inference/embeddings"""")\n+    @webmethod(route=""""/v1/embeddings"""")\n     async def embeddings(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/84","84","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `MetaReferenceAgentsImpl` class located in `agents.py`. The modifications primarily affect two methods: `create_agent_turn` and `_create_agent_turn_streaming`. \n\nIn the `create_agent_turn` method, the logic for returning a streaming response has been updated. The method now checks if `attachments` is `None` in addition to the `stream` flag being `True`. This allows for a streaming response under these conditions, whereas previously, a streaming response was only returned if `stream` was `True`. If neither condition is satisfied, the method raises a `NotImplementedError` for non-streaming agent turns.\n\nThe `_create_agent_turn_streaming` method has also been modified. The logic now includes a check for `request.stream` being `False` and the presence of `request.attachments` before invoking `get_agent`. This introduces a dependency on both the `stream` flag and the existence of attachments, thereby altering the flow of how agents are retrieved based on the request's attributes.\n\nOverall, these changes refine the control flow for creating and streaming agent turns, particularly concerning attachment handling.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","             attachments=attachments,\n             stream=True,\n         )\n-        if stream:\n+        if stream or attachments is None:\n             return self._create_agent_turn_streaming(request)\n         else:\n             raise NotImplementedError(""""Non-streaming agent turns not yet implemented"""")\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/84","84","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `MetaReferenceAgentsImpl` class located in `agents.py`. The modifications primarily affect two methods: `create_agent_turn` and `_create_agent_turn_streaming`. \n\nIn the `create_agent_turn` method, the logic for returning a streaming response has been updated. The method now checks if `attachments` is `None` in addition to the `stream` flag being `True`. This allows for a streaming response under these conditions, whereas previously, a streaming response was only returned if `stream` was `True`. If neither condition is satisfied, the method raises a `NotImplementedError` for non-streaming agent turns.\n\nThe `_create_agent_turn_streaming` method has also been modified. The logic now includes a check for `request.stream` being `False` and the presence of `request.attachments` before invoking `get_agent`. This introduces a dependency on both the `stream` flag and the existence of attachments, thereby altering the flow of how agents are retrieved based on the request's attributes.\n\nOverall, these changes refine the control flow for creating and streaming agent turns, particularly concerning attachment handling.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhX0PTNOAtMAHAAsGjDjXr7+QSGIYQyYkKfoDAzSU4dhuLddvhfPhKvAMERIABVGwAGS4AG1YLhcNxEBwAPQYojqWD9DRMZgYphKKiqdTaDEAcWB2zAtjAABFqD0SLgMdwfN4MZcALoACmRqPRWJxAPxhOJimU5NwlJp3jpDOZcqm7M5vh5FwAlNd3LclIgGBR4NxxK0eBR8OUlBt1vBXjRkADqGNUBq/AFgqEukc0IlmNQHTlvPJjSRkiN5ADPARgZAEQADdIkmVqOXwDEkRYkUpZCrVCiJgVCtGY7G4iUsKWklTpynZ3NlAuUXWQABy+HQtFo6iKGBykCUGe8yGKCh2JAAHmEVPg8GNPAw5hDpPw+LsI7hsAFkOCGN5sLaUFgY3dPY8fS5PLxrVtouDF0PpMbTeaMBojPojCYoGR6Pguw4AQxBkMowwKKw7BcLw/DCKI4hSDIYbSmS6ZaDo+i/jcmzIG8/ogaQ5BUBBhJsDsXBUJUkB9M4rjvChtayhhuhgIYxjgGARi3iIYgYmg3CZr4aCBgA+s8aAMAA1hyVo2pQiAYvAzDcKOGJsHKokBJuAQYN8/FEbgiloIZiAaNwsgcAYMQ2QYFiQHEACSoHEZGNFOIG9GAYwK6kIg+qeL2uxAeCuBWrQ2DfMgzCKPA+yOv2zpdmeiYALJsmgNgkDpZDfHEpmOSp3iJow3g9HuWCJiZ7BmRZiYADQ0dwohxcGvjyDkNAmhCT7ePgOIMF0uKPil4bJKJ1U7KJ24UBgJWYPQiaiWNNATYZ007hg4lhRGgwQiVGmwIoZmQI5lUrSQa3sBts0NU+TD2u+kBAnwAQzYUPVoDRO0ieCkK7twrRTJAcwyCQZCQNg3C0G5BAngeR6eF9y6iFJz3jlVKKSbA5FGSVpx/ZAiaduQibXHAqDLpgpDoCClTOrch2KOEXZvZt6DfQEv09QDQOeHFkAkLi0yJs8XPMCVqCJtAFAhCVGPUHKy644gkvIMTrQkHdlTjFzyC8Pm86IKGKBhK0Jts7N0RfWLu2E7zGDAwLos/RLvrqzLcvXI5QHkMLfAPb2T2oBpjXqP42hTHhROdrghWqSQuN0AAohQVpFujfAYK0zSu4Tk3/JtZlGGdT5LRdV1Te923i39B1skdtCNWefUDSDRynBDaC0PkzzRHDKPSSgQGJl6TyaLbIlq0TABiORTPN6xE2PoRaFjys1fNASWtI7DvNlxRLiGhOJqQuCV7gZM4RVYWKJFa7I60Qf9oOSjNesuXyBaKWT27uxlZCBaT4DZTD0p4byitsYq0ajrB0sBaZdQZp4f+oJ+BAQLg8MKFRsh+AEKyACp5bgr2eAAcn1laZqFBxDSE/AYAA8lIKgvhm63CpquZAZAVzfHuq0W+fgUHUQCEQFwvYepHWohg96eFt4XUOEvX+dBGrcBcOIBgPgXAm0fAEMqT04ZnhXLQbwhMIHrxxjVWh5hLBxG8F1IMQMWZPiUAeFwdjHZoMFlOQGVDojjk5AIIxg12B9mkF+SA6UATM0QPAIgA4ZoTGhpGLgiYlBAQrgXG6GB+RTG8LsRq6SthcDFo1KOUTWiiQKZzRqbBECIGquiSAsIkC4ARFCQorQWlTAoOlGp1VGrQHwMCLKiBAaOxIN02ppBeS8jyaYlWXA6Fmhft4BEjTngIjiLM9gUzIAAF4Oya2Ka7eZizWg5ARAIAZ3heS7MgHPUcJBtS6D0A5RAsg9JUjAiRYokssDOJqUTcJmVsqUFyiQfKNV47FRPETHiCF+KCQxMJMSElpKyTvKSRSylVKKQ0mgLSwLdL6QLsZUy5lZAlUAEmERMUmMC5qtdJ70skkByXk9aFSik0R+P2cptBClhSqT8OpXBVnNNaf2DplBxm9JgJcoZIyphSsmdM9Amydj1IWe+M5Ir1mqtwNsvZJMSCHPFsczVyyLnAmuXsu5UxHlsReW8hgHzXIEAzo+P56tAVZRymA8FarIU/JhVaXi7IBJCTKsipWMlbzyQoJioqOKMr4p9US0yBlzF1UgPybOPlqb8ywFEmJ1AdxGveAuVuDpIAxSCgcXUBgoDhMbjRaJsSS2QwScMJJPRHXPiAstOll0GWbRrnbCETKWUPG9M8LgfrcDQE2gAYQHVlKduA7XPLiK895nzqDfOhR6gFGVvUgt9QVIqgbEywr4mGxFEa8UoujXJe8calIJvUkm7SJ7U01XTWqsllKibdr0r2yA/atyDvWtXX+f1x25MnePGdhl52zSXeBld4910Ou3S6vd7qyr/LSkegloLZ2IADdCy9wa4U3qRfeqNaLY3xuxe+zSn7CUkF/UZTjtVyVZpzWwmmj5C2toCI1AQ5b+qVura1OgdabIxC/GxH8nFBZLwgYkFy4FohkWghHaitFPLyFGKmNC6gWJYRU2RdQPLED4vKFUOg20VGsXYthWo2UAAMAB2M4Xnai7DOAATjOAAVhC4FkLiwGAAGYPOBei7QXYiWliLB7AIQLtQGC0EWF53LLnlMQEgoMc+WxbPNgc7QUS/4XNAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self,\n         request: AgentTurnCreateRequest,\n     ) -> AsyncGenerator:\n-        agent = await self.get_agent(request.agent_id)\n+        if not request.stream and request.attachments:\n+            agent = await self.get_agent(request.agent_id)\n         async for event in agent.create_and_execute_turn(request):\n             yield event\n \n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/86","86","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute, `score_threshold`, is added to the `RewardScoringRequest` class, which has a default value of `0.0`. This new attribute allows users to specify a threshold for scoring in their requests.\n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is updated to include the `score_threshold` parameter, which also defaults to `0.0`. The implementation of this method is modified to incorporate logic that processes both the `dialog_generations` and `score_threshold` parameters. Specifically, if the `dialog_generations` list is empty, the method will return an empty `RewardScoringResponse`. If the `score_threshold` is greater than or equal to `0`, the method will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These modifications enhance the functionality of the reward scoring mechanism by enabling the specification and handling of a scoring threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     dialog_generations: List[DialogGenerations]\n     model: str\n+    score_threshold: float = 0.0\n \n \n @json_schema_type\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/86","86","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute, `score_threshold`, is added to the `RewardScoringRequest` class, which has a default value of `0.0`. This new attribute allows users to specify a threshold for scoring in their requests.\n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is updated to include the `score_threshold` parameter, which also defaults to `0.0`. The implementation of this method is modified to incorporate logic that processes both the `dialog_generations` and `score_threshold` parameters. Specifically, if the `dialog_generations` list is empty, the method will return an empty `RewardScoringResponse`. If the `score_threshold` is greater than or equal to `0`, the method will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These modifications enhance the functionality of the reward scoring mechanism by enabling the specification and handling of a scoring threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def reward_score(\n         self,\n         dialog_generations: List[DialogGenerations],\n-        model: str,\n-    ) -> Union[RewardScoringResponse]: ...\n+        model: str, \n+        score_threshold: float = 0.0,\n+    ) -> Union[RewardScoringResponse]:\n+        if not dialog_generations:\n+            return RewardScoringResponse(scored_generations=[])\n+        \n+        if score_threshold >= 0:\n+            return RewardScoringResponse(\n+                scored_generations=[\n+                    ScoredDialogGenerations(dialog=[], scored_generations=[])\n+                ])\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/87","87","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the `pgvector.py` file focus on enhancing the `PGVectorMemoryAdapter` class and its handling of memory banks. A new variable, `_bank_metadata_cache`, has been added to cache metadata related to memory banks. This cache is utilized across several methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding metadata is stored in the `_bank_metadata_cache`, and a commit operation is performed to save changes to the database. The `list_memory_banks` method has been updated to return memory banks with cached metadata instead of raw database results.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of a memory bank in the `_bank_metadata_cache` before proceeding to retrieve the associated index. If a bank is not found in the cache, a `ValueError` is raised. These modifications collectively enhance the management of memory bank metadata and improve the robustness of operations related to memory banks.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self.cursor = None\n         self.conn = None\n         self.cache = {}\n+        self._bank_metadata_cache = {}\n \n     async def initialize(self) -> None:\n         try:\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/87","87","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the `pgvector.py` file focus on enhancing the `PGVectorMemoryAdapter` class and its handling of memory banks. A new variable, `_bank_metadata_cache`, has been added to cache metadata related to memory banks. This cache is utilized across several methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding metadata is stored in the `_bank_metadata_cache`, and a commit operation is performed to save changes to the database. The `list_memory_banks` method has been updated to return memory banks with cached metadata instead of raw database results.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of a memory bank in the `_bank_metadata_cache` before proceeding to retrieve the associated index. If a bank is not found in the cache, a `ValueError` is raised. These modifications collectively enhance the management of memory bank metadata and improve the robustness of operations related to memory banks.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                 (memory_bank.identifier, memory_bank),\n             ],\n         )\n+        self._bank_metadata_cache[memory_bank.identifier] = memory_bank\n \n         index = BankWithIndex(\n             bank=memory_bank,\n             index=PGVectorIndex(memory_bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n         )\n         self.cache[memory_bank.identifier] = index\n+        self.conn.commit()\n \n     async def list_memory_banks(self) -> List[MemoryBankDef]:\n         banks = load_models(self.cursor, MemoryBankDef)\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/87","87","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the `pgvector.py` file focus on enhancing the `PGVectorMemoryAdapter` class and its handling of memory banks. A new variable, `_bank_metadata_cache`, has been added to cache metadata related to memory banks. This cache is utilized across several methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding metadata is stored in the `_bank_metadata_cache`, and a commit operation is performed to save changes to the database. The `list_memory_banks` method has been updated to return memory banks with cached metadata instead of raw database results.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of a memory bank in the `_bank_metadata_cache` before proceeding to retrieve the associated index. If a bank is not found in the cache, a `ValueError` is raised. These modifications collectively enhance the management of memory bank metadata and improve the robustness of operations related to memory banks.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                     index=PGVectorIndex(bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n                 )\n                 self.cache[bank.identifier] = index\n-        return banks\n+        return [self._bank_metadata_cache.get(bank.identifier, bank) for bank in banks]\n \n     async def insert_documents(\n         self,\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/87","87","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the `pgvector.py` file focus on enhancing the `PGVectorMemoryAdapter` class and its handling of memory banks. A new variable, `_bank_metadata_cache`, has been added to cache metadata related to memory banks. This cache is utilized across several methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding metadata is stored in the `_bank_metadata_cache`, and a commit operation is performed to save changes to the database. The `list_memory_banks` method has been updated to return memory banks with cached metadata instead of raw database results.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of a memory bank in the `_bank_metadata_cache` before proceeding to retrieve the associated index. If a bank is not found in the cache, a `ValueError` is raised. These modifications collectively enhance the management of memory bank metadata and improve the robustness of operations related to memory banks.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         documents: List[MemoryBankDocument],\n         ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/87","87","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes introduced in the `pgvector.py` file focus on enhancing the `PGVectorMemoryAdapter` class and its handling of memory banks. A new variable, `_bank_metadata_cache`, has been added to cache metadata related to memory banks. This cache is utilized across several methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding metadata is stored in the `_bank_metadata_cache`, and a commit operation is performed to save changes to the database. The `list_memory_banks` method has been updated to return memory banks with cached metadata instead of raw database results.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of a memory bank in the `_bank_metadata_cache` before proceeding to retrieve the associated index. If a bank is not found in the cache, a `ValueError` is raised. These modifications collectively enhance the management of memory bank metadata and improve the robustness of operations related to memory banks.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/85","85","Automated Test: @eval-junior-reviewer-1-new-sonnet","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `get_embedding_model` function located in `project/api/llama_stack/providers/utils/memory/vector_store.py`. The modifications focus on optimizing the loading process of embedding models by removing redundant code. The previous implementation always printed a loading message and instantiated the model, regardless of its existing state. The updated version first checks the `EMBEDDING_MODELS` dictionary to determine if the model is already loaded. If the model is not present, it prints a loading message, imports `SentenceTransformer`, creates a new model instance, and stores it in the dictionary. If the model is found in the dictionary, it retrieves the loaded model without printing the loading message or re-instantiating it. Importantly, there are no changes to the signatures of exported or public entities, and the overall structure and functionality of other methods in the file remain unchanged.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjGDklWCI+BjkuDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qBhOApTRABwArBqQAJJhDJiQO+gMDNJT9NRjngBm+L74lfAYRJAAqjYADJcADasFwuG4iA4AHoYUR1LB+homMwYUwlFRVOptDCAOLvJQYMC2MAAEWoPRIuBh3B83hhhwAugAKcGQ6FwhG4JECFEsdGKZTY3C4gneIkkmzkylTGl03yMg4ASmO7nGkCUiAYFHg3HErRQ63gFxoyB5Tx5qAVfgCwVCXR6OAIzGoJpy3nkOpIyRG8h5njx6gAEv1IJNpgADdIY4VqUXwGEkRYkUpZCrVCiR44AOXw6FotHURQwOU11O03mQxQUGBoAA8wip8Hhnow5j9pPw+HSKNx8FN+C82zb/EEQogmwEeBR8OUlBssAHy9rdfqSxojPojCYoGR6Phh2hEsQyMphgpWOwuLx+MJROIpDIvUKsfGtDp9LuYAhkKhLseBCnuQVAXqibB1lwVCVJAfTOK4VwvpiKjvtouhgIYxjgGARi8PgIhiDCaDcImvhoK6AD6k5oAwADWtKzvOlCIDCeDwFWMJsMwxSyDCUhiMUVEEAEGjcLIHAGDEUkGBYkBxCcwHntEcGughh7tpgpCIOqnhFi8w7fLgs60NgdzINxenugaGDmvmy6RqQuAUSQzA7IW3xEBRFkkN4kaQC8BRiCWRqQJGeEETSxGkd45FoEJNH0XhTEUCxbEcVxPF8Q+gmTsUJCibI2Y/p4DAdlpsFGT6zDeN8njLt4+BoEWPxDpALluc1vzeVWiFtTVgyluILUBCZ6yYOcQrHFYZRFJMnoADRtgFGBBYaOTdLIyC8IZ0RoJADVNR5kBsIgiBoKQayLtRdbwL6bbdWORAuLQUSna1lTjAGfDqI6yA5AETXyAdC7HB44bcLQd0NQiDD+fAKXnOMdF/sOy4PdaARTHWIX2QAogAsgAQrjZJkicOZ4hR+MAPJkrjgL2H5RaraWrjHCcBlhJs+C4ItP3bXWf37Y1nXHfc50kHzzD9hQuDIJG9jsGQdzQFQNlvBQbBZot3rJELjRGtddytWjQreItmD0LlmMoFzS4asz1kuLI7Ooxq6N/d4AO0EDIt0HzYRFgEYiemORkVE+tv+bOzBto7JbO10iItmEAtDb89Ui0dJ1nRdNYBGA3zXeIbotabSjeJuBh5hpnbIJmniuko4R2RqiDwEQg3YDb6kkPWMsXjWdICDVsPsMW0gW+sbZzsovgVRQpm4N3niW/5gVOzVuDyOpy4BK63zZ9SsCKH+9uvOxnj79oWCBWVdBV+YlhxN4NCgSWtlx6IMXv601bDn3Ae0Qh79FHm1G64hpBbkgDXHIb83R/xbl/BgP8EE2VaoA4og8eygJNOAiIFR667GOk1fKklpIGG3FhCA4CDxHhPKQECd1wLXn8GgGCKlE6jFjG+dQH50J6G/OBdQFF4C0EQBRGaVQ6DxVlgInc2F0AAAY0AAHY0AABY9iLFqC8RYSjtEADYACcJAlHGJorUPYGjNG1FoHowxAgDiLBTIsYxhjVHyOoVAYRTkxESKkdUWgzlp76CAA==\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n     global EMBEDDING_MODELS\n \n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n+    if model not in EMBEDDING_MODELS:\n+        print(f""""Loading sentence transformer for {model}..."""")\n+        from sentence_transformers import SentenceTransformer\n+        loaded_model = SentenceTransformer(model)\n+        EMBEDDING_MODELS[model] = loaded_model\n \n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n+    loaded_model = EMBEDDING_MODELS[model]\n     return loaded_model\n \n \n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/88","88","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `faiss.py` file involve a comprehensive restructuring of the codebase related to document embeddings and memory management. The `FaissIndex` class has been removed, and its functionalities have been integrated into a newly introduced `EmbeddingIndex` class, which includes abstract methods for adding chunks and querying embeddings. The `FaissMemoryImpl` class has been updated to work with the new `EmbeddingIndex`, leading to modifications in its `insert_documents` and `query_documents` methods.\n\nSeveral new utility functions have been added, such as `get_embedding_model` for loading sentence transformer models, `parse_data_url` for processing data URLs, and `content_from_data` for handling various MIME types and decoding base64 data. Additionally, the `content_from_doc` function has been revised to support both URL and data URI formats.\n\nThe introduction of the `make_overlapped_chunks` function allows for the creation of overlapping text chunks from documents. A new data class, `BankWithIndex`, has been added to encapsulate memory banks and their corresponding embedding indices. Overall, these changes enhance the document processing and embedding management capabilities within the code.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-\n-import logging\n-\n+import base64\n+import io\n+import re\n+from abc import ABC, abstractmethod\n+from dataclasses import dataclass\n from typing import Any, Dict, List, Optional\n+from urllib.parse import unquote\n \n-import faiss\n+import chardet\n+import httpx\n import numpy as np\n from numpy.typing import NDArray\n+from pypdf import PdfReader\n+from termcolor import cprint\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_models.llama3.api.tokenizer import Tokenizer\n \n from llama_stack.apis.memory import *  # noqa: F403\n-from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n-\n-from llama_stack.providers.utils.memory.vector_store import (\n-    ALL_MINILM_L6_V2_DIMENSION,\n-    BankWithIndex,\n-    EmbeddingIndex,\n-)\n-from llama_stack.providers.utils.telemetry import tracing\n-\n-from .config import FaissImplConfig\n-\n-logger = logging.getLogger(__name__)\n \n+ALL_MINILM_L6_V2_DIMENSION = 384\n+\n+EMBEDDING_MODELS = {}\n+\n+\n+def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n+    global EMBEDDING_MODELS\n+\n+    loaded_model = EMBEDDING_MODELS.get(model)\n+    if loaded_model is not None:\n+        return loaded_model\n+\n+    print(f""""Loading sentence transformer for {model}..."""")\n+    from sentence_transformers import SentenceTransformer\n+\n+    loaded_model = SentenceTransformer(model)\n+    EMBEDDING_MODELS[model] = loaded_model\n+    return loaded_model\n+\n+\n+def parse_data_url(data_url: str):\n+    data_url_pattern = re.compile(\n+        r""""^""""\n+        r""""data:""""\n+        r""""(?P<mimetype>[\w/\-+.]+)""""\n+        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n+        r""""(?P<base64>;base64)?""""\n+        r"""",(?P<data>.*)""""\n+        r""""$"""",\n+        re.DOTALL,\n+    )\n+    match = data_url_pattern.match(data_url)\n+    if not match:\n+        raise ValueError(""""Invalid Data URL format"""")\n+\n+    parts = match.groupdict()\n+    parts[""""is_base64""""] = bool(parts[""""base64""""])\n+    return parts\n+\n+\n+def content_from_data(data_url: str) -> str:\n+    parts = parse_data_url(data_url)\n+    data = parts[""""data""""]\n+\n+    if parts[""""is_base64""""]:\n+        data = base64.b64decode(data)\n+    else:\n+        data = unquote(data)\n+        encoding = parts[""""encoding""""] or """"utf-8""""\n+        data = data.encode(encoding)\n+\n+    encoding = parts[""""encoding""""]\n+    if not encoding:\n+        detected = chardet.detect(data)\n+        encoding = detected[""""encoding""""]\n+\n+    mime_type = parts[""""mimetype""""]\n+    mime_category = mime_type.split(""""/"""")[0]\n+    if mime_category == """"text"""":\n+        # For text-based files (including CSV, MD)\n+        return data.decode(encoding)\n+\n+    elif mime_type == """"application/pdf"""":\n+        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n+        pdf_bytes = io.BytesIO(data)\n+        pdf_reader = PdfReader(pdf_bytes)\n+        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n+\n+    else:\n+        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n+        return """"""""\n+\n+\n+async def content_from_doc(doc: MemoryBankDocument) -> str:\n+    if isinstance(doc.content, URL):\n+        if doc.content.uri.startswith(""""data:""""):\n+            return content_from_data(doc.content.uri)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content.uri)\n+                return r.text\n+\n+    pattern = re.compile(""""^(https?://|file://|data:)"""")\n+    if pattern.match(doc.content):\n+        if doc.content.startswith(""""data:""""):\n+            return content_from_data(doc.content)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content)\n+                return r.text\n+\n+    return interleaved_text_media_as_str(doc.content)\n+\n+\n+def make_overlapped_chunks(\n+    document_id: str, text: str, window_len: int, overlap_len: int\n+) -> List[Chunk]:\n+    tokenizer = Tokenizer.get_instance()\n+    tokens = tokenizer.encode(text, bos=False, eos=False)\n+\n+    chunks = []\n+    for i in range(0, len(tokens), window_len - overlap_len):\n+        toks = tokens[i : i + window_len]\n+        chunk = tokenizer.decode(toks)\n+        chunks.append(\n+            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n+        )\n \n-class FaissIndex(EmbeddingIndex):\n-    id_by_index: Dict[int, str]\n-    chunk_by_index: Dict[int, str]\n+    return chunks\n \n-    def __init__(self, dimension: int):\n-        self.index = faiss.IndexFlatL2(dimension)\n-        self.id_by_index = {}\n-        self.chunk_by_index = {}\n \n-    @tracing.span(name=""""add_chunks"""")\n+class EmbeddingIndex(ABC):\n+    @abstractmethod\n     async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        indexlen = len(self.id_by_index)\n-        for i, chunk in enumerate(chunks):\n-            self.chunk_by_index[indexlen + i] = chunk\n-            self.id_by_index[indexlen + i] = chunk.document_id\n-\n-        self.index.add(np.array(embeddings).astype(np.float32))\n+        raise NotImplementedError()\n \n+    @abstractmethod\n     async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        distances, indices = self.index.search(\n-            embedding.reshape(1, -1).astype(np.float32), k\n-        )\n-\n-        chunks = []\n-        scores = []\n-        for d, i in zip(distances[0], indices[0]):\n-            if i < 0:\n-                continue\n-            chunks.append(self.chunk_by_index[int(i)])\n-            scores.append(1.0 / float(d))\n-\n-        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+        raise NotImplementedError()\n \n \n-class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n-    def __init__(self, config: FaissImplConfig) -> None:\n-        self.config = config\n-        self.cache = {}\n-\n-    async def initialize(self) -> None: ...\n-\n-    async def shutdown(self) -> None: ...\n-\n-    async def register_memory_bank(\n-        self,\n-        memory_bank: MemoryBankDef,\n-    ) -> None:\n-        assert (\n-            memory_bank.type == MemoryBankType.vector.value\n-        ), f""""Only vector banks are supported {memory_bank.type}""""\n-\n-        index = BankWithIndex(\n-            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n-        )\n-        self.cache[memory_bank.identifier] = index\n-\n-    async def list_memory_banks(self) -> List[MemoryBankDef]:\n-        return [i.bank for i in self.cache.values()]\n+@dataclass\n+class BankWithIndex:\n+    bank: MemoryBankDef\n+    index: EmbeddingIndex\n \n     async def insert_documents(\n         self,\n-        bank_id: str,\n         documents: List[MemoryBankDocument],\n-        ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        await index.insert_documents(documents)\n+        model = get_embedding_model(self.bank.embedding_model)\n+        for doc in documents:\n+            content = await content_from_doc(doc)\n+            chunks = make_overlapped_chunks(\n+                doc.document_id,\n+                content,\n+                self.bank.chunk_size_in_tokens,\n+                self.bank.overlap_size_in_tokens\n+                or (self.bank.chunk_size_in_tokens // 4),\n+            )\n+            if not chunks:\n+                continue\n+            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n+            # Unstable order of chunks\n+            chunks = sorted(chunks, key=lambda x: hash(x.content))\n+            \n+            await self.index.add_chunks(chunks, embeddings)\n \n     async def query_documents(\n         self,\n-        bank_id: str,\n         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        return await index.query_documents(query, params)\n+        if params is None:\n+            params = {}\n+        k = params.get(""""max_chunks"""", 3)\n+\n+        def _process(c) -> str:\n+            if isinstance(c, str):\n+                return c\n+            else:\n+                return """"<media>""""\n+\n+        if isinstance(query, list):\n+            query_str = """" """".join([_process(c) for c in query])\n+        else:\n+            query_str = _process(query)\n+\n+        model = get_embedding_model(self.bank.embedding_model)\n+        query_vector = model.encode([query_str])[0].astype(np.float32)\n+        return await self.index.query(query_vector, k)\n","project/api/llama_stack/providers/impls/meta_reference/memory/faiss.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/89","89","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces optimizations to the `OpenTelemetryAdapter` class in the `opentelemetry.py` file, specifically targeting the conversion of string representations of trace and span IDs into integers. Two caching mechanisms, `_trace_id_cache` and `_span_id_cache`, are implemented to store previously computed values, each with a maximum capacity of 10,000 entries. The `string_to_trace_id` and `string_to_span_id` functions are updated to utilize these caches, checking for existing values before performing conversions. If the cache exceeds its size limit, it is cleared. Additionally, the `string_to_span_id` function employs a hash of the first three characters of the input string as a cache key. \n\nThe overall structure of the `OpenTelemetryAdapter` class remains unchanged, with no alterations to its public interface or method signatures. The implementation maintains consistent error handling and control flow, focusing solely on enhancing the efficiency of ID conversions without modifying the existing functionality related to logging events or managing telemetry data.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," from .config import OpenTelemetryConfig\n \n \n-def string_to_trace_id(s: str) -> int:\n-    # Convert the string to bytes and then to an integer\n-    return int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+# Optimization: Cache trace and span ID conversions\n+_trace_id_cache = {}\n+_span_id_cache = {}\n+_max_cache_size = 10000\n \n+def string_to_trace_id(s: str) -> int:\n+    if s not in _trace_id_cache:\n+        if len(_trace_id_cache) >= _max_cache_size:\n+            _trace_id_cache.clear()\n+        _trace_id_cache[s] = int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+    return _trace_id_cache[s]\n \n def string_to_span_id(s: str) -> int:\n-    # Use only the first 8 bytes (64 bits) for span ID\n-    return int.from_bytes(s.encode()[:8], byteorder=""""big"""", signed=False)\n+    # Optimization: Cache span ID conversions\n+    # Use hash of first few chars as cache key for better memory usage\n+    key = hash(s[:3]) % 1000  \n+    if key not in _span_id_cache:\n+        if len(_span_id_cache) >= _max_cache_size:\n+            _span_id_cache.clear()\n+        # Convert full span ID string to int value\n+        _span_id_cache[key] = int.from_bytes(s.encode(), byteorder=""""little"""", signed=False) \n+    return _span_id_cache[key]\n+\n \n \n def is_tracing_enabled(tracer):\n","project/api/llama_stack/providers/adapters/telemetry/opentelemetry/opentelemetry.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/90","90","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `server.py` file located in the `project/api/llama_stack/distribution/server` directory. The primary focus of these modifications is on the main function responsible for configuring and running the FastAPI application. A new parameter, `timeout_keep_alive`, has been added to the Uvicorn server configuration, setting its value to 5 seconds. This change indicates a more aggressive approach to managing connection timeouts.\n\nAdditionally, a comment has been added to highlight the introduction of """"risky assumptions about network reliability,"""" which suggests a shift in how network behavior is expected to be handled. Despite these updates, the overall structure of the application remains unchanged; the main function continues to read the YAML configuration, set up the FastAPI app, and define routes as before. The existing exception handling and signal handling for graceful shutdowns are preserved without modifications. Overall, the changes consist of adding new parameters and comments while maintaining the existing functionality and control flow of the application.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/91","91","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe recent changes to the `LocalInference` class in `LocalInference.swift` involve the addition of several new methods and modifications to existing functionality. New methods introduced include `encodeHeader`, `encodeDialogPrompt`, `getRole`, `encodeMessage`, `prepareMessages`, `maybeExtractCustomToolCalls`, and `decodeAssistantMessage`. These methods enhance the encoding and processing of messages, allowing for more structured handling of different message types.\n\nThe `encodeHeader` method formats a string based on a specified role, while `encodeDialogPrompt` constructs a prompt string from an array of messages, incorporating the encoded header. The `getRole` method identifies the role of a message, and `encodeMessage` encodes individual messages, considering their type and content. The `prepareMessages` method is responsible for preparing a list of messages, including system messages and user messages with tools.\n\nAdditionally, the error handling in the `loadModel` method has been removed, and the `chatCompletion` method has been significantly revised to integrate the new message processing logic. These changes collectively improve the message handling capabilities within the `LocalInference` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import Foundation\n \n-import LLaMARunner\n import LlamaStackClient\n \n-class RunnerHolder: ObservableObject {\n-  var runner: Runner?\n+func encodeHeader(role: String) -> String {\n+  return """"<|start_header_id|>\(role)<|end_header_id|>\n\n""""\n }\n \n-public class LocalInference: Inference {\n-  private var runnerHolder = RunnerHolder()\n-  private let runnerQueue: DispatchQueue\n+func encodeDialogPrompt(messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload]) -> String {\n+  var prompt = """"""""\n \n-  public init (queue: DispatchQueue) {\n-    runnerQueue = queue\n+  prompt.append(""""<|begin_of_text|>"""")\n+  for message in messages {\n+    let msg = encodeMessage(message: message)\n+    prompt += msg\n   }\n \n-  public func loadModel(modelPath: String, tokenizerPath: String, completion: @escaping (Result<Void, Error>) -> Void) {\n-    runnerHolder.runner = runnerHolder.runner ?? Runner(\n-      modelPath: modelPath,\n-      tokenizerPath: tokenizerPath\n-    )\n-\n-\n-    runnerQueue.async {\n-      let runner = self.runnerHolder.runner\n-      do {\n-        try runner!.load()\n-        completion(.success(()))\n-      } catch let loadError {\n-        print(""""error: """" + loadError.localizedDescription)\n-        completion(.failure(loadError))\n+  prompt.append(encodeHeader(role: """"assistant""""))\n+\n+  return prompt\n+}\n+\n+func getRole(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  switch (message) {\n+  case .UserMessage(let m):\n+    return m.role.rawValue\n+  case .SystemMessage(let m):\n+    return m.role.rawValue\n+  case .ToolResponseMessage(let m):\n+    return m.role.rawValue\n+  case .CompletionMessage(let m):\n+    return m.role.rawValue\n+  }\n+}\n+\n+func encodeMessage(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  var prompt = encodeHeader(role: getRole(message: message))\n+\n+  switch (message) {\n+  case .CompletionMessage(let m):\n+    if (m.tool_calls.count > 0) {\n+      prompt += """"<|python_tag|>""""\n+    }\n+  default:\n+    break\n+  }\n+\n+  func _processContent(_ content: Any) -> String {\n+    func _process(_ c: Any) {\n+      if let str = c as? String {\n+        prompt += str\n       }\n     }\n+\n+    if let str = content as? String {\n+      _process(str)\n+    } else if let list = content as? [Any] {\n+      for c in list {\n+        _process(c)\n+      }\n+    }\n+\n+    return """"""""\n   }\n \n-  public func stop() {\n-    runnerHolder.runner?.stop()\n+  switch (message) {\n+  case .UserMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .SystemMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .ToolResponseMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .CompletionMessage(let m):\n+    prompt += _processContent(m.content)\n   }\n \n-  public func chatCompletion(request: Components.Schemas.ChatCompletionRequest) -> AsyncStream<Components.Schemas.ChatCompletionResponseStreamChunk> {\n-    return AsyncStream { continuation in\n-      runnerQueue.async {\n-        do {\n-          var tokens: [String] = []\n-\n-          let prompt = try encodeDialogPrompt(messages: prepareMessages(request: request))\n-          var stopReason: Components.Schemas.StopReason? = nil\n-          var buffer = """"""""\n-          var ipython = false\n-          var echoDropped = false\n-\n-          try self.runnerHolder.runner?.generate(prompt, sequenceLength: 4096) { token in\n-            buffer += token\n-\n-            // HACK: Workaround until LlamaRunner exposes echo param\n-            if (!echoDropped) {\n-              if (buffer.hasPrefix(prompt)) {\n-                buffer = String(buffer.dropFirst(prompt.count))\n-                echoDropped = true\n-              }\n-              return\n-            }\n-\n-            tokens.append(token)\n-\n-            if !ipython && (buffer.starts(with: """"<|python_tag|>"""") || buffer.starts(with: """"["""") ) {\n-              ipython = true\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                      content: .case1(""""""""),\n-                      parse_status: Components.Schemas.ToolCallParseStatus.started\n-                      )\n-                    ),\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-\n-              if (buffer.starts(with: """"<|python_tag|>"""")) {\n-                buffer = String(buffer.dropFirst(""""<|python_tag|>"""".count))\n-              }\n-            }\n-\n-            // TODO: Non-streaming lobprobs\n-\n-            var text = """"""""\n-            if token == """"<|eot_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_turn\n-            } else if token == """"<|eom_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_message\n-            } else {\n-              text = token\n-            }\n-\n-            var delta: Components.Schemas.ChatCompletionResponseEvent.deltaPayload\n-            if ipython {\n-              delta = .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                content: .case1(text),\n-                parse_status: .in_progress\n-              ))\n-            } else {\n-              delta = .case1(text)\n-            }\n-\n-            if stopReason == nil {\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: delta,\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-            }\n-          }\n-\n-          if stopReason == nil {\n-            stopReason = Components.Schemas.StopReason.out_of_tokens\n-          }\n-\n-          let message = decodeAssistantMessage(tokens: tokens.joined(), stopReason: stopReason!)\n-          // TODO: non-streaming support\n-\n-          let didParseToolCalls = message.tool_calls.count > 0\n-          if ipython && !didParseToolCalls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(content: .case1(""""""""), parse_status: .failure)),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          for toolCall in message.tool_calls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                    content: .ToolCall(toolCall),\n-                    parse_status: .success\n-                  )),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          continuation.yield(\n-            Components.Schemas.ChatCompletionResponseStreamChunk(\n-              event: Components.Schemas.ChatCompletionResponseEvent(\n-                delta: .case1(""""""""),\n-                event_type: .complete\n-              )\n-              // TODO: stopReason\n-            )\n-          )\n-        }\n-        catch (let error) {\n-          print(""""Inference error: """" + error.localizedDescription)\n+  var eom = false\n+\n+  switch (message) {\n+  case .UserMessage(let m):\n+    switch (m.content) {\n+    case .case1(let c):\n+      prompt += _processContent(c)\n+    case .case2(let c):\n+      prompt += _processContent(c)\n+    }\n+  case .CompletionMessage(let m):\n+    // TODO: Support encoding past tool call history\n+    // for t in m.tool_calls {\n+    //  _processContent(t.)\n+    //}\n+    eom = m.stop_reason == Components.Schemas.StopReason.end_of_message\n+  case .SystemMessage(_):\n+    break\n+  case .ToolResponseMessage(_):\n+    break\n+  }\n+\n+  if (eom) {\n+    prompt += """"<|eom_id|>""""\n+  } else {\n+    prompt += """"<|eot_id|>""""\n+  }\n+\n+  return prompt\n+}\n+\n+func prepareMessages(request: Components.Schemas.ChatCompletionRequest) throws -> [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] {\n+  var existingMessages = request.messages\n+  var existingSystemMessage: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload?\n+  // TODO: Existing system message\n+\n+  var messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] = []\n+\n+  let defaultGen = SystemDefaultGenerator()\n+  let defaultTemplate = defaultGen.gen()\n+\n+  var sysContent = """"""""\n+\n+  // TODO: Built-in tools\n+\n+  sysContent += try defaultTemplate.render()\n+\n+  messages.append(.SystemMessage(Components.Schemas.SystemMessage(\n+    content: .case1(sysContent),\n+    role: .system))\n+  )\n+\n+  if request.tools?.isEmpty == false {\n+    // TODO: Separate built-ins and custom tools (right now everything treated as custom)\n+    let toolGen = FunctionTagCustomToolGenerator()\n+    let toolTemplate = try toolGen.gen(customTools: request.tools!)\n+    let tools = try toolTemplate.render()\n+    messages.append(.UserMessage(Components.Schemas.UserMessage(\n+      content: .case1(tools),\n+      role: .user)\n+    ))\n+  }\n+\n+  messages.append(contentsOf: existingMessages)\n+\n+  return messages\n+}\n+\n+struct FunctionCall {\n+    let name: String\n+    let params: [String: Any]\n+}\n+\n+public func maybeExtractCustomToolCalls(input: String) -> [Components.Schemas.ToolCall] {\n+  guard input.hasPrefix(""""["""") && input.hasSuffix(""""]"""") else {\n+    return []\n+  }\n+\n+  do {\n+    let trimmed = input.trimmingCharacters(in: CharacterSet(charactersIn: """"[]""""))\n+    let calls = trimmed.components(separatedBy: """"),"""").map { $0.hasSuffix("""")"""") ? $0 : $0 + """")"""" }\n+\n+    var result: [Components.Schemas.ToolCall] = []\n+\n+    for call in calls {\n+      guard let nameEndIndex = call.firstIndex(of: """"(""""),\n+            let paramsStartIndex = call.firstIndex(of: """"{""""),\n+            let paramsEndIndex = call.lastIndex(of: """"}"""") else {\n+        return []\n+      }\n+\n+      let name = String(call[..<nameEndIndex]).trimmingCharacters(in: .whitespacesAndNewlines)\n+      let paramsString = String(call[paramsStartIndex...paramsEndIndex])\n+\n+      guard let data = paramsString.data(using: .utf8),\n+            let params = try? JSONSerialization.jsonObject(with: data, options: []) as? [String: Any] else {\n+        return []\n+      }\n+\n+      var props: [String : Components.Schemas.ToolCall.argumentsPayload.additionalPropertiesPayload] = [:]\n+      for (param_name, param) in params {\n+        switch (param) {\n+        case let value as String:\n+          props[param_name] = .case1(value)\n+        case let value as Int:\n+          props[param_name] = .case2(value)\n+        case let value as Float: // Changed from Double to Float for less precise comparisons\n+          props[param_name] = .case3(value)\n+        case let value as Bool:\n+          props[param_name] = .case4(value)\n+        default:\n+          return []\n         }\n       }\n+\n+      result.append(\n+        Components.Schemas.ToolCall(\n+          arguments: .init(additionalProperties: props),\n+          call_id: UUID().uuidString,\n+          tool_name: .case2(name) // custom_tool\n+        )\n+      )\n+    }\n+\n+    return result.isEmpty ? [] : result\n+  } catch {\n+    return []\n+  }\n+}\n+\n+func decodeAssistantMessage(tokens: String, stopReason: Components.Schemas.StopReason) -> Components.Schemas.CompletionMessage {\n+  var content = tokens\n+\n+  let roles = [""""user"""", """"system"""", """"assistant""""]\n+  for role in roles {\n+    let headerStr = encodeHeader(role: role)\n+    if content.hasPrefix(headerStr) {\n+      content = String(content.dropFirst(encodeHeader(role: role).count))\n     }\n   }\n+\n+  if content.hasPrefix(""""<|python_tag|>"""") {\n+    content = String(content.dropFirst(""""<|python_tag|>"""".count))\n+  }\n+\n+\n+  if content.hasSuffix(""""<|eot_id|>"""") {\n+    content = String(content.dropLast(""""<|eot_id|>"""".count))\n+  } else {\n+    content = String(content.dropLast(""""<|eom_id|>"""".count))\n+  }\n+\n+  return Components.Schemas.CompletionMessage(\n+    content: .case1(content),\n+    role: .assistant,\n+    stop_reason: stopReason,\n+    tool_calls: maybeExtractCustomToolCalls(input: content)\n+  )\n }\n","project/api/llama_stack/providers/impls/ios/inference/LocalInferenceImpl/LocalInference.swift"
"github.com/coderabbitai/Golden-PR-Dataset/pull/93","93","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily involve the `batch_inference.py` file, which has undergone significant modifications to implement a new memory management system utilizing FAISS for vector storage and retrieval. A new class, `FaissIndex`, has been introduced, extending the `EmbeddingIndex` class, and includes methods for adding chunks and querying embeddings. This class manages dictionaries for mapping indices to document IDs and caching embeddings.\n\nAdditionally, the `FaissMemoryImpl` class has been added, implementing the `Memory` and `MemoryBanksProtocolPrivate` interfaces. It manages memory banks, allowing for the registration of memory banks and the insertion of documents into the FAISS index. The `insert_documents` and `query_documents` methods have been updated to include bank ID parameters, with error handling for non-existent bank IDs.\n\nSeveral existing classes related to batch processing, such as `BatchCompletionRequest`, have been removed, indicating a shift in the handling of batch operations. The import statements have been updated to include new dependencies like `faiss` and `numpy`, and logging functionality has been added for debugging purposes. Overall, the changes reflect a comprehensive overhaul of the batch inference functionality, focusing on a more sophisticated memory management system based on vector embeddings.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-from typing import List, Optional, Protocol, runtime_checkable\n+import logging\n \n-from llama_models.schema_utils import json_schema_type, webmethod\n+from typing import Any, Dict, List, Optional\n \n-from pydantic import BaseModel, Field\n+import faiss\n+import numpy as np\n+from numpy.typing import NDArray\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_stack.apis.inference import *  # noqa: F403\n \n+from llama_stack.apis.memory import *  # noqa: F403\n+from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n \n-@json_schema_type\n-class BatchCompletionRequest(BaseModel):\n-    model: str\n-    content_batch: List[InterleavedTextMedia]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n-    logprobs: Optional[LogProbConfig] = None\n+from llama_stack.providers.utils.memory.vector_store import (\n+    ALL_MINILM_L6_V2_DIMENSION,\n+    BankWithIndex,\n+    EmbeddingIndex,\n+)\n+from llama_stack.providers.utils.telemetry import tracing\n \n+from .config import FaissImplConfig\n \n-@json_schema_type\n-class BatchCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+logger = logging.getLogger(__name__)\n \n \n-@json_schema_type\n-class BatchChatCompletionRequest(BaseModel):\n-    model: str\n-    messages_batch: List[List[Message]]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n+class FaissIndex(EmbeddingIndex):\n+    id_by_index: Dict[int, str]\n+    chunk_by_index: Dict[int, str]\n+    embedding_cache: Dict[str, NDArray]\n+    _cached_distances = []\n \n-    # zero-shot tool definitions as input to the model\n-    tools: Optional[List[ToolDefinition]] = Field(default_factory=list)\n-    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n-    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n-        default=ToolPromptFormat.json\n-    )\n-    logprobs: Optional[LogProbConfig] = None\n+    def __init__(self, dimension: int):\n+        self.index = faiss.IndexFlatL2(dimension)\n+        self.id_by_index = {}\n+        self.chunk_by_index = {}\n+        self.embedding_cache = {}\n \n+    @tracing.span(name=""""add_chunks"""")\n+    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n+        indexlen = len(self.id_by_index)\n+        for i, chunk in enumerate(chunks):\n+            self.chunk_by_index[indexlen + i] = chunk\n+            self.id_by_index[indexlen + i] = chunk.document_id\n+            # Cache embeddings for each chunk\n+            self.embedding_cache[chunk.document_id] = embeddings[i]\n \n-@json_schema_type\n-class BatchChatCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+        self.index.add(np.array(embeddings).astype(np.float32))\n \n+    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n+        # Search through cache first before index\n+        cached_embeddings = np.array(list(self.embedding_cache.values()))\n+        if len(cached_embeddings) > 0:\n+            self._cached_distances, indices = self.index.search(\n+            embedding.reshape(1, -1).astype(np.float32), k\n+        )\n+            distances = self._cached_distances\n \n-@runtime_checkable\n-class BatchInference(Protocol):\n-    @webmethod(route=""""/batch_inference/completion"""")\n-    async def batch_completion(\n+        chunks = []\n+        scores = []\n+        for d, i in zip(self._cached_distances[0], indices[0]):\n+            if i < 0:\n+                continue\n+            chunks.append(self.chunk_by_index[int(i)])\n+            scores.append(1.0 / float(d))\n+\n+        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+\n+\n+class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n+    def __init__(self, config: FaissImplConfig) -> None:\n+        self.config = config\n+        self._memory_banks = {}\n+\n+    async def initialize(self) -> None: ...\n+\n+    async def shutdown(self) -> None: ...\n+\n+    async def register_memory_bank(\n+        self,\n+        memory_bank: MemoryBankDef,\n+    ) -> None:\n+        assert (\n+            memory_bank.type == MemoryBankType.vector.value\n+        ), f""""Only vector banks are supported {memory_bank.type}""""\n+\n+        index = BankWithIndex(\n+            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n+        )\n+        self._memory_banks[memory_bank.identifier] = index\n+\n+    async def list_memory_banks(self) -> List[MemoryBankDef]:\n+        # Stale cache - doesn't account for expired/deleted banks\n+        return [i.bank for i in self._memory_banks.values()]\n+\n+    async def insert_documents(\n         self,\n-        model: str,\n-        content_batch: List[InterleavedTextMedia],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchCompletionResponse: ...\n-\n-    @webmethod(route=""""/batch_inference/chat_completion"""")\n-    async def batch_chat_completion(\n+        bank_id: str,\n+        documents: List[MemoryBankDocument],\n+        ttl_seconds: Optional[int] = None,\n+    ) -> None:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            return  # Silently fail instead of raising error\n+\n+        await index.insert_documents(documents)\n+\n+    async def query_documents(\n         self,\n-        model: str,\n-        messages_batch: List[List[Message]],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        # zero-shot tool definitions as input to the model\n-        tools: Optional[List[ToolDefinition]] = list,\n-        tool_choice: Optional[ToolChoice] = ToolChoice.auto,\n-        tool_prompt_format: Optional[ToolPromptFormat] = ToolPromptFormat.json,\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchChatCompletionResponse: ...\n+        bank_id: str,\n+        query: InterleavedTextMedia,\n+        params: Optional[Dict[str, Any]] = None,\n+    ) -> QueryDocumentsResponse:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            raise ValueError(f""""Bank {bank_id} not found"""")\n+\n+        return await index.query_documents(query, params)\n","project/api/llama_stack/apis/batch_inference/batch_inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/92","92","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `vector_store.py` file involve a comprehensive restructuring of the memory bank management system. A new enumeration, `MemoryBankType`, has been introduced to classify various memory bank types, including vector, keyvalue, keyword, and graph. This is complemented by the addition of several Pydantic data classes, such as `CommonDef`, `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, which define the structure for different memory bank definitions.\n\nA new type alias, `MemoryBankDef`, has been established using `Annotated` and `Union`, which includes a discriminator field for type identification across the various memory bank types. Additionally, the `MemoryBanks` protocol has been defined, outlining asynchronous methods for listing, retrieving, and registering memory banks, with appropriate web method route annotations.\n\nThe update also involves the removal of outdated functions related to embedding model retrieval and data handling, signaling a shift towards a more modular and type-safe design. Furthermore, the `insert_documents` method in the `BankWithIndex` class has been updated to align with the new memory bank definitions. Overall, these changes aim to enhance the structural integrity and maintainability of the codebase.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-import base64\n-import io\n-import re\n-from abc import ABC, abstractmethod\n-from dataclasses import dataclass\n-from typing import Any, Dict, List, Optional\n-from urllib.parse import unquote\n-\n-import chardet\n-import httpx\n-import numpy as np\n-from numpy.typing import NDArray\n-from pypdf import PdfReader\n-from termcolor import cprint\n-\n-from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_models.llama3.api.tokenizer import Tokenizer\n-\n-from llama_stack.apis.memory import *  # noqa: F403\n-\n-ALL_MINILM_L6_V2_DIMENSION = 384\n-\n-EMBEDDING_MODELS = {}\n-\n-\n-def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n-    global EMBEDDING_MODELS\n-\n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n-\n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n-    return loaded_model\n-\n-\n-def parse_data_url(data_url: str):\n-    data_url_pattern = re.compile(\n-        r""""^""""\n-        r""""data:""""\n-        r""""(?P<mimetype>[\w/\-+.]+)""""\n-        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n-        r""""(?P<base64>;base64)?""""\n-        r"""",(?P<data>.*)""""\n-        r""""$"""",\n-        re.DOTALL,\n-    )\n-    match = data_url_pattern.match(data_url)\n-    if not match:\n-        raise ValueError(""""Invalid Data URL format"""")\n-\n-    parts = match.groupdict()\n-    parts[""""is_base64""""] = bool(parts[""""base64""""])\n-    return parts\n-\n-\n-def content_from_data(data_url: str) -> str:\n-    parts = parse_data_url(data_url)\n-    data = parts[""""data""""]\n-\n-    if parts[""""is_base64""""]:\n-        data = base64.b64decode(data)\n-    else:\n-        data = unquote(data)\n-        encoding = parts[""""encoding""""] or """"utf-8""""\n-        data = data.encode(encoding)\n-\n-    encoding = parts[""""encoding""""]\n-    if not encoding:\n-        detected = chardet.detect(data)\n-        encoding = detected[""""encoding""""]\n-\n-    mime_type = parts[""""mimetype""""]\n-    mime_category = mime_type.split(""""/"""")[0]\n-    if mime_category == """"text"""":\n-        # For text-based files (including CSV, MD)\n-        return data.decode(encoding)\n-\n-    elif mime_type == """"application/pdf"""":\n-        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n-        pdf_bytes = io.BytesIO(data)\n-        pdf_reader = PdfReader(pdf_bytes)\n-        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n-\n-    else:\n-        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n-        return """"""""\n-\n-\n-async def content_from_doc(doc: MemoryBankDocument) -> str:\n-    if isinstance(doc.content, URL):\n-        if doc.content.uri.startswith(""""data:""""):\n-            return content_from_data(doc.content.uri)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content.uri)\n-                return r.text\n-\n-    pattern = re.compile(""""^(https?://|file://|data:)"""")\n-    if pattern.match(doc.content):\n-        if doc.content.startswith(""""data:""""):\n-            return content_from_data(doc.content)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content)\n-                return r.text\n-\n-    return interleaved_text_media_as_str(doc.content)\n-\n-\n-def make_overlapped_chunks(\n-    document_id: str, text: str, window_len: int, overlap_len: int\n-) -> List[Chunk]:\n-    tokenizer = Tokenizer.get_instance()\n-    tokens = tokenizer.encode(text, bos=False, eos=False)\n-\n-    chunks = []\n-    for i in range(0, len(tokens), window_len - overlap_len):\n-        toks = tokens[i : i + window_len]\n-        chunk = tokenizer.decode(toks)\n-        chunks.append(\n-            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n-        )\n-\n-    return chunks\n-\n-\n-class EmbeddingIndex(ABC):\n-    @abstractmethod\n-    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        raise NotImplementedError()\n-\n-    @abstractmethod\n-    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        raise NotImplementedError()\n-\n-\n-@dataclass\n-class BankWithIndex:\n-    bank: MemoryBankDef\n-    index: EmbeddingIndex\n-\n-    async def insert_documents(\n-        self,\n-        documents: List[MemoryBankDocument],\n+\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+    _status: str = """"new""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider,\n     ) -> None:\n-        model = get_embedding_model(self.bank.embedding_model)\n-        for doc in documents:\n-            content = await content_from_doc(doc)\n-            chunks = make_overlapped_chunks(\n-                doc.document_id,\n-                content,\n-                self.bank.chunk_size_in_tokens,\n-                self.bank.overlap_size_in_tokens\n-                or (self.bank.chunk_size_in_tokens // 4),\n-            )\n-            if not chunks:\n-                continue\n-            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n-\n-            await self.index.add_chunks(chunks, embeddings)\n-\n-    async def query_documents(\n-        self,\n-        query: InterleavedTextMedia,\n-        params: Optional[Dict[str, Any]] = None,\n-    ) -> QueryDocumentsResponse:\n-        if params is None:\n-            params = {}\n-        k = params.get(""""max_chunks"""", 3)\n-\n-        def _process(c) -> str:\n-            if isinstance(c, str):\n-                return c\n-            else:\n-                return """"<media>""""\n-\n-        if isinstance(query, list):\n-            query_str = """" """".join([_process(c) for c in query])\n-        else:\n-            query_str = _process(query)\n-\n-        model = get_embedding_model(self.bank.embedding_model)\n-        query_vector = model.encode([query_str])[0].astype(np.float32)\n-        return await self.index.query(query_vector, k)\n+        memory_bank._status = """"registering"""" \n+        # Registration logic would go here\n+        memory_bank._status = """"active""""\n+        ...\n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/94","94","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `run_shield` method of the `TogetherSafetyImpl` class located in `together.py`. The primary modifications include the introduction of two `time.sleep` calls that create delays in the execution flow when managing the retrieval of the `together_api_key`. Specifically, a delay of 0.01 seconds is added after confirming that `self.config.api_key` is not `None`, and a longer delay of 0.1 seconds is added before raising a `ValueError` if `provider_data` is either `None` or lacks a valid `together_api_key`. These changes are intended to affect the timing of responses related to the API key retrieval process. Importantly, there are no modifications to the method signatures or the overall structure of the `TogetherSafetyImpl` class, and the existing logic for handling shields and responses from the safety model remains unchanged. Additionally, there are no alterations to the declarations of exported or public entities in this update.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and e64e36889897b65f2a34597fab052117f7c98b4a.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/providers/adapters/safety/together/together.py (1 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (2)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/providers/adapters/safety/together/together.py (2)</summary><blockquote>\n\n`59-60`: _:warning: Potential issue_\n\n**Remove arbitrary delays and address potential underlying issues.**\n\nThe added `time.sleep` calls introduce arbitrary delays in the execution flow, which could negatively impact performance without clear benefits. Additionally, the `time` module is not imported, which will cause a NameError.\n\n1. If these delays are attempting to mitigate an underlying issue (e.g., rate limiting, race conditions), it's better to address that issue directly rather than using arbitrary delays.\n2. If there's no specific reason for these delays, they should be removed to maintain optimal performance.\n\n\nTo resolve these issues:\n\n1. Remove the `time.sleep` calls:\n\n```diff\n- time.sleep(0.01)\n```\n\n```diff\n- time.sleep(0.1)\n```\n\n2. If there are underlying issues that need to be addressed, please provide more context so we can suggest a more appropriate solution.\n\n\nTo ensure there are no other occurrences of `time.sleep` or references to the `time` module, run the following script:\n\n```shell\n#!/bin/bash\n# Description: Check for usage of time.sleep and imports of the time module\n\necho """"Checking for time.sleep usage:""""\nrg 'time\.sleep'\n\necho """"\nChecking for time module imports:""""\nrg '^import time|^from time import'\n```\n\n\n\nAlso applies to: 63-63\n\n---\n\nLine range hint `1-93`: **Final Review Summary**\n\nThe changes introduced in this pull request add arbitrary delays to the `run_shield` method of the `TogetherSafetyImpl` class. These delays do not appear to serve a clear purpose and could negatively impact the performance of the safety checks.\n\nRecommendations:\n1. Remove the introduced `time.sleep` calls.\n2. If there are underlying issues (such as rate limiting or race conditions) that these delays were attempting to address, they should be handled more appropriately and documented clearly.\n3. Ensure that any changes to the API key handling or error conditions are thoroughly tested and do not introduce unexpected behavior.\n\nPlease provide more context about the reasons for these changes so that we can suggest more appropriate solutions if necessary.\n\n\nTo ensure that the removal of these changes doesn't affect other parts of the codebase, run the following script:\n\n```shell\n#!/bin/bash\n# Description: Check for any references to TogetherSafetyImpl or run_shield method\n\necho """"Checking for references to TogetherSafetyImpl:""""\nrg 'TogetherSafetyImpl'\n\necho """"\nChecking for references to run_shield method:""""\nrg 'run_shield'\n```\n\nThis will help identify any other parts of the codebase that might be relying on or affected by the behavior of the `run_shield` method.\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuX0TZAYTgKUkACcACwoWLi9/iTc+IjqRbIaMCfcPn4BwaGMmJBb6AwM0vmrYcdPIt8L58BV4BgiJAAKo2AAyXAA2rBcLhuIgOAB6TFEdSwVoaJjMTFMJRUVTqbSYgDiIPmYFsYAAItQmiRcJiHr5MfsALoAChRaIx2NxxwJRJJimUFNwVNp3npjJZcvyHK53h5ewAlLd3CclIgGBR4NxxPgsLx8GUlDNpvAGMlkMdqD1UBrTi9EGFGsg0IlmNQHTlvPJjSRkl15IDwvgQZAAAbpUkytRy+CYkg1EglLLlKoUBO3ABy+HQtFo6kKGBykCU6e8yCKCgWJAAHmEVPg8D1PAxhpDpPw+A8KOd8vxFr2vL5PSFvegAocGN5sLbDtPDcbTeaMBojPojCYoGR6Pgp/6CMQyMpOgpWOwuLx+MJROIpDIw9LyWmtDp9MedyzH6WCXoQpDkFQd5EmwCxcFQFSQC0ziuB8X5kiov7aLoYCGMY4BgEYVoiGImJoNwGa+GggYAPremgDAANachQ1pzJQiBkbQ5E0BQnGIGgizsrImIEKQgIUKJ+Dib0FAaNwsgcAYMQqQYFiQHEACS16QZGSFOIGqHnowA6kIg+qeJWixThCuCsbQ2A/MgzCKPAyyOruzpljGCYUNgGB0QgJCKgmkBsMcigNHiELTgm0DSeysn2IJwmacw3DeKFK5NMgMUJmJiWUPJshFncfamUOvDwIZ8ChocEgglI05oBWVYWpO4QVGW+XVSQGiIFEZxZSGXmHHZiiOZZwVoLIuVHCcTALKxfiLN4YINL0WADrQ3gQlCMYBHZ5TZH4xk+QVEk0eR8A0YxJAlbc9jcKIbnBr4sgADToIm4hsP1g3cPyAAMGhAwAjNqoWoC167VWwlbJHVgm8SZoiMXtKBTgm+TeIshIWssRBaBRt33VDyAYPgYQJqW5AJl9mCrD9vX/SQZzAxoEPk2N9mTV0JDAkuVBIBjaCJgAajkIQAKIUKxhaY7FVo2pQNHcXK3M0xaJChc2tD4EOlNhIt6agZAJ1zD9CWXddpMPWVE4tUI/S4LBuB+t4KMxr9GNnSc7aiHg1aQKtYJfecNALPAIbyIJQliBjsDrcEDqMXVMbhUn9ABIg5zTKNPwUKbLaVp5pxEC4laQtOcRWJpkB3TcRhxK1u4x19EmeC4niUyZmBmbG06Z5FlxEDWuDYDnw7Ttayizt6fliJPnh+323g5bcHiQGtuIMCHzbbbt1eIEFiogfQB3SHnE6LKxzDTgJQm4PILlKE8JCBhCc1ymIX3gsc04qqGXkMCBg/R+DzU8D7auq8NJ1wbvdU4R0si1itE5RA+4jBqUsHET2t5qyjRjEobKUECEdXbOcIu0RmwPAELtPe7AqzSAPJAUs6A8GkItIQg0oh16cIwE2KcFCih3hoa0ehkBGHiCHAWTwgYlAbmOKgKyeNlKqQMIefCEBJHTA6mBHSt5ogwUfP4NAiFkLALQgoDCso/w4T0IBGC6gaJzEQDRUo+Y6B0TlEXexR4CKSIAGx7BIAAZkCQADgiTsaJAB2AQgSACsiwahoFCXsRJOxYmLBUEDRJNQwZg2ybEhgMSBB7DFpoxxLB2i4BcbQNxHjKheNPPYoAA==\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         together_api_key = None\n         if self.config.api_key is not None:\n             together_api_key = self.config.api_key\n-        else:\n+            time.sleep(0.01)\n+        else:            \n             provider_data = self.get_request_provider_data()\n             if provider_data is None or not provider_data.together_api_key:\n+                time.sleep(0.1)\n                 raise ValueError(\n                     'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n                 )\n             together_api_key = provider_data.together_api_key\n-\n         # messages can have role assistant or user\n         api_messages = []\n         for message in messages:\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/95","95","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class within the `ollama.py` file. The `list_models` method has been updated to refine error handling by removing the try-except block that previously caught `httpx.ConnectError`. Instead, the method now processes the response from the client directly. The model registration logic remains unchanged, still raising a `ValueError` for unsupported dynamic model registration.\n\nIn addition, the `_get_params` method has been altered to handle the `prompt` parameter with ASCII encoding and decoding, ensuring non-ASCII characters are ignored. This change is also reflected in the `_nonstream_chat_completion` method, where the `text` field of the `OpenAICompatCompletionChoice` undergoes similar encoding and decoding modifications. While the overall control flow of the class remains intact, these changes enhance the robustness of model listing and response handling by focusing on ASCII character processing. The method signatures for both `_get_params` and `_nonstream_chat_completion` have been noted as updated, although there are no changes in their signatures.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def _get_params(self, request: ChatCompletionRequest) -> dict:\n         return {\n             """"model"""": OLLAMA_SUPPORTED_MODELS[request.model],\n-            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter),\n+            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter).encode('ascii', 'ignore').decode('ascii'),\n             """"options"""": get_sampling_options(request),\n             """"raw"""": True,\n             """"stream"""": request.stream,\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/95","95","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `OllamaInferenceAdapter` class within the `ollama.py` file. The `list_models` method has been updated to refine error handling by removing the try-except block that previously caught `httpx.ConnectError`. Instead, the method now processes the response from the client directly. The model registration logic remains unchanged, still raising a `ValueError` for unsupported dynamic model registration.\n\nIn addition, the `_get_params` method has been altered to handle the `prompt` parameter with ASCII encoding and decoding, ensuring non-ASCII characters are ignored. This change is also reflected in the `_nonstream_chat_completion` method, where the `text` field of the `OpenAICompatCompletionChoice` undergoes similar encoding and decoding modifications. While the overall control flow of the class remains intact, these changes enhance the robustness of model listing and response handling by focusing on ASCII character processing. The method signatures for both `_get_params` and `_nonstream_chat_completion` have been noted as updated, although there are no changes in their signatures.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n         choice = OpenAICompatCompletionChoice(\n             finish_reason=r[""""done_reason""""] if r[""""done""""] else None,\n-            text=r[""""response""""],\n+            text=r[""""response""""].encode('ascii', 'ignore').decode('ascii'),\n         )\n         response = OpenAICompatCompletionResponse(\n             choices=[choice],\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/97","97","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `server.py` file located in the `project/api/llama_stack/distribution/server` directory. A significant addition is the configuration of the `uvicorn` server, which now includes a new instantiation of `uvicorn.Config`. This configuration specifies parameters such as `host`, `port`, and a `timeout_keep_alive` set to 5 seconds. The introduction of this timeout is highlighted as an """"aggressive timeout"""" and may impact how the server manages client connections.\n\nFurthermore, the `uvicorn` library is imported to facilitate the running of the FastAPI application. While the overall control flow of the server remains unchanged, the new configuration parameters are expected to influence connection handling and timeout management with clients. The existing error handling mechanisms are preserved, and no new functions or modifications to existing function signatures are introduced. The changes primarily enhance the server's configuration capabilities without altering its fundamental operation.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/96","96","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request involve the addition of a new function called `calculate_similarity` in the `agents.py` file located within the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. It includes a check to ensure that both vectors are of equal length, returning `0.0` if they are not. The function attempts to calculate the dot product of the vectors and their magnitudes; however, it contains an error in the magnitude calculation as it does not include the necessary square root operation.\n\nFurthermore, an import statement for the `math` module has been added to the file, although this module is not used in the new function. The existing structure and functionality of the `MetaReferenceAgentsImpl` class remain unchanged, with no alterations made to any existing methods or their signatures.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuX0TZAYTgKUkACcAGwakACSYQyYkFvoDAzS+athuL2Qi/i++BXwGESQAKo2ADJcADasFwuG4iA4AHooUR1LBWhomMwoUwlFRVOptFCAOKveZgWxgAAi1CaJFwUO4Pm8UP2AF0ABSg8GQmFwx6I5GoxTKTG4bF47wEomkgX5SnU3x0vYASkO7ieSkQDAo8G44nwWF4+DKShm03gZxoyEe1B6qClfgCwVCDTWaESzGoRpy3nkqpIyS68kenhx6gAEq0rpqsECAAbpNF8tQC+BQkg1EglLLlKoUCNMlkQ6Gw+Fclg89EqOPYpMp0rpyjyyAAOXw6FotHUhQwOUgSnj3mQRQUCxIAA8wip8Hgep4GMMvtJ+HxqRRuPh8vxFhOvL5/EEQogRwEUBgGN5sPqD+vlar1WGNEZ9EYTFAyPR8GvHQRiGRlJ0FKx2FxePwwiiOIUgyB6vIYnGWg6PoD4wAgyCoOcb6EKQ5BUN+yJsAsXBUBUkAtM4rgXOBJb8tBuhgIYxjgGARg6iIYhQmg3AJr4aDOgA+ruaAMAA1lSFC6nMlCIFC8DMNwPZQmwAqcQEiyUGQNzMWhuBiWgamIBo3CyBwBgxIZBgWJAcRHB+6HegRTjOsRL6MNOpCIIqngtosa6fLgQm0NgNzIGg6yVM82CHmGkARmc3gMD4yTcRJ8DeC46iyBG4SNn64Waew2m6alyxRAANA0CBTj+1ImuuTCIJ8njVe0iVqrg8hbLgVRkOEFSNlIYhFNp8GeIsIViG2DmiHxiFrhlURfI8vaTU8nzlZA3UEBQyARt1ACMqWYPQG2iDUO37tuORFQEuDYBQGCfN8EYAAwaHdqXwPNJDyC4ngYPgmjHKcOTRYlFUZbQ308N5vlhPZGUrb1Uz0BlOo+WIq4TvAfDOkQ10XcqRUCOO6j9vGGD+c8iUVFwGUY1jJ6Tv9MVhSDs5fQ8aB8Z4GWIMEH3+Pg31FRUJWwCgyDkH5iAuPILx8AFTAUAEyNVTVBHxQ1yVlXgLpajeBhxM2rZam6shFRlElLhQYQ8TQ2FhFL64Rs6jypcwig+J4wwyCQ7VoM2dBFTkjxjkQQsE6gzOQHgCXwOM0QfI8nyVZdAQLA5mBOYcHj8FIVCbruFAQ5dni7cFoVtjkatQ08EYALIUmgNgkIpSc3HEWlHJJ3ipUeTTIAEzrx0Njm+w08LrI2ztua6Yamo2Q5IOIXyQLJsCKL2fB+mjyuY9QBfaUY5iWHE3g0BhbbT+eogNZrxMo0OZvfn21ICN4RqQOwrbSLekA1wHqw+7QXARiUGuSKANYp1QSklJqjItpcH+HPIEixvD4GoPSIq3UaiwPgYg5BuB6Syl0HoUmODnpYAjAxYCzFWJQnYlxHi/FBLCXRGJU20lZJoHkg3JSh4SCqWyrwhYOUUoGSMgYO8NEICv2mCjFCFkvzRCwn+fwaB8KEVss1UisZ1AUVgrRH87RcCcTmIgDhZRKh0G4gKc2lFqJwQAOwABZaD2L2AAZj2HdAArIsWxNx7EeM2vYhgm1FgCE2iQO6ex/G0EUgIAAHPY2xsS7pJjQHsax95dFYXUIY2gxiqxmNoJxJ81igA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import json\n import logging\n import uuid\n+import math\n from typing import AsyncGenerator\n \n from llama_stack.apis.inference import Inference\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/96","96","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request involve the addition of a new function called `calculate_similarity` in the `agents.py` file located within the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. It includes a check to ensure that both vectors are of equal length, returning `0.0` if they are not. The function attempts to calculate the dot product of the vectors and their magnitudes; however, it contains an error in the magnitude calculation as it does not include the necessary square root operation.\n\nFurthermore, an import statement for the `math` module has been added to the file, although this module is not used in the new function. The existing structure and functionality of the `MetaReferenceAgentsImpl` class remain unchanged, with no alterations made to any existing methods or their signatures.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuX0TZAYTgKUkACcAGwakACSYQyYkFvoDAzS+athuL2Qi/i++BXwGESQAKo2ADJcADasFwuG4iA4AHooUR1LBWhomMwoUwlFRVOptFCAOKveZgWxgAAi1CaJFwUO4Pm8UP2AF0ABSg8GQmFwx6I5GoxTKTG4bF47wEomkgX5SnU3x0vYASkO7ieSkQDAo8G44nwWF4+DKShm03gZxoyEe1B6qClfgCwVCDTWaESzGoRpy3nkqpIyS68kenhx6gAEq0rpqsECAAbpNF8tQC+BQkg1EglLLlKoUCNMlkQ6Gw+Fclg89EqOPYpMp0rpyjyyAAOXw6FotHUhQwOUgSnj3mQRQUCxIAA8wip8Hgep4GMMvtJ+HxqRRuPh8vxFhOvL5/EEQogRwEUBgGN5sPqD+vlar1WGNEZ9EYTFAyPR8GvHQRiGRlJ0FKx2FxePwwiiOIUgyB6vIYnGWg6PoD4wAgyCoOcb6EKQ5BUN+yJsAsXBUBUkAtM4rgXOBJb8tBuhgIYxjgGARg6iIYhQmg3AJr4aDOgA+ruaAMAA1lSFC6nMlCIFC8DMNwPZQmwAqcQEiyUGQNzMWhuBiWgamIBo3CyBwBgxIZBgWJAcRHB+6HegRTjOsRL6MNOpCIIqngtosa6fLgQm0NgNzIGg6yVM82CHmGkARmc3gMD4yTcRJ8DeC46iyBG4SNn64Waew2m6alyxRAANA0CBTj+1ImuuTCIJ8njVe0iVqrg8hbLgVRkOEFSNlIYhFNp8GeIsIViG2DmiHxiFrhlURfI8vaTU8nzlZA3UEBQyARt1ACMqWYPQG2iDUO37tuORFQEuDYBQGCfN8EYAAwaHdqXwPNJDyC4ngYPgmjHKcOTRYlFUZbQ308N5vlhPZGUrb1Uz0BlOo+WIq4TvAfDOkQ10XcqRUCOO6j9vGGD+c8iUVFwGUY1jJ6Tv9MVhSDs5fQ8aB8Z4GWIMEH3+Pg31FRUJWwCgyDkH5iAuPILx8AFTAUAEyNVTVBHxQ1yVlXgLpajeBhxM2rZam6shFRlElLhQYQ8TQ2FhFL64Rs6jypcwig+J4wwyCQ7VoM2dBFTkjxjkQQsE6gzOQHgCXwOM0QfI8nyVZdAQLA5mBOYcHj8FIVCbruFAQ5dni7cFoVtjkatQ08EYALIUmgNgkIpSc3HEWlHJJ3ipUeTTIAEzrx0Njm+w08LrI2ztua6Yamo2Q5IOIXyQLJsCKL2fB+mjyuY9QBfaUY5iWHE3g0BhbbT+eogNZrxMo0OZvfn21ICN4RqQOwrbSLekA1wHqw+7QXARiUGuSKANYp1QSklJqjItpcH+HPIEixvD4GoPSIq3UaiwPgYg5BuB6Syl0HoUmODnpYAjAxYCzFWJQnYlxHi/FBLCXRGJU20lZJoHkg3JSh4SCqWyrwhYOUUoGSMgYO8NEICv2mCjFCFkvzRCwn+fwaB8KEVss1UisZ1AUVgrRH87RcCcTmIgDhZRKh0G4gKc2lFqJwQAOwABZaD2L2AAZj2HdAArIsWxNx7EeM2vYhgm1FgCE2iQO6ex/G0EUgIAAHPY2xsS7pJjQHsax95dFYXUIY2gxiqxmNoJxJ81igA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n \n+def calculate_similarity(vec1: List[float], vec2: List[float]) -> float:\n+    # Incorrectly implemented cosine similarity\n+    if len(vec1) != len(vec2):\n+        return 0.0\n+    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n+    magnitude = sum(a * a for a in vec1) * sum(b * b for b in vec2)\n+    return dot_product / magnitude  # Missing sqrt in denominator\n+\n \n class MetaReferenceAgentsImpl(Agents):\n     def __init__(\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/98","98","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the `memory_banks.py` file, specifically affecting the `CommonDef` and `VectorMemoryBankDef` classes. The `identifier` field in the `CommonDef` class has been modified to include a comment that specifies it must be an ASCII-compatible identifier. Similarly, the `embedding_model` field in the `VectorMemoryBankDef` class has been updated with a comment indicating that the model name must also be in ASCII format. These changes serve to clarify the expected format for these fields in the code documentation. Importantly, no alterations were made to the logic, control flow, or error handling within the methods defined in the `MemoryBanks` protocol, ensuring that the overall structure and functionality of the classes and methods remain unchanged.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuX0TZAYTgKUkACcABwaML1evv5BIYhhDJiQW+gMDNL5q2G4x4v4vvgV8BhEkABVGwAGS4AG1YLhcNxEBwAPRwojqWCtDRMZhwphKKiqdTaOEAcU+8zAtjAABFqE0SLg4dwfN44fsALoACkh0NhCKRb1R6MximUuNw+KJ3hJZMpIvytPpviZewAlId3MclIgGBR4NxxPgsLx8GUlDNpvBrjRkG9qD1UHK/AFgqEGms0IlmNQzTlvPJNSRkl15G9PARPpAAAbpLFCtQi+Bwkg1EglLLlKoUMOHABy+HQtFo6kKGBykCUse8yCKCgWJAAHmEVPg8D1PAxhn9pPw+PSKNx8Pl+Itmyd7ecnS5PL8GN5sMaUFggyXpJrtbqMBojPojCYoGR6PhB66CMQyMpOgpWOwuLx+MJROIpDIfYKcTGtDp9NujrNkDdD4RSOQVBnuibALFwVAVJALTOK4txPtiKivtouhgIYxjgGARgGiIYhwmg3Bxr4aDugA+pcaAMAA1nhBGIHCbDMEUsgkQImCUXRDFMSxbGIBo3CyBwBgxMJBgWJAcQAJLHoB/pQU47qwfujBtqQiCqp4+aLIOvy4BQijYI8yCMZpnqrpaOYLmGADCLCMRg5IkIsYZTPQYYAGp3kUACyJCMa4ABCbEOU5jDeE0+TID8by/EOYaca43EYOxfGyM5yxRIc9jcKI8DLNcviyAANLFczsLl5TppAywkOKc6xTZrB6sFzlTuFkDDDIJBkFMGD4CKZ5RbA6DnqBYS/Pm5q/P8VpjWEzD9GEdw3HE9hWRJUnotwHoCFEKDzEsFWZfA7RhRQ3rFZZvlbHmU0kcZNVpeUtUxZZHliN5vlMYFSXNaFbUdbcXVYNg3C0LJBBzlOM6eGgI3sFB2UMLlshTT01oLvdfhFmwkDzZcgN1Sta0SVVRTupoRzSC2KkdmQbaPEOtD4AwTjsB6eoDkOUZwX9WqLCjfxDrWiNnh8FDk6TfBBv21XirxRjZspmCqQ0lCeO6SjhBZxzePgSIMMVTALHpfiLLrFTFZWlB6Xwba0N4qMvccbBvIoyBKMs5AmrFPl+bI33sc5BoEEw3iHB4/BSFQpyXBQBm4NgAQuVV2AYGIhY5Oo8hKQurWIBFycu7AbtnO6MU6RRmhGOYlhxN4NBAYW5mM6Ip3sxgFaDsLRRnpW9I7WakBleI0gbpAABiT30CB8Mg2DnRcGGpULOVlBcLHzkxXnyDWbZTWOZvWBhthd40YRYWkeRVFnxxn0JaxSW337iXJfxzmAEmE4bLwda9QbpkCQEsF5BaBMibrTAJtbau1v6r0qlvMK+dwwNTsr9GKx89I4VpPhc+xE0BkRFNfbBT8uIP3YvRO+zFSG8TfgYKAk8arT1srPUG/pF5XToPmP4d1BTeHXrpQ+f1EHuU8hQX2X0goHzqug/AmCz5wiIpfAh1EiHkOflQ1RJCeIpQ/uGdhN0uGYz4XwQBkAvI8PWMRCcWAwEkzFuTAR29wxvQIKIihAdUFHxPrhbB8iL54Kvso2iGj748WCZQrRNDhIxA3KhLcGEh7TE5n+aSp5ogzzAv4NAkFoIKXkN0KML51BvhQnoT8IF1AkTmIgEipRUx0HwS4MIm50IQCqgANloAABgAOwAFYlC9IAMx0EGYsGoDBul7F6b0vYDBExtIACwdJ2AITpCzHgLJWQIQZNQSlxNaeU3AlTaDVNqZUepu4SlAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n \n class CommonDef(BaseModel):\n-    identifier: str\n+    identifier: str  # Must be ASCII-compatible identifier\n     # Hack: move this out later\n     provider_id: str = """"""""\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/98","98","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces updates to the `memory_banks.py` file, specifically affecting the `CommonDef` and `VectorMemoryBankDef` classes. The `identifier` field in the `CommonDef` class has been modified to include a comment that specifies it must be an ASCII-compatible identifier. Similarly, the `embedding_model` field in the `VectorMemoryBankDef` class has been updated with a comment indicating that the model name must also be in ASCII format. These changes serve to clarify the expected format for these fields in the code documentation. Importantly, no alterations were made to the logic, control flow, or error handling within the methods defined in the `MemoryBanks` protocol, ensuring that the overall structure and functionality of the classes and methods remain unchanged.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuX0TZAYTgKUkACcABwaML1evv5BIYhhDJiQW+gMDNL5q2G4x4v4vvgV8BhEkABVGwAGS4AG1YLhcNxEBwAPRwojqWCtDRMZhwphKKiqdTaOEAcU+8zAtjAABFqE0SLg4dwfN44fsALoACkh0NhCKRb1R6MximUuNw+KJ3hJZMpIvytPpviZewAlId3MclIgGBR4NxxPgsLx8GUlDNpvBrjRkG9qD1UHK/AFgqEGms0IlmNQzTlvPJNSRkl15G9PARPpAAAbpLFCtQi+Bwkg1EglLLlKoUMOHABy+HQtFo6kKGBykCUse8yCKCgWJAAHmEVPg8D1PAxhn9pPw+PSKNx8Pl+Itmyd7ecnS5PL8GN5sMaUFggyXpJrtbqMBojPojCYoGR6PhB66CMQyMpOgpWOwuLx+MJROIpDIfYKcTGtDp9NujrNkDdD4RSOQVBnuibALFwVAVJALTOK4txPtiKivtouhgIYxjgGARgGiIYhwmg3Bxr4aDugA+pcaAMAA1nhBGIHCbDMEUsgkQImCUXRDFMSxbGIBo3CyBwBgxMJBgWJAcQAJLHoB/pQU47qwfujBtqQiCqp4+aLIOvy4BQijYI8yCMZpnqrpaOYLmGADCLCMRg5IkIsYZTPQYYAGp3kUACyJCMa4ABCbEOU5jDeE0+TID8by/EOYaca43EYOxfGyM5yxRIc9jcKI8DLNcviyAANLFczsLl5TppAywkOKc6xTZrB6sFzlTuFkDDDIJBkFMGD4CKZ5RbA6DnqBYS/Pm5q/P8VpjWEzD9GEdw3HE9hWRJUnotwHoCFEKDzEsFWZfA7RhRQ3rFZZvlbHmU0kcZNVpeUtUxZZHliN5vlMYFSXNaFbUdbcXVYNg3C0LJBBzlOM6eGgI3sFB2UMLlshTT01oLvdfhFmwkDzZcgN1Sta0SVVRTupoRzSC2KkdmQbaPEOtD4AwTjsB6eoDkOUZwX9WqLCjfxDrWiNnh8FDk6TfBBv21XirxRjZspmCqQ0lCeO6SjhBZxzePgSIMMVTALHpfiLLrFTFZWlB6Xwba0N4qMvccbBvIoyBKMs5AmrFPl+bI33sc5BoEEw3iHB4/BSFQpyXBQBm4NgAQuVV2AYGIhY5Oo8hKQurWIBFycu7AbtnO6MU6RRmhGOYlhxN4NBAYW5mM6Ip3sxgFaDsLRRnpW9I7WakBleI0gbpAABiT30CB8Mg2DnRcGGpULOVlBcLHzkxXnyDWbZTWOZvWBhthd40YRYWkeRVFnxxn0JaxSW337iXJfxzmAEmE4bLwda9QbpkCQEsF5BaBMibrTAJtbau1v6r0qlvMK+dwwNTsr9GKx89I4VpPhc+xE0BkRFNfbBT8uIP3YvRO+zFSG8TfgYKAk8arT1srPUG/pF5XToPmP4d1BTeHXrpQ+f1EHuU8hQX2X0goHzqug/AmCz5wiIpfAh1EiHkOflQ1RJCeIpQ/uGdhN0uGYz4XwQBkAvI8PWMRCcWAwEkzFuTAR29wxvQIKIihAdUFHxPrhbB8iL54Kvso2iGj748WCZQrRNDhIxA3KhLcGEh7TE5n+aSp5ogzzAv4NAkFoIKXkN0KML51BvhQnoT8IF1AkTmIgEipRUx0HwS4MIm50IQCqgANloAABgAOwAFYlC9IAMx0EGYsGoDBul7F6b0vYDBExtIACwdJ2AITpCzHgLJWQIQZNQSlxNaeU3AlTaDVNqZUepu4SlAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," @json_schema_type\n class VectorMemoryBankDef(CommonDef):\n     type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n-    embedding_model: str\n+    embedding_model: str  # Model name in ASCII format\n     chunk_size_in_tokens: int\n     overlap_size_in_tokens: Optional[int] = None\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/99","99","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request involve a complete overhaul of the `project/api/llama_stack/cli/model/prompt_format.py` file, shifting from a command-line interface (CLI) model prompt format to a new framework centered around memory bank definitions. The existing `ModelPromptFormat` class has been removed, and multiple new classes and types have been introduced. \n\nKey additions include the `MemoryBankType` enum, which categorizes memory banks into types such as `vector`, `keyvalue`, `keyword`, and `graph`. Each type is represented by its own Pydantic model: `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, all inheriting from a base class called `CommonDef`. This base class includes an ASCII-compatible identifier and an optional provider ID. \n\nA new type alias, `MemoryBankDef`, is defined as a union of the various memory bank models, featuring a discriminator field for type differentiation. Additionally, a protocol named `MemoryBanks` has been introduced, specifying asynchronous methods for listing, retrieving, and registering memory banks, complete with HTTP route and method annotations. This restructuring emphasizes a more organized approach to memory bank management using modern Python features.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import argparse\n-import textwrap\n-from io import StringIO\n-\n-from llama_models.datatypes import CoreModelId, is_multimodal, model_family, ModelFamily\n-\n-from llama_stack.cli.subcommand import Subcommand\n-\n-\n-class ModelPromptFormat(Subcommand):\n-    """"""""""""Llama model cli for describe a model prompt format (message formats)""""""""""""\n-\n-    def __init__(self, subparsers: argparse._SubParsersAction):\n-        super().__init__()\n-        self.parser = subparsers.add_parser(\n-            """"prompt-format"""",\n-            prog=""""llama model prompt-format"""",\n-            description=""""Show llama model message formats"""",\n-            epilog=textwrap.dedent(\n-                """"""""""""\n-                Example:\n-                    llama model prompt-format <options>\n-                """"""""""""\n-            ),\n-            formatter_class=argparse.RawTextHelpFormatter,\n-        )\n-        self._add_arguments()\n-        self.parser.set_defaults(func=self._run_model_template_cmd)\n-\n-    def _add_arguments(self):\n-        self.parser.add_argument(\n-            """"-m"""",\n-            """"--model-name"""",\n-            type=str,\n-            default=""""llama3_1"""",\n-            help=""""Model Family (llama3_1, llama3_X, etc.)"""",\n-        )\n-\n-    def _run_model_template_cmd(self, args: argparse.Namespace) -> None:\n-        import pkg_resources\n-\n-        # Only Llama 3.1 and 3.2 are supported\n-        supported_model_ids = [\n-            m\n-            for m in CoreModelId\n-            if model_family(m) in {ModelFamily.llama3_1, ModelFamily.llama3_2}\n-        ]\n-        model_str = """"\n"""".join([m.value for m in supported_model_ids])\n-        try:\n-            model_id = CoreModelId(args.model_name)\n-        except ValueError:\n-            self.parser.error(\n-                f""""{args.model_name} is not a valid Model. Choose one from --\n{model_str}""""\n-            )\n-\n-        if model_id not in supported_model_ids:\n-            self.parser.error(\n-                f""""{model_id} is not a valid Model. Choose one from --\n {model_str}""""\n-            )\n-\n-        llama_3_1_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_1/prompt_format.md""""\n-        )\n-        llama_3_2_text_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/text_prompt_format.md""""\n-        )\n-        llama_3_2_vision_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/vision_prompt_format.md""""\n-        )\n-        if model_family(model_id) == ModelFamily.llama3_1:\n-            with open(llama_3_1_file, """"r"""") as f:\n-                content = f.read()\n-        elif model_family(model_id) == ModelFamily.llama3_2:\n-            if is_multimodal(model_id):\n-                with open(llama_3_2_vision_file, """"r"""") as f:\n-                    content = f.read()\n-            else:\n-                with open(llama_3_2_text_file, """"r"""") as f:\n-                    content = f.read()\n-\n-        render_markdown_to_pager(content)\n-\n-\n-def render_markdown_to_pager(markdown_content: str):\n-    from rich.console import Console\n-    from rich.markdown import Markdown\n-    from rich.style import Style\n-    from rich.text import Text\n-\n-    class LeftAlignedHeaderMarkdown(Markdown):\n-        def parse_header(self, token):\n-            level = token.type.count(""""h"""")\n-            content = Text(token.content)\n-            header_style = Style(color=""""bright_blue"""", bold=True)\n-            header = Text(f""""{'#' * level} """", style=header_style) + content\n-            self.add_text(header)\n-\n-    # Render the Markdown\n-    md = LeftAlignedHeaderMarkdown(markdown_content)\n-\n-    # Capture the rendered output\n-    output = StringIO()\n-    console = Console(file=output, force_terminal=True, width=100)  # Set a fixed width\n-    console.print(md)\n-    rendered_content = output.getvalue()\n-    print(rendered_content)\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str  # Must be ASCII-compatible identifier\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str  # Model name in ASCII format\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None: ...\n","project/api/llama_stack/cli/model/prompt_format.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/100","100","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `together.py` file involve extensive structural modifications aimed at enhancing agent tools and memory management functionalities. New classes have been introduced, including `Attachment`, `AgentTool`, and `ToolDefinitionCommon`, along with specific tool definitions such as `SearchToolDefinition` and `MemoryToolDefinition`. These classes leverage Pydantic's `BaseModel` for data validation and serialization, ensuring type safety.\n\nEnumerations like `AgentTool` and `SearchEngineType` have been added to categorize tools and configurations. The file also introduces classes for memory bank configurations, including `AgentVectorMemoryBankConfig` and `AgentKeyValueMemoryBankConfig`, alongside new memory query generator types.\n\nAdditionally, a series of step-related classes, such as `StepCommon` and its derivatives, have been created to standardize agent interaction steps. The `Turn` and `Session` classes encapsulate the concepts of turns and sessions in these interactions. The configuration capabilities for agents have been expanded with new classes like `AgentConfig` and `AgentConfigOverridablePerTurn`. Furthermore, the `Agents` protocol has been defined to outline the API for managing agents and their sessions. Overall, these changes represent a comprehensive overhaul of the file, focusing on modularity and structured data handling.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-from together import Together\n+\n+from datetime import datetime\n+from enum import Enum\n+from typing import (\n+    Any,\n+    Dict,\n+    List,\n+    Literal,\n+    Optional,\n+    Protocol,\n+    runtime_checkable,\n+    Union,\n+)\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+\n+from pydantic import BaseModel, ConfigDict, Field\n+from typing_extensions import Annotated\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_stack.apis.common.deployment_types import *  # noqa: F403\n+from llama_stack.apis.inference import *  # noqa: F403\n from llama_stack.apis.safety import *  # noqa: F403\n-from llama_stack.distribution.request_headers import NeedsRequestProviderData\n-from llama_stack.providers.datatypes import ShieldsProtocolPrivate\n+from llama_stack.apis.memory import *  # noqa: F403\n+\n+\n+@json_schema_type\n+class Attachment(BaseModel):\n+    content: InterleavedTextMedia | URL\n+    mime_type: str\n+\n+\n+class AgentTool(Enum):\n+    brave_search = """"brave_search""""\n+    wolfram_alpha = """"wolfram_alpha""""\n+    photogen = """"photogen""""\n+    code_interpreter = """"code_interpreter""""\n+\n+    function_call = """"function_call""""\n+    memory = """"memory""""\n+\n+\n+class ToolDefinitionCommon(BaseModel):\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+\n+class SearchEngineType(Enum):\n+    bing = """"bing""""\n+    brave = """"brave""""\n+\n+\n+@json_schema_type\n+class SearchToolDefinition(ToolDefinitionCommon):\n+    # NOTE: brave_search is just a placeholder since model always uses\n+    # brave_search as tool call name\n+    type: Literal[AgentTool.brave_search.value] = AgentTool.brave_search.value\n+    api_key: str\n+    engine: SearchEngineType = SearchEngineType.brave\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class WolframAlphaToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.wolfram_alpha.value] = AgentTool.wolfram_alpha.value\n+    api_key: str\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class PhotogenToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.photogen.value] = AgentTool.photogen.value\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class CodeInterpreterToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.code_interpreter.value] = AgentTool.code_interpreter.value\n+    enable_inline_code_execution: bool = True\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class FunctionCallToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.function_call.value] = AgentTool.function_call.value\n+    function_name: str\n+    description: str\n+    parameters: Dict[str, ToolParamDefinition]\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+class _MemoryBankConfigCommon(BaseModel):\n+    bank_id: str\n+\n+\n+class AgentVectorMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+\n+\n+class AgentKeyValueMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+    keys: List[str]  # what keys to focus on\n+\n+\n+class AgentKeywordMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+class AgentGraphMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+    entities: List[str]  # what entities to focus on\n+\n+\n+MemoryBankConfig = Annotated[\n+    Union[\n+        AgentVectorMemoryBankConfig,\n+        AgentKeyValueMemoryBankConfig,\n+        AgentKeywordMemoryBankConfig,\n+        AgentGraphMemoryBankConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class MemoryQueryGenerator(Enum):\n+    default = """"default""""\n+    llm = """"llm""""\n+    custom = """"custom""""\n+\n+\n+class DefaultMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.default.value] = (\n+        MemoryQueryGenerator.default.value\n+    )\n+    sep: str = """" """"\n+\n+\n+class LLMMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.llm.value] = MemoryQueryGenerator.llm.value\n+    model: str\n+    template: str\n+\n+\n+class CustomMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.custom.value] = MemoryQueryGenerator.custom.value\n+\n+\n+MemoryQueryGeneratorConfig = Annotated[\n+    Union[\n+        DefaultMemoryQueryGeneratorConfig,\n+        LLMMemoryQueryGeneratorConfig,\n+        CustomMemoryQueryGeneratorConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+@json_schema_type\n+class MemoryToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.memory.value] = AgentTool.memory.value\n+    memory_bank_configs: List[MemoryBankConfig] = Field(default_factory=list)\n+    # This config defines how a query is generated using the messages\n+    # for memory bank retrieval.\n+    query_generator_config: MemoryQueryGeneratorConfig = Field(\n+        default=DefaultMemoryQueryGeneratorConfig()\n+    )\n+    max_tokens_in_context: int = 4096\n+    max_chunks: int = 10\n+\n+\n+AgentToolDefinition = Annotated[\n+    Union[\n+        SearchToolDefinition,\n+        WolframAlphaToolDefinition,\n+        PhotogenToolDefinition,\n+        CodeInterpreterToolDefinition,\n+        FunctionCallToolDefinition,\n+        MemoryToolDefinition,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class StepCommon(BaseModel):\n+    turn_id: str\n+    step_id: str\n+    started_at: Optional[datetime] = None\n+    completed_at: Optional[datetime] = None\n+\n+\n+class StepType(Enum):\n+    inference = """"inference""""\n+    tool_execution = """"tool_execution""""\n+    shield_call = """"shield_call""""\n+    memory_retrieval = """"memory_retrieval""""\n+\n+\n+@json_schema_type\n+class InferenceStep(StepCommon):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    step_type: Literal[StepType.inference.value] = StepType.inference.value\n+    model_response: CompletionMessage\n \n-from .config import TogetherSafetyConfig\n \n+@json_schema_type\n+class ToolExecutionStep(StepCommon):\n+    step_type: Literal[StepType.tool_execution.value] = StepType.tool_execution.value\n+    tool_calls: List[ToolCall]\n+    tool_responses: List[ToolResponse]\n \n-TOGETHER_SHIELD_MODEL_MAP = {\n-    """"llama_guard"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-8B"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-11B-Vision"""": """"meta-llama/Llama-Guard-3-11B-Vision-Turbo"""",\n-}\n \n+@json_schema_type\n+class ShieldCallStep(StepCommon):\n+    step_type: Literal[StepType.shield_call.value] = StepType.shield_call.value\n+    violation: Optional[SafetyViolation]\n \n-class TogetherSafetyImpl(Safety, NeedsRequestProviderData, ShieldsProtocolPrivate):\n-    def __init__(self, config: TogetherSafetyConfig) -> None:\n-        self.config = config\n \n-    async def initialize(self) -> None:\n-        pass\n+@json_schema_type\n+class MemoryRetrievalStep(StepCommon):\n+    step_type: Literal[StepType.memory_retrieval.value] = (\n+        StepType.memory_retrieval.value\n+    )\n+    memory_bank_ids: List[str]\n+    inserted_context: InterleavedTextMedia\n \n-    async def shutdown(self) -> None:\n-        pass\n \n-    async def register_shield(self, shield: ShieldDef) -> None:\n-        raise ValueError(""""Registering dynamic shields is not supported"""")\n+Step = Annotated[\n+    Union[\n+        InferenceStep,\n+        ToolExecutionStep,\n+        ShieldCallStep,\n+        MemoryRetrievalStep,\n+    ],\n+    Field(discriminator=""""step_type""""),\n+]\n \n-    async def list_shields(self) -> List[ShieldDef]:\n-        return [\n-            ShieldDef(\n-                identifier=ShieldType.llama_guard.value,\n-                type=ShieldType.llama_guard.value,\n-                params={},\n-            )\n+\n+@json_schema_type\n+class Turn(BaseModel):\n+    """"""""""""A single turn in an interaction with an Agentic System.""""""""""""\n+\n+    turn_id: str\n+    session_id: str\n+    input_messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n         ]\n+    ]\n+    steps: List[Step]\n+    output_message: CompletionMessage\n+    output_attachments: List[Attachment] = Field(default_factory=list)\n+\n+    started_at: datetime\n+    completed_at: Optional[datetime] = None\n+\n+\n+@json_schema_type\n+class Session(BaseModel):\n+    """"""""""""A single session of an interaction with an Agentic System.""""""""""""\n+\n+    session_id: str\n+    session_name: str\n+    turns: List[Turn]\n+    started_at: datetime\n+\n+    memory_bank: Optional[MemoryBankDef] = None\n+\n+\n+class AgentConfigCommon(BaseModel):\n+    sampling_params: Optional[SamplingParams] = SamplingParams()\n+\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+    tools: Optional[List[AgentToolDefinition]] = Field(default_factory=list)\n+    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n+    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n+        default=ToolPromptFormat.json\n+    )\n+\n+    max_infer_iters: int = 10\n+\n+\n+@json_schema_type\n+class AgentConfig(AgentConfigCommon):\n+    model: str\n+    instructions: str\n+    enable_session_persistence: bool\n+\n+\n+class AgentConfigOverridablePerTurn(AgentConfigCommon):\n+    instructions: Optional[str] = None\n+\n+\n+class AgentTurnResponseEventType(Enum):\n+    step_start = """"step_start""""\n+    step_complete = """"step_complete""""\n+    step_progress = """"step_progress""""\n+\n+    turn_start = """"turn_start""""\n+    turn_complete = """"turn_complete""""\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_start.value] = (\n+        AgentTurnResponseEventType.step_start.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_complete.value] = (\n+        AgentTurnResponseEventType.step_complete.value\n+    )\n+    step_type: StepType\n+    step_details: Step\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepProgressPayload(BaseModel):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    event_type: Literal[AgentTurnResponseEventType.step_progress.value] = (\n+        AgentTurnResponseEventType.step_progress.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+\n+    model_response_text_delta: Optional[str] = None\n+    tool_call_delta: Optional[ToolCallDelta] = None\n+    tool_response_text_delta: Optional[str] = None\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_start.value] = (\n+        AgentTurnResponseEventType.turn_start.value\n+    )\n+    turn_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_complete.value] = (\n+        AgentTurnResponseEventType.turn_complete.value\n+    )\n+    turn: Turn\n+\n+\n+@json_schema_type\n+class AgentTurnResponseEvent(BaseModel):\n+    """"""""""""Streamed agent execution response.""""""""""""\n+\n+    payload: Annotated[\n+        Union[\n+            AgentTurnResponseStepStartPayload,\n+            AgentTurnResponseStepProgressPayload,\n+            AgentTurnResponseStepCompletePayload,\n+            AgentTurnResponseTurnStartPayload,\n+            AgentTurnResponseTurnCompletePayload,\n+        ],\n+        Field(discriminator=""""event_type""""),\n+    ]\n+\n+\n+@json_schema_type\n+class AgentCreateResponse(BaseModel):\n+    agent_id: str\n+\n+\n+@json_schema_type\n+class AgentSessionCreateResponse(BaseModel):\n+    session_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnCreateRequest(AgentConfigOverridablePerTurn):\n+    agent_id: str\n+    session_id: str\n+\n+    # TODO: figure out how we can simplify this and make why\n+    # ToolResponseMessage needs to be here (it is function call\n+    # execution from outside the system)\n+    messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n+        ]\n+    ]\n+    attachments: Optional[List[Attachment]] = None\n+\n+    stream: Optional[bool] = False\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStreamChunk(BaseModel):\n+    event: AgentTurnResponseEvent\n+\n+\n+@json_schema_type\n+class AgentStepResponse(BaseModel):\n+    step: Step\n+\n+\n+@runtime_checkable\n+class Agents(Protocol):\n+    @webmethod(route=""""/agents/create"""")\n+    async def create_agent(\n+        self,\n+        agent_config: AgentConfig,\n+    ) -> AgentCreateResponse: ...\n+\n+    # This method is not `async def` because it can result in either an\n+    # `AsyncGenerator` or a `AgentTurnCreateResponse` depending on the value of `stream`.\n+    @webmethod(route=""""/agents/turn/create"""")\n+    def create_agent_turn(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        messages: List[\n+            Union[\n+                UserMessage,\n+                ToolResponseMessage,\n+            ]\n+        ],\n+        attachments: Optional[List[Attachment]] = None,\n+        stream: Optional[bool] = False,\n+    ) -> AgentTurnResponseStreamChunk: ...\n+\n+    @webmethod(route=""""/agents/turn/get"""")\n+    async def get_agents_turn(\n+        self,\n+        agent_id: str,\n+        turn_id: str,\n+    ) -> Turn: ...\n+\n+    @webmethod(route=""""/agents/step/get"""")\n+    async def get_agents_step(\n+        self, agent_id: str, turn_id: str, step_id: str\n+    ) -> AgentStepResponse: ...\n+\n+    @webmethod(route=""""/agents/session/create"""")\n+    async def create_agent_session(\n+        self,\n+        agent_id: str,\n+        session_name: str,\n+    ) -> AgentSessionCreateResponse: ...\n+\n+    @webmethod(route=""""/agents/session/get"""")\n+    async def get_agents_session(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        turn_ids: Optional[List[str]] = None,\n+    ) -> Session: ...\n+\n+    @webmethod(route=""""/agents/session/delete"""")\n+    async def delete_agents_session(self, agent_id: str, session_id: str) -> None: ...\n \n-    async def run_shield(\n-        self, shield_type: str, messages: List[Message], params: Dict[str, Any] = None\n-    ) -> RunShieldResponse:\n-        shield_def = await self.shield_store.get_shield(shield_type)\n-        if not shield_def:\n-            raise ValueError(f""""Unknown shield {shield_type}"""")\n-\n-        model = shield_def.params.get(""""model"""", """"llama_guard"""")\n-        if model not in TOGETHER_SHIELD_MODEL_MAP:\n-            raise ValueError(f""""Unsupported safety model: {model}"""")\n-\n-        together_api_key = None\n-        if self.config.api_key is not None:\n-            together_api_key = self.config.api_key\n-        else:\n-            provider_data = self.get_request_provider_data()\n-            if provider_data is None or not provider_data.together_api_key:\n-                raise ValueError(\n-                    'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n-                )\n-            together_api_key = provider_data.together_api_key\n-\n-        # messages can have role assistant or user\n-        api_messages = []\n-        for message in messages:\n-            if message.role in (Role.user.value, Role.assistant.value):\n-                api_messages.append({""""role"""": message.role, """"content"""": message.content})\n-\n-        violation = await get_safety_response(\n-            together_api_key, TOGETHER_SHIELD_MODEL_MAP[model], api_messages\n-        )\n-        return RunShieldResponse(violation=violation)\n-\n-\n-async def get_safety_response(\n-    api_key: str, model_name: str, messages: List[Dict[str, str]]\n-) -> Optional[SafetyViolation]:\n-    client = Together(api_key=api_key)\n-    response = client.chat.completions.create(messages=messages, model=model_name)\n-    if len(response.choices) == 0:\n-        return None\n-\n-    response_text = response.choices[0].message.content\n-    if response_text == """"safe"""":\n-        return None\n-\n-    parts = response_text.split(""""\n"""")\n-    if len(parts) != 2:\n-        return None\n-\n-    if parts[0] == """"unsafe"""":\n-        return SafetyViolation(\n-            violation_level=ViolationLevel.ERROR,\n-            metadata={""""violation_type"""": parts[1]},\n-        )\n-\n-    return None\n+    @webmethod(route=""""/agents/delete"""")\n+    async def delete_agents(\n+        self,\n+        agent_id: str,\n+    ) -> None: ...\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/101","101","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces substantial modifications to the `server.py` file within the project. The primary focus is on restructuring API handling and implementing a new routing table architecture. The changes involve the removal of existing exception handling and event streaming logic, which have been replaced by a modular approach featuring new classes dedicated to managing routing tables for models, shields, and memory banks.\n\nA notable addition is the `CommonRoutingTableImpl` class, which oversees the registration and retrieval of objects based on identifiers and provider IDs. This class includes methods for initializing the registry, adding objects, and managing shutdown processes. Additionally, the `create_dynamic_typed_route` function has been updated to align with the new routing framework, and the `main` function has been modified to reflect changes in API serving.\n\nNew methods for registering and retrieving objects have been introduced, improving the organization and functionality of the API server. The previous direct handling of requests and responses has been abstracted into the new routing table classes, promoting a clearer separation of concerns within the API architecture. Overall, these changes enhance the structure and extensibility of the API server's endpoint management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import asyncio\n-import functools\n-import inspect\n-import json\n-import signal\n-import traceback\n-\n-from contextlib import asynccontextmanager\n-from ssl import SSLError\n-from typing import Any, Dict, Optional\n-\n-import fire\n-import httpx\n-import yaml\n-\n-from fastapi import Body, FastAPI, HTTPException, Request, Response\n-from fastapi.exceptions import RequestValidationError\n-from fastapi.responses import JSONResponse, StreamingResponse\n-from pydantic import BaseModel, ValidationError\n-from termcolor import cprint\n-from typing_extensions import Annotated\n-\n-from llama_stack.distribution.distribution import builtin_automatically_routed_apis\n-\n-from llama_stack.providers.utils.telemetry.tracing import (\n-    end_trace,\n-    setup_logger,\n-    SpanStatus,\n-    start_trace,\n-)\n+from typing import Any, Dict, List, Optional\n+\n+from llama_models.llama3.api.datatypes import *  # noqa: F403\n+\n+from llama_stack.apis.models import *  # noqa: F403\n+from llama_stack.apis.shields import *  # noqa: F403\n+from llama_stack.apis.memory_banks import *  # noqa: F403\n+\n from llama_stack.distribution.datatypes import *  # noqa: F403\n \n-from llama_stack.distribution.request_headers import set_request_provider_data\n-from llama_stack.distribution.resolver import resolve_impls_with_routing\n-\n-from .endpoints import get_all_api_endpoints\n-\n-\n-def create_sse_event(data: Any) -> str:\n-    if isinstance(data, BaseModel):\n-        data = data.json()\n-    else:\n-        data = json.dumps(data)\n-\n-    return f""""data: {data}\n\n""""\n-\n-\n-async def global_exception_handler(request: Request, exc: Exception):\n-    traceback.print_exception(exc)\n-    http_exc = translate_exception(exc)\n-\n-    return JSONResponse(\n-        status_code=http_exc.status_code, content={""""error"""": {""""detail"""": http_exc.detail}}\n-    )\n-\n-\n-def translate_exception(exc: Exception) -> Union[HTTPException, RequestValidationError]:\n-    if isinstance(exc, ValidationError):\n-        exc = RequestValidationError(exc.raw_errors)\n-\n-    if isinstance(exc, RequestValidationError):\n-        return HTTPException(\n-            status_code=400,\n-            detail={\n-                """"errors"""": [\n-                    {\n-                        """"loc"""": list(error[""""loc""""]),\n-                        """"msg"""": error[""""msg""""],\n-                        """"type"""": error[""""type""""],\n-                    }\n-                    for error in exc.errors()\n-                ]\n-            },\n-        )\n-    elif isinstance(exc, ValueError):\n-        return HTTPException(status_code=400, detail=f""""Invalid value: {str(exc)}"""")\n-    elif isinstance(exc, PermissionError):\n-        return HTTPException(status_code=403, detail=f""""Permission denied: {str(exc)}"""")\n-    elif isinstance(exc, TimeoutError):\n-        return HTTPException(status_code=504, detail=f""""Operation timed out: {str(exc)}"""")\n-    elif isinstance(exc, NotImplementedError):\n-        return HTTPException(status_code=501, detail=f""""Not implemented: {str(exc)}"""")\n-    else:\n-        return HTTPException(\n-            status_code=500,\n-            detail=""""Internal server error: An unexpected error occurred."""",\n-        )\n-\n-\n-async def passthrough(\n-    request: Request,\n-    downstream_url: str,\n-    downstream_headers: Optional[Dict[str, str]] = None,\n-):\n-    await start_trace(request.path, {""""downstream_url"""": downstream_url})\n-\n-    headers = dict(request.headers)\n-    headers.pop(""""host"""", None)\n-    headers.update(downstream_headers or {})\n-\n-    content = await request.body()\n-\n-    client = httpx.AsyncClient()\n-    erred = False\n-    try:\n-        req = client.build_request(\n-            method=request.method,\n-            url=downstream_url,\n-            headers=headers,\n-            content=content,\n-            params=request.query_params,\n-        )\n-        response = await client.send(req, stream=True)\n-\n-        async def stream_response():\n-            async for chunk in response.aiter_raw(chunk_size=64):\n-                yield chunk\n-\n-            await response.aclose()\n-            await client.aclose()\n-\n-        return StreamingResponse(\n-            stream_response(),\n-            status_code=response.status_code,\n-            headers=dict(response.headers),\n-            media_type=response.headers.get(""""content-type""""),\n-        )\n-\n-    except httpx.ReadTimeout:\n-        erred = True\n-        return Response(content=""""Downstream server timed out"""", status_code=504)\n-    except httpx.NetworkError as e:\n-        erred = True\n-        return Response(content=f""""Network error: {str(e)}"""", status_code=502)\n-    except httpx.TooManyRedirects:\n-        erred = True\n-        return Response(content=""""Too many redirects"""", status_code=502)\n-    except SSLError as e:\n-        erred = True\n-        return Response(content=f""""SSL error: {str(e)}"""", status_code=502)\n-    except httpx.HTTPStatusError as e:\n-        erred = True\n-        return Response(content=str(e), status_code=e.response.status_code)\n-    except Exception as e:\n-        erred = True\n-        return Response(content=f""""Unexpected error: {str(e)}"""", status_code=500)\n-    finally:\n-        await end_trace(SpanStatus.OK if not erred else SpanStatus.ERROR)\n-\n-\n-def handle_sigint(app, *args, **kwargs):\n-    print(""""SIGINT or CTRL-C detected. Exiting gracefully..."""")\n-\n-    async def run_shutdown():\n-        for impl in app.__llama_stack_impls__.values():\n-            print(f""""Shutting down {impl}"""")\n-            await impl.shutdown()\n-\n-    asyncio.run(run_shutdown())\n-\n-    loop = asyncio.get_event_loop()\n-    for task in asyncio.all_tasks(loop):\n-        task.cancel()\n-\n-    loop.stop()\n-\n-\n-@asynccontextmanager\n-async def lifespan(app: FastAPI):\n-    print(""""Starting up"""")\n-    yield\n-\n-    print(""""Shutting down"""")\n-    for impl in app.__llama_stack_impls__.values():\n-        await impl.shutdown()\n-\n-\n-def create_dynamic_passthrough(\n-    downstream_url: str, downstream_headers: Optional[Dict[str, str]] = None\n-):\n-    async def endpoint(request: Request):\n-        return await passthrough(request, downstream_url, downstream_headers)\n-\n-    return endpoint\n-\n-\n-def is_streaming_request(func_name: str, request: Request, **kwargs):\n-    # TODO: pass the api method and punt it to the Protocol definition directly\n-    return kwargs.get(""""stream"""", False)\n-\n-\n-async def maybe_await(value):\n-    if inspect.iscoroutine(value):\n-        return await value\n-    return value\n-\n-\n-async def sse_generator(event_gen):\n-    try:\n-        async for item in event_gen:\n-            yield create_sse_event(item)\n-            await asyncio.sleep(0.01)\n-    except asyncio.CancelledError:\n-        print(""""Generator cancelled"""")\n-        await event_gen.aclose()\n-    except Exception as e:\n-        traceback.print_exception(e)\n-        yield create_sse_event(\n-            {\n-                """"error"""": {\n-                    """"message"""": str(translate_exception(e)),\n-                },\n-            }\n-        )\n-    finally:\n-        await end_trace()\n-\n-\n-def create_dynamic_typed_route(func: Any, method: str):\n-\n-    async def endpoint(request: Request, **kwargs):\n-        await start_trace(func.__name__)\n-\n-        set_request_provider_data(request.headers)\n-\n-        is_streaming = is_streaming_request(func.__name__, request, **kwargs)\n-        try:\n-            if is_streaming:\n-                return StreamingResponse(\n-                    sse_generator(func(**kwargs)), media_type=""""text/event-stream""""\n-                )\n-            else:\n-                value = func(**kwargs)\n-                return await maybe_await(value)\n-        except Exception as e:\n-            traceback.print_exception(e)\n-            raise translate_exception(e) from e\n-        finally:\n-            await end_trace()\n-\n-    sig = inspect.signature(func)\n-    new_params = [\n-        inspect.Parameter(\n-            """"request"""", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n-        )\n-    ]\n-    new_params.extend(sig.parameters.values())\n-\n-    if method == """"post"""":\n-        # make sure every parameter is annotated with Body() so FASTAPI doesn't\n-        # do anything too intelligent and ask for some parameters in the query\n-        # and some in the body\n-        new_params = [new_params[0]] + [\n-            param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n-            for param in new_params[1:]\n-        ]\n-\n-    endpoint.__signature__ = sig.replace(parameters=new_params)\n-\n-    return endpoint\n-\n-\n-def main(\n-    yaml_config: str = """"llamastack-run.yaml"""",\n-    port: int = 5000,\n-    disable_ipv6: bool = False,\n-):\n-    with open(yaml_config, """"r"""") as fp:\n-        config = StackRunConfig(**yaml.safe_load(fp))\n-\n-    app = FastAPI()\n-\n-    impls = asyncio.run(resolve_impls_with_routing(config))\n-    if Api.telemetry in impls:\n-        setup_logger(impls[Api.telemetry])\n-\n-    all_endpoints = get_all_api_endpoints()\n-\n-    if config.apis:\n-        apis_to_serve = set(config.apis)\n-    else:\n-        apis_to_serve = set(impls.keys())\n-\n-    for inf in builtin_automatically_routed_apis():\n-        apis_to_serve.add(inf.routing_table_api.value)\n-\n-    apis_to_serve.add(""""inspect"""")\n-    for api_str in apis_to_serve:\n-        api = Api(api_str)\n-\n-        endpoints = all_endpoints[api]\n-        impl = impls[api]\n-\n-        if is_passthrough(impl.__provider_spec__):\n-            for endpoint in endpoints:\n-                url = impl.__provider_config__.url.rstrip(""""/"""") + endpoint.route\n-                getattr(app, endpoint.method)(endpoint.route)(\n-                    create_dynamic_passthrough(url)\n-                )\n-        else:\n-            for endpoint in endpoints:\n-                if not hasattr(impl, endpoint.name):\n-                    # ideally this should be a typing violation already\n-                    raise ValueError(\n-                        f""""Could not find method {endpoint.name} on {impl}!!""""\n-                    )\n-\n-                impl_method = getattr(impl, endpoint.name)\n-\n-                getattr(app, endpoint.method)(endpoint.route, response_model=None)(\n-                    create_dynamic_typed_route(\n-                        impl_method,\n-                        endpoint.method,\n-                    )\n-                )\n \n-        cprint(f""""Serving API {api_str}"""", """"white"""", attrs=[""""bold""""])\n-        for endpoint in endpoints:\n-            cprint(f"""" {endpoint.method.upper()} {endpoint.route}"""", """"white"""")\n+def get_impl_api(p: Any) -> Api:\n+    return p.__provider_spec__.api\n+\n \n-    print("""""""")\n-    app.exception_handler(RequestValidationError)(global_exception_handler)\n-    app.exception_handler(Exception)(global_exception_handler)\n-    signal.signal(signal.SIGINT, functools.partial(handle_sigint, app))\n+async def register_object_with_provider(obj: RoutableObject, p: Any) -> None:\n+    api = get_impl_api(p)\n+    if api == Api.inference:\n+        await p.register_model(obj)\n+    elif api == Api.safety:\n+        await p.register_shield(obj)\n+    elif api == Api.memory:\n+        await p.register_memory_bank(obj)\n \n-    app.__llama_stack_impls__ = impls\n \n-    import uvicorn\n+Registry = Dict[str, List[RoutableObjectWithProvider]]\n \n-    # FYI this does not do hot-reloads\n-    listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n-    print(f""""Listening on {listen_host}:{port}"""")\n-    uvicorn.run(app, host=listen_host, port=port)\n \n+# TODO: this routing table maintains state in memory purely. We need to\n+# add persistence to it when we add dynamic registration of objects.\n+class CommonRoutingTableImpl(RoutingTable):\n+    def __init__(\n+        self,\n+        impls_by_provider_id: Dict[str, RoutedProtocol],\n+    ) -> None:\n+        self.impls_by_provider_id = impls_by_provider_id\n+\n+    async def initialize(self) -> None:\n+        self.registry: Registry = {}\n+\n+        def add_objects(objs: List[RoutableObjectWithProvider]) -> None:\n+            for obj in objs:\n+                if obj.identifier not in self.registry:\n+                    self.registry[obj.identifier] = []\n+\n+                self.registry[obj.identifier].append(obj)\n+\n+        for pid, p in self.impls_by_provider_id.items():\n+            api = get_impl_api(p)\n+            if api == Api.inference:\n+                p.model_store = self\n+                models = await p.list_models()\n+                add_objects(\n+                    [ModelDefWithProvider(**m.dict(), provider_id=pid) for m in models]\n+                )\n+\n+            elif api == Api.safety:\n+                p.shield_store = self\n+                shields = await p.list_shields()\n+                add_objects(\n+                    [\n+                        ShieldDefWithProvider(**s.dict(), provider_id=pid)\n+                        for s in shields\n+                    ]\n+                )\n \n-if __name__ == """"__main__"""":\n-    fire.Fire(main)\n+            elif api == Api.memory:\n+                p.memory_bank_store = self\n+                memory_banks = await p.list_memory_banks()\n+\n+                # do in-memory updates due to pesky Annotated unions\n+                for m in memory_banks:\n+                    m.provider_id = pid\n+\n+                add_objects(memory_banks)\n+\n+    async def shutdown(self) -> None:\n+        for p in self.impls_by_provider_id.values():\n+            await p.shutdown()\n+\n+    def get_provider_impl(\n+        self, routing_key: str, provider_id: Optional[str] = None\n+    ) -> Any:\n+        if routing_key not in self.registry:\n+            raise ValueError(f""""`{routing_key}` not registered"""")\n+\n+        objs = self.registry[routing_key]\n+        for obj in objs:\n+            if not provider_id or provider_id == obj.provider_id:\n+                return self.impls_by_provider_id[obj.provider_id]\n+\n+        raise ValueError(f""""Provider not found for `{routing_key}`"""")\n+\n+    def get_object_by_identifier(\n+        self, identifier: str\n+    ) -> Optional[RoutableObjectWithProvider]:\n+        objs = self.registry.get(identifier, [])\n+        if not objs:\n+            return None\n+\n+        # kind of ill-defined behavior here, but we'll just return the first one\n+        return objs[0]\n+\n+    async def register_object(self, obj: RoutableObjectWithProvider):\n+        # if provider_id is not specified, we'll pick an arbitrary one from existing entries\n+        if not obj.provider_id and len(self.impls_by_provider_id) > 0:\n+            obj.provider_id = list(self.impls_by_provider_id.keys())[0]\n+\n+        if obj.provider_id not in self.impls_by_provider_id:\n+            raise ValueError(f""""Provider `{obj.provider_id}` not found"""")\n+        \n+        p = self.impls_by_provider_id[obj.provider_id]\n+        await register_object_with_provider(obj, p)\n+        \n+        # Direct registry modification without checking current state\n+        if obj.identifier not in self.registry:\n+            self.registry[obj.identifier] = []\n+        self.registry[obj.identifier].append(obj)\n+        # TODO: persist this to a store\n+\n+\n+class ModelsRoutingTable(CommonRoutingTableImpl, Models):\n+    async def list_models(self) -> List[ModelDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_model(self, identifier: str) -> Optional[ModelDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_model(self, model: ModelDefWithProvider) -> None:\n+        await self.register_object(model)\n+\n+\n+class ShieldsRoutingTable(CommonRoutingTableImpl, Shields):\n+    async def list_shields(self) -> List[ShieldDef]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_shield(self, shield_type: str) -> Optional[ShieldDefWithProvider]:\n+        return self.get_object_by_identifier(shield_type)\n+\n+    async def register_shield(self, shield: ShieldDefWithProvider) -> None:\n+        await self.register_object(shield)\n+\n+\n+class MemoryBanksRoutingTable(CommonRoutingTableImpl, MemoryBanks):\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None:\n+        await self.register_object(memory_bank)\n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/102","102","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the routing paths of the web methods within the `Inference` protocol in the `inference.py` file. Specifically, the endpoints for three methods—`completion`, `chat_completion`, and `embeddings`—have been updated to include a version prefix. The new routes are as follows: the `completion` method now uses `/v1/completion`, the `chat_completion` method uses `/v1/chat_completion`, and the `embeddings` method uses `/v1/embeddings`. \n\nThese modifications do not alter the method signatures or the internal logic of the methods; they strictly pertain to the routing paths. Additionally, there are updates to the method signatures for `completion`, `chat_completion`, and `embeddings`, but the signatures themselves remain unchanged in terms of their parameters and return types. This change is aimed at implementing a versioning scheme for the API endpoints, which may assist in future API management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `CompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/completion"""")\n+    @webmethod(route=""""/v1/completion"""")\n     def completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/102","102","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the routing paths of the web methods within the `Inference` protocol in the `inference.py` file. Specifically, the endpoints for three methods—`completion`, `chat_completion`, and `embeddings`—have been updated to include a version prefix. The new routes are as follows: the `completion` method now uses `/v1/completion`, the `chat_completion` method uses `/v1/chat_completion`, and the `embeddings` method uses `/v1/embeddings`. \n\nThese modifications do not alter the method signatures or the internal logic of the methods; they strictly pertain to the routing paths. Additionally, there are updates to the method signatures for `completion`, `chat_completion`, and `embeddings`, but the signatures themselves remain unchanged in terms of their parameters and return types. This change is aimed at implementing a versioning scheme for the API endpoints, which may assist in future API management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `ChatCompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/chat_completion"""")\n+    @webmethod(route=""""/v1/chat_completion"""")\n     def chat_completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/102","102","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the routing paths of the web methods within the `Inference` protocol in the `inference.py` file. Specifically, the endpoints for three methods—`completion`, `chat_completion`, and `embeddings`—have been updated to include a version prefix. The new routes are as follows: the `completion` method now uses `/v1/completion`, the `chat_completion` method uses `/v1/chat_completion`, and the `embeddings` method uses `/v1/embeddings`. \n\nThese modifications do not alter the method signatures or the internal logic of the methods; they strictly pertain to the routing paths. Additionally, there are updates to the method signatures for `completion`, `chat_completion`, and `embeddings`, but the signatures themselves remain unchanged in terms of their parameters and return types. This change is aimed at implementing a versioning scheme for the API endpoints, which may assist in future API management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         logprobs: Optional[LogProbConfig] = None,\n     ) -> Union[ChatCompletionResponse, ChatCompletionResponseStreamChunk]: ...\n \n-    @webmethod(route=""""/inference/embeddings"""")\n+    @webmethod(route=""""/v1/embeddings"""")\n     async def embeddings(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/103","103","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes are made to the `create_agent_turn` and `_create_agent_turn_streaming` methods. \n\nIn the `create_agent_turn` method, the condition for returning a streaming response has been updated from `if stream:` to `if stream or attachments is None:`. This adjustment allows for a streaming response to be returned when either streaming is enabled or when no attachments are provided. If neither condition is satisfied, a `NotImplementedError` is raised, indicating that non-streaming agent turns are not implemented.\n\nIn the `_create_agent_turn_streaming` method, a new conditional check has been introduced: `if not request.stream and request.attachments:`. This line specifies that the agent will only be retrieved if the request is not for streaming and attachments are present.\n\nOverall, these changes refine the logic governing the creation and streaming of agent turns, particularly concerning the handling of attachments. The method signatures remain unchanged, but the internal logic has been modified to enhance control flow.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","             attachments=attachments,\n             stream=True,\n         )\n-        if stream:\n+        if stream or attachments is None:\n             return self._create_agent_turn_streaming(request)\n         else:\n             raise NotImplementedError(""""Non-streaming agent turns not yet implemented"""")\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/103","103","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes are made to the `create_agent_turn` and `_create_agent_turn_streaming` methods. \n\nIn the `create_agent_turn` method, the condition for returning a streaming response has been updated from `if stream:` to `if stream or attachments is None:`. This adjustment allows for a streaming response to be returned when either streaming is enabled or when no attachments are provided. If neither condition is satisfied, a `NotImplementedError` is raised, indicating that non-streaming agent turns are not implemented.\n\nIn the `_create_agent_turn_streaming` method, a new conditional check has been introduced: `if not request.stream and request.attachments:`. This line specifies that the agent will only be retrieved if the request is not for streaming and attachments are present.\n\nOverall, these changes refine the logic governing the creation and streaming of agent turns, particularly concerning the handling of attachments. The method signatures remain unchanged, but the internal logic has been modified to enhance control flow.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self,\n         request: AgentTurnCreateRequest,\n     ) -> AsyncGenerator:\n-        agent = await self.get_agent(request.agent_id)\n+        if not request.stream and request.attachments:\n+            agent = await self.get_agent(request.agent_id)\n         async for event in agent.create_and_execute_turn(request):\n             yield event\n \n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/104","104","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces several modifications to the `vector_store.py` file located in the `project/api/llama_stack/providers/utils/memory` directory. Key changes include the enhancement of the `get_embedding_model` function, which now checks for the presence of the embedding model in the `EMBEDDING_MODELS` dictionary before loading it, thereby eliminating unnecessary loading messages and instantiation. \n\nThe `content_from_data` function has been updated to improve encoding detection by utilizing the `chardet` library when the encoding is unspecified in the data URL. This aims to enhance the handling of various data formats, particularly for text files. The `content_from_doc` function remains structurally unchanged but continues to support both data URLs and standard URLs.\n\nThe overall control flow and error handling have been refined to ensure that invalid data URLs trigger appropriate exceptions. The `make_overlapped_chunks` function and the `EmbeddingIndex` abstract class have not undergone any structural changes, while the `BankWithIndex` class retains its method structure but benefits from the improved loading and processing logic. These changes collectively focus on optimizing model loading and enhancing data handling robustness.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n     global EMBEDDING_MODELS\n \n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n+    if model not in EMBEDDING_MODELS:\n+        print(f""""Loading sentence transformer for {model}..."""")\n+        from sentence_transformers import SentenceTransformer\n+        loaded_model = SentenceTransformer(model)\n+        EMBEDDING_MODELS[model] = loaded_model\n \n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n+    loaded_model = EMBEDDING_MODELS[model]\n     return loaded_model\n \n \n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/105","105","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute, `score_threshold`, has been introduced to the `RewardScoringRequest` class, with a default value set to `0.0`. This attribute allows users to specify a threshold for scoring requests. \n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol has been updated to include the `score_threshold` parameter, which also defaults to `0.0`. The implementation of this method has been modified to incorporate logic that utilizes the new parameter. Specifically, if the `dialog_generations` input is empty, the method will return an empty `RewardScoringResponse`. Furthermore, if the `score_threshold` is greater than or equal to `0`, the method will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These changes affect the control flow of the scoring process based on the specified threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     dialog_generations: List[DialogGenerations]\n     model: str\n+    score_threshold: float = 0.0\n \n \n @json_schema_type\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/105","105","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `reward_scoring.py` file within the `project/api/llama_stack/apis/reward_scoring` directory. A new attribute, `score_threshold`, has been introduced to the `RewardScoringRequest` class, with a default value set to `0.0`. This attribute allows users to specify a threshold for scoring requests. \n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol has been updated to include the `score_threshold` parameter, which also defaults to `0.0`. The implementation of this method has been modified to incorporate logic that utilizes the new parameter. Specifically, if the `dialog_generations` input is empty, the method will return an empty `RewardScoringResponse`. Furthermore, if the `score_threshold` is greater than or equal to `0`, the method will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These changes affect the control flow of the scoring process based on the specified threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def reward_score(\n         self,\n         dialog_generations: List[DialogGenerations],\n-        model: str,\n-    ) -> Union[RewardScoringResponse]: ...\n+        model: str, \n+        score_threshold: float = 0.0,\n+    ) -> Union[RewardScoringResponse]:\n+        if not dialog_generations:\n+            return RewardScoringResponse(scored_generations=[])\n+        \n+        if score_threshold >= 0:\n+            return RewardScoringResponse(\n+                scored_generations=[\n+                    ScoredDialogGenerations(dialog=[], scored_generations=[])\n+                ])\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/106","106","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private dictionary named `_bank_metadata_cache` has been introduced to cache metadata related to memory banks. This cache is utilized across multiple methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding entry is stored in the `_bank_metadata_cache`, and a commit operation is added to persist changes to the database. The `list_memory_banks` method has been updated to return a list that merges entries from the `_bank_metadata_cache` with loaded models, ensuring the output reflects the latest state of memory banks.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of the bank ID in the `_bank_metadata_cache` before accessing the corresponding index. This enhancement ensures that only registered memory banks are considered valid, thereby improving error handling and maintaining the integrity of database interactions. Overall, these modifications enhance internal state management and operational reliability within the `PGVectorMemoryAdapter` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self.cursor = None\n         self.conn = None\n         self.cache = {}\n+        self._bank_metadata_cache = {}\n \n     async def initialize(self) -> None:\n         try:\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/106","106","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private dictionary named `_bank_metadata_cache` has been introduced to cache metadata related to memory banks. This cache is utilized across multiple methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding entry is stored in the `_bank_metadata_cache`, and a commit operation is added to persist changes to the database. The `list_memory_banks` method has been updated to return a list that merges entries from the `_bank_metadata_cache` with loaded models, ensuring the output reflects the latest state of memory banks.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of the bank ID in the `_bank_metadata_cache` before accessing the corresponding index. This enhancement ensures that only registered memory banks are considered valid, thereby improving error handling and maintaining the integrity of database interactions. Overall, these modifications enhance internal state management and operational reliability within the `PGVectorMemoryAdapter` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                 (memory_bank.identifier, memory_bank),\n             ],\n         )\n+        self._bank_metadata_cache[memory_bank.identifier] = memory_bank\n \n         index = BankWithIndex(\n             bank=memory_bank,\n             index=PGVectorIndex(memory_bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n         )\n         self.cache[memory_bank.identifier] = index\n+        self.conn.commit()\n \n     async def list_memory_banks(self) -> List[MemoryBankDef]:\n         banks = load_models(self.cursor, MemoryBankDef)\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/106","106","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private dictionary named `_bank_metadata_cache` has been introduced to cache metadata related to memory banks. This cache is utilized across multiple methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding entry is stored in the `_bank_metadata_cache`, and a commit operation is added to persist changes to the database. The `list_memory_banks` method has been updated to return a list that merges entries from the `_bank_metadata_cache` with loaded models, ensuring the output reflects the latest state of memory banks.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of the bank ID in the `_bank_metadata_cache` before accessing the corresponding index. This enhancement ensures that only registered memory banks are considered valid, thereby improving error handling and maintaining the integrity of database interactions. Overall, these modifications enhance internal state management and operational reliability within the `PGVectorMemoryAdapter` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                     index=PGVectorIndex(bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n                 )\n                 self.cache[bank.identifier] = index\n-        return banks\n+        return [self._bank_metadata_cache.get(bank.identifier, bank) for bank in banks]\n \n     async def insert_documents(\n         self,\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/106","106","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private dictionary named `_bank_metadata_cache` has been introduced to cache metadata related to memory banks. This cache is utilized across multiple methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding entry is stored in the `_bank_metadata_cache`, and a commit operation is added to persist changes to the database. The `list_memory_banks` method has been updated to return a list that merges entries from the `_bank_metadata_cache` with loaded models, ensuring the output reflects the latest state of memory banks.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of the bank ID in the `_bank_metadata_cache` before accessing the corresponding index. This enhancement ensures that only registered memory banks are considered valid, thereby improving error handling and maintaining the integrity of database interactions. Overall, these modifications enhance internal state management and operational reliability within the `PGVectorMemoryAdapter` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         documents: List[MemoryBankDocument],\n         ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/106","106","Automated Test: @eval-senior-reviewer-2","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private dictionary named `_bank_metadata_cache` has been introduced to cache metadata related to memory banks. This cache is utilized across multiple methods, including `register_memory_bank`, `list_memory_banks`, `insert_documents`, and `query_documents`.\n\nIn the `register_memory_bank` method, after updating the memory bank model, the corresponding entry is stored in the `_bank_metadata_cache`, and a commit operation is added to persist changes to the database. The `list_memory_banks` method has been updated to return a list that merges entries from the `_bank_metadata_cache` with loaded models, ensuring the output reflects the latest state of memory banks.\n\nAdditionally, the `insert_documents` and `query_documents` methods now verify the existence of the bank ID in the `_bank_metadata_cache` before accessing the corresponding index. This enhancement ensures that only registered memory banks are considered valid, thereby improving error handling and maintaining the integrity of database interactions. Overall, these modifications enhance internal state management and operational reliability within the `PGVectorMemoryAdapter` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mCIZPD4FGABEvAkAO6UYABMMZAVaMiI2ALM6jT0cuGwntj5fOSwOWBoNQBe6Bj0qPBKGOIAZuVd8ri9kBhOApSQAIwADABsGpAAkmEMmJA76AwM0vn01D2ei/i++BXwGESQAKo2AAyXAA2rBcLhuIgOAB6WFEdSwVoaJjMWFMJRUVTqbSwgDiH3mYFsYAAItQmiRcLDuD5vLDDkcALoACghUJh8MR6xRaIximUONweMJ3mJpIpIvyNLpvkZxwAlKd3BslIgGBR4NxxPgsLx8GUlDNpvArjRkOsXutUHK/AFgqEGk0cARmNQzTlvPJNSRkqtXuF8B9IAADdKYoVqEXwWEkGokEpZcpVCih04AOXw6FotHUhQwOUgShj3mQRQUCxIAA8wip8HhAwxhr9pPw+OtPHSKNx8Pl+ItA3b/EEQog6wEUBgGN5sMap4H1ZrtbqMBojPojCYoGR6PhB2hEsQyMpOgpWOwuLx+MJROIpDIfYLsdGtDp9NuYAhkKhroeCMe5BUGeaJsAsXBUBUkAtM4rg3E+WIqK+2i6GAhjGOAYBGAaIhiLCaDcLGvhoO6AD645oAwADWtIUIacyUIg+G0ARNAUExbDMEUsi0kQUhiEUvH8QQFAaNwsgcAYMTSQYFiQHEZyAae0Qwe6cH7owLakIgqqeHmiyDj8uB0bQ2APM0WTKH4XH6Z6q6WtmnZhtwfF3kUYmyKGkDLFEAA0PBamp8DepAZAtgwPx/E5izYNOq45Oo8gaU5oZWPiABqbkUAAsiQXGuHELE6pQXkzk0iCnHEmyVAFkjJMWZrxXBoakQImBUaRbAiixIqkVczYkF5v65tEBCMJRGxdWgPVoN5FacdxNztYg/kVAgzYoMgeDBfA4zRD8gahgEiLjpQnV5dxrXtaG/mht4SC4Od+WyFdGBUYgN1hj8AyPbQ+AME47Aff5mD0KGjquKRf0A2BuAfZAXWwIoFWQEYZxYClx0PWdC2Q21b1eYjigg4sbGQNg0KUOIvyBrj8j41RCOCt4/lOXTS1vZt0EiftGMbC1DPnd1lJ9RNg2Vbm+Z6l6sgg+e7RhPg3CngWXPTfOY1kC0k7Npg2noJOiBoFI9BjU5M1tf2aCk7sWOnVqNOzezDMqgYHhhvd45PZdDPw0TMzIDZ8DLKN2YBLg2AUFgs2e2EVqXCwajkMg7Bam2ix0cwYavR1U0zaLA1ed86yBt4+DTdENkkGW/la5HkU9NaGzh5H5D0LHI6LFEYiWpNfaXJHAQLNz9XJZNF1wb7rvu6G31U1D/2Aws8Og2GEMvdDS9w4T1JI7QyAYF8mmiIz7wdhsNbY9Onhj54DPnGSC4C+1QvTSL/W9F5Oxn541A0MwOoG5jXDmnKQTYigBEQL2U0NMfhKGrN5TOTYxanDgKgXWrZQoYG1m2eO/AMAhWdstRuYRhhgJ2GQEcJ02LRBcJ4Jg2CGIBHoNke6tBa4YHCg3SgdE+AtloPdX464DAAHkpBUF8KzDYGD9bwAAXRMBTkjKUELH4CiNAEaYDQKQWGA4EYT3psQ1eddJx4KVirPUyA6E8EoGfNge4sCsLmFg4y5QVoNAQFEdAZZszuiMtoDAQCNjKKIFqXASVBzm0pJbTwyiqBiALBVIw5hLBxG8GxD0ligyLlEN4FwmTsF6JrL2CgZ4Kx0gEPdBgLj8zSA3JAdKLh4AqC8erOgXBQz5G8IsDQOdX75w/oNBcZVEDIFShlLKuVnqFVYiVJ+OE7z4UIrCYiZEKLUVovRLETE37FXYrCOmQkspHIEqJcSoYpIyQMJuDCEAsF7gPEeUgQF/Ty0vP4NAUFVIuHpghKM6g3yoT0J+UC6hSJzEQKRUoKY6DkRFKUoFW5MLFgABwAE4UWLAAMwCAOAIPYJASBHATDUBguLaAMCxQwPYAAWI4BwGCLBRTUGlAgji0COGgA4ewjiItuVAUFj0IVQuTJUWFu4gVAA\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/52","52","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `server.py` file located in the `project/api/llama_stack/distribution/server` directory. A new configuration variable named `uvicorn_config` is added, which includes a `timeout_keep_alive` parameter set to 5 seconds, indicating a more aggressive timeout policy for maintaining connections. Additionally, a comment is included to note the introduction of """"risky assumptions about network reliability."""" \n\nThe changes do not affect the existing structure or logic of the functions within the file. Key components such as the `global_exception_handler`, `translate_exception`, and `passthrough` functions remain unchanged, ensuring that the core functionality and error handling mechanisms are preserved. The primary focus of the modifications is on the server configuration, specifically how the `uvicorn` server is set up, without introducing new functionality or altering the application's internal logic. Overall, the changes are centered around enhancing the server's configuration parameters while maintaining existing operational behavior.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and fdd4441f5c5b0293ef170c537ee779e9c453c256.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/distribution/server/server.py (1 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (2)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/distribution/server/server.py (2)</summary><blockquote>\n\n`337-338`: **Clarify the """"risky assumptions"""" comment**\n\nThe added comment mentions """"risky assumptions about network reliability"""" without providing specific details. This vagueness could lead to misunderstandings or overlooked issues in the future.\n\nCould you please elaborate on these assumptions and their potential impact on the system? This information would be valuable for future maintenance and troubleshooting.\n\n---\n\n`339-342`: _:warning: Potential issue_\n\n**Address unused `uvicorn_config` and aggressive timeout**\n\n1. The newly created `uvicorn_config` is not being used in the `uvicorn.run()` call. This appears to be an oversight.\n\n2. Setting `timeout_keep_alive` to 5 seconds is described as an """"Aggressive timeout"""". This could potentially cause issues with long-running connections or slow clients.\n\n\nTo resolve these issues:\n\n1. Update the `uvicorn.run()` call to use the `uvicorn_config`:\n\n```diff\n-uvicorn.run(app, host=listen_host, port=port)\n+uvicorn.Server(uvicorn_config).run()\n```\n\n2. Consider the implications of the aggressive timeout:\n   - How might this affect long-running operations?\n   - Could this negatively impact users with slower internet connections?\n   - Is this timeout aligned with the expected behavior of your API endpoints?\n\n\nTo better understand the impact of this change, could you provide more context on why this aggressive timeout was introduced? Are there specific performance issues or concerns this is addressing?\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/54","54","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily affect the `vector_store.py` file within the project. A new enumeration named `MemoryBankType` has been introduced to classify various memory bank types, specifically vector, key-value, keyword, and graph. Several new data classes have been created, including `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, all of which inherit from a base class called `CommonDef`. These classes utilize Pydantic for data validation and schema generation, with defined fields tailored to each memory bank type.\n\nAdditionally, a type alias `MemoryBankDef` has been established as a union of the new memory bank definitions, featuring a discriminator field for type identification. A protocol named `MemoryBanks` has also been defined, specifying asynchronous methods for listing, retrieving, and registering memory banks, complete with web method route annotations. The existing content extraction and chunking functions remain unchanged but are now framed within the context of memory bank management. Modifications to the `insert_documents` method in the `BankWithIndex` class include updates to the memory bank's status during registration, transitioning from """"new"""" to """"registering"""" and finally to """"active.""""\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhXd8rh9w04CQwCsACwaMNvcPn4BwaGMmJB76AwM0oP01L2eK/i++JXwGERIABVGwAGS4AG1YLhcNxEBwAPQIojqWBtDRMZgIphKKiqdTaBEAcW+SzAtjAABFqM0SLgEedfAijgBdAAU0Nh8KRKK26Mx2MUynxuEJJO8ZIp1NFg3pjO8zMOAEoTu5tkpEAwKPBuOJ8FhePhykp5nN4Axksgtu8tqh5f4giFEGEmsg0IlmNRzTlvPItSRkhsPpAieoABJtSADIYAA3SOOFalF8ARJAmJFKWQq1QoMZOADl8OhaLR1EUMDlIEpk95kMUFMsSAAPMIqfB4YMMUYA6T8PjnCjcfCDfgrYP2q5O1sBFAYBjebAm2fBjVanV6jAaIz6IwmKBkej4MfugjEMjKLoKVjsLi8fjCUTiKQyP1CvFJrQ6fR704LN1YE9CFIcgqEvTE2GWLgqEqSBWmcVx7lfXEVA/bRdDAQxjHAMAjENEQxARNBuBTXw0E9AB9Z00AYABrBkKCNRZKEQBE8HgWsETYZhilkBEpDEYpKIIAING4WQOAMGIpIMCxIDiABJM8QMDWCnE9BCj0YbtSEQNVPFLFYx3+XAGNobBnhaeAiEKNYLWWSBuIM70NytIstk8GN+OEoTihIUTZBjSA1iiAAaHhtXU9j5C+BgBn+QF9WDNASzLRLNPIGD52aQZ/3oWgaVgkzzNwbAAmQAJvBUggHJIbiEIETAaMQE44mGKpIDIJwL3LSAYwAWVqniACFGugWRuBIQLUCUNZyHoaqLRoIhingKZ9PgQzKHYcJxt7TSuJ4+5GsQML/nnRd4sgLzijCmiSFkMBsgXEhbvuypiloMLMHoIgqG4WATjgP9HkxbhMHWRDOwCL00rHQYpCoPx8tFRhKsQHLIDZGMADVH2KAa6tkEaMBoykSBWGMwpjABpe7sZyEICeGxqyYpqnadkd6KFoJnXGJ0nycp2Z6BjIk/tgXmiZZwWlV6d5mxoOZ0CvbisAakcsvR3qAGEWFV1m81OaRPE1jG2O8VbPCsWR8uWc0gvrZG0CunJFhhgClc1PpPUgYDuv1MK/i2WCJoYDb7bWEgJWQGb/miL4+ADLsasJo6SZ2iatwMDxesl/mDYzzwFmWUzzOiZplYKHrNPcl3tXbZADvqxqq3J/5UowE7ZgwfBRUvIPYGV0tNQi/5qHrSOJQdvhcF2lAllWZzyxalKNx9WQvramDDQIJg/H6wa+eOqaY7buawsQUONtkS7mlkOdYAYnuBhqrZFGQBPIAt514rCgITIqOUAEX0lYBBRM6Sgl0m7yAaiTLuSdB6YB7n3aIA9GgkAEK/WAih/DthoM1PSHUmxIHEACIKBQxDlnKlHKqRYmCNnsgrKglDErfS0gUGil0VgMWYFWfAsUIK4GoZ6f4s5RRiHuB2Fwnge4wWMiQX6KljJFmdgIBiyUhj0JoC2UcKdDqwJog5TAaBSCCMBtsGM/xBgUFwORWg/CurLEQIFNgb9TTBhjPzAA6qieScxmyBVNpAUYMgSBkAcoocO0RqpnQXEoZWVESrIGwNwZGnx6y12gWnQxZltRkNrmAkhoEeqGgsl3f4pZFqXRMpgRAHcP48NiBlBo1UYiFIgXkogDQ2GzXXuEIsMRqJPhIDELOAB5BGPowq1y7JgHSHUMDdmeMGZ0FBiqlU8D0iha8Laz10VkgxRiKymO2gPURmTFA+BemI0uYcyHOzqp4BiAgBhhFnhNWCsgIG8LYXfB+T8G63DBmoXZFQP71m7LQC2ZCDnHSzuYSwcRvA0GKfqVyK5RCVVRZ3XRzYhw2OiPWc4AgLYMAWREMF25ID5nap1H5JY6BcAPoTfmY0JpTSwDGPCj5CLEQRKRCiVFaL0UYriFi5sWLQL4njCgPkRJiRjAYKANLMpozdAy2gTLdasH1AXURXKGL4XpEREilVBXiLooaY0zFWLiA4lK66srnS+X8oq5V7UgnJRNEy3GAkKB52lhTZcBr8BGt5aasiaAhLUUtQxa1FBxV2slYfXijq5V+QVUq6lHq1XFm9b1Dm9NnoBpJnqzl3KCImv5WaqNQrY2iptRKziKbpV+vTa6rNKrUbZTzYygtb0PoloFkG/VFbjV8oFbWi1Ir42JvYsmwmrbvLOvlQFTtOae1er7aLcWQ6y29THeG6tkbo3CqtUxBNtr53NsXWmldGa11QDZZsi2Fct2atzim/Ogtg2HqrZO099bZ1XvtS2u9wkH1upgHPV2b6NVMr3eTHxWwrBxovRyg9hqeX/prYBmdF652gdvTK9tmb3XbwYrvb4vaP3MuZnAjDIaw04ZPXW/DYqQMLp4kuwS96O1SRiNuDCu5sILMPMeRISkLzRHAjefwaAYJwXUjApCiZ1CfnQnoH84F1DkUWIgciZRsx0GjTYzTImICQAAOwAE4bMAA4BC0AmBMfYAgAAMABmNAhwGBWdoN59zkwrP2dCwwOznmJjudoCsKzEwbMMAEGOHcWFLM6dsfpwzWYqgmYPJpoAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-import base64\n-import io\n-import re\n-from abc import ABC, abstractmethod\n-from dataclasses import dataclass\n-from typing import Any, Dict, List, Optional\n-from urllib.parse import unquote\n-\n-import chardet\n-import httpx\n-import numpy as np\n-from numpy.typing import NDArray\n-from pypdf import PdfReader\n-from termcolor import cprint\n-\n-from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_models.llama3.api.tokenizer import Tokenizer\n-\n-from llama_stack.apis.memory import *  # noqa: F403\n-\n-ALL_MINILM_L6_V2_DIMENSION = 384\n-\n-EMBEDDING_MODELS = {}\n-\n-\n-def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n-    global EMBEDDING_MODELS\n-\n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n-\n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n-    return loaded_model\n-\n-\n-def parse_data_url(data_url: str):\n-    data_url_pattern = re.compile(\n-        r""""^""""\n-        r""""data:""""\n-        r""""(?P<mimetype>[\w/\-+.]+)""""\n-        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n-        r""""(?P<base64>;base64)?""""\n-        r"""",(?P<data>.*)""""\n-        r""""$"""",\n-        re.DOTALL,\n-    )\n-    match = data_url_pattern.match(data_url)\n-    if not match:\n-        raise ValueError(""""Invalid Data URL format"""")\n-\n-    parts = match.groupdict()\n-    parts[""""is_base64""""] = bool(parts[""""base64""""])\n-    return parts\n-\n-\n-def content_from_data(data_url: str) -> str:\n-    parts = parse_data_url(data_url)\n-    data = parts[""""data""""]\n-\n-    if parts[""""is_base64""""]:\n-        data = base64.b64decode(data)\n-    else:\n-        data = unquote(data)\n-        encoding = parts[""""encoding""""] or """"utf-8""""\n-        data = data.encode(encoding)\n-\n-    encoding = parts[""""encoding""""]\n-    if not encoding:\n-        detected = chardet.detect(data)\n-        encoding = detected[""""encoding""""]\n-\n-    mime_type = parts[""""mimetype""""]\n-    mime_category = mime_type.split(""""/"""")[0]\n-    if mime_category == """"text"""":\n-        # For text-based files (including CSV, MD)\n-        return data.decode(encoding)\n-\n-    elif mime_type == """"application/pdf"""":\n-        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n-        pdf_bytes = io.BytesIO(data)\n-        pdf_reader = PdfReader(pdf_bytes)\n-        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n-\n-    else:\n-        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n-        return """"""""\n-\n-\n-async def content_from_doc(doc: MemoryBankDocument) -> str:\n-    if isinstance(doc.content, URL):\n-        if doc.content.uri.startswith(""""data:""""):\n-            return content_from_data(doc.content.uri)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content.uri)\n-                return r.text\n-\n-    pattern = re.compile(""""^(https?://|file://|data:)"""")\n-    if pattern.match(doc.content):\n-        if doc.content.startswith(""""data:""""):\n-            return content_from_data(doc.content)\n-        else:\n-            async with httpx.AsyncClient() as client:\n-                r = await client.get(doc.content)\n-                return r.text\n-\n-    return interleaved_text_media_as_str(doc.content)\n-\n-\n-def make_overlapped_chunks(\n-    document_id: str, text: str, window_len: int, overlap_len: int\n-) -> List[Chunk]:\n-    tokenizer = Tokenizer.get_instance()\n-    tokens = tokenizer.encode(text, bos=False, eos=False)\n-\n-    chunks = []\n-    for i in range(0, len(tokens), window_len - overlap_len):\n-        toks = tokens[i : i + window_len]\n-        chunk = tokenizer.decode(toks)\n-        chunks.append(\n-            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n-        )\n-\n-    return chunks\n-\n-\n-class EmbeddingIndex(ABC):\n-    @abstractmethod\n-    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        raise NotImplementedError()\n-\n-    @abstractmethod\n-    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        raise NotImplementedError()\n-\n-\n-@dataclass\n-class BankWithIndex:\n-    bank: MemoryBankDef\n-    index: EmbeddingIndex\n-\n-    async def insert_documents(\n-        self,\n-        documents: List[MemoryBankDocument],\n+\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+    _status: str = """"new""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider,\n     ) -> None:\n-        model = get_embedding_model(self.bank.embedding_model)\n-        for doc in documents:\n-            content = await content_from_doc(doc)\n-            chunks = make_overlapped_chunks(\n-                doc.document_id,\n-                content,\n-                self.bank.chunk_size_in_tokens,\n-                self.bank.overlap_size_in_tokens\n-                or (self.bank.chunk_size_in_tokens // 4),\n-            )\n-            if not chunks:\n-                continue\n-            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n-\n-            await self.index.add_chunks(chunks, embeddings)\n-\n-    async def query_documents(\n-        self,\n-        query: InterleavedTextMedia,\n-        params: Optional[Dict[str, Any]] = None,\n-    ) -> QueryDocumentsResponse:\n-        if params is None:\n-            params = {}\n-        k = params.get(""""max_chunks"""", 3)\n-\n-        def _process(c) -> str:\n-            if isinstance(c, str):\n-                return c\n-            else:\n-                return """"<media>""""\n-\n-        if isinstance(query, list):\n-            query_str = """" """".join([_process(c) for c in query])\n-        else:\n-            query_str = _process(query)\n-\n-        model = get_embedding_model(self.bank.embedding_model)\n-        query_vector = model.encode([query_str])[0].astype(np.float32)\n-        return await self.index.query(query_vector, k)\n+        memory_bank._status = """"registering"""" \n+        # Registration logic would go here\n+        memory_bank._status = """"active""""\n+        ...\n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/51","51","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces optimizations to the `OpenTelemetryAdapter` class in the `opentelemetry.py` file, specifically focusing on the conversion of trace and span IDs. Two caching mechanisms, `_trace_id_cache` and `_span_id_cache`, are implemented to store previously computed trace and span IDs, each with a maximum capacity of 10,000 entries. The `string_to_trace_id` and `string_to_span_id` functions are modified to utilize these caches, checking for existing entries before executing the conversion logic. If the cache exceeds its maximum size, it is cleared to maintain efficiency. The caching mechanism employs a hash of the first three characters of the input string as a key for the span ID cache. Despite these internal changes, the overall structure of the `OpenTelemetryAdapter` class remains unchanged, with no alterations to its public methods or attributes. The function signatures for `string_to_trace_id` and `string_to_span_id` have been updated accordingly to reflect these changes.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," from .config import OpenTelemetryConfig\n \n \n-def string_to_trace_id(s: str) -> int:\n-    # Convert the string to bytes and then to an integer\n-    return int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+# Optimization: Cache trace and span ID conversions\n+_trace_id_cache = {}\n+_span_id_cache = {}\n+_max_cache_size = 10000\n \n+def string_to_trace_id(s: str) -> int:\n+    if s not in _trace_id_cache:\n+        if len(_trace_id_cache) >= _max_cache_size:\n+            _trace_id_cache.clear()\n+        _trace_id_cache[s] = int.from_bytes(s.encode(), byteorder=""""big"""", signed=False)\n+    return _trace_id_cache[s]\n \n def string_to_span_id(s: str) -> int:\n-    # Use only the first 8 bytes (64 bits) for span ID\n-    return int.from_bytes(s.encode()[:8], byteorder=""""big"""", signed=False)\n+    # Optimization: Cache span ID conversions\n+    # Use hash of first few chars as cache key for better memory usage\n+    key = hash(s[:3]) % 1000  \n+    if key not in _span_id_cache:\n+        if len(_span_id_cache) >= _max_cache_size:\n+            _span_id_cache.clear()\n+        # Convert full span ID string to int value\n+        _span_id_cache[key] = int.from_bytes(s.encode(), byteorder=""""little"""", signed=False) \n+    return _span_id_cache[key]\n+\n \n \n def is_tracing_enabled(tracer):\n","project/api/llama_stack/providers/adapters/telemetry/opentelemetry/opentelemetry.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/50","50","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request primarily affect the `faiss.py` file within the `project/api/llama_stack/providers/impls/meta_reference/memory` directory. The `FaissIndex` class has been removed, and its functionalities have been integrated into a newly created abstract base class called `EmbeddingIndex`, which includes two abstract methods: `add_chunks` and `query`. This restructuring aims to enhance modularity in handling embeddings.\n\nNew functionalities have been introduced, including the `get_embedding_model` function for managing sentence transformer models and the `parse_data_url` function for processing data URLs based on MIME types. The `content_from_data` function has been added to handle various content types, such as text and PDF, with specific decoding and extraction processes.\n\nThe `FaissMemoryImpl` class has been updated to utilize the `EmbeddingIndex` class, with changes to the method signatures of `insert_documents` and `query_documents` reflecting new document processing and querying approaches. Additionally, a new data structure, `BankWithIndex`, has been introduced to associate memory banks with their embedding indices, contributing to improved memory management organization. Overall, these changes represent a significant overhaul of the embedding and document processing logic.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-\n-import logging\n-\n+import base64\n+import io\n+import re\n+from abc import ABC, abstractmethod\n+from dataclasses import dataclass\n from typing import Any, Dict, List, Optional\n+from urllib.parse import unquote\n \n-import faiss\n+import chardet\n+import httpx\n import numpy as np\n from numpy.typing import NDArray\n+from pypdf import PdfReader\n+from termcolor import cprint\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_models.llama3.api.tokenizer import Tokenizer\n \n from llama_stack.apis.memory import *  # noqa: F403\n-from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n-\n-from llama_stack.providers.utils.memory.vector_store import (\n-    ALL_MINILM_L6_V2_DIMENSION,\n-    BankWithIndex,\n-    EmbeddingIndex,\n-)\n-from llama_stack.providers.utils.telemetry import tracing\n-\n-from .config import FaissImplConfig\n-\n-logger = logging.getLogger(__name__)\n \n+ALL_MINILM_L6_V2_DIMENSION = 384\n+\n+EMBEDDING_MODELS = {}\n+\n+\n+def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n+    global EMBEDDING_MODELS\n+\n+    loaded_model = EMBEDDING_MODELS.get(model)\n+    if loaded_model is not None:\n+        return loaded_model\n+\n+    print(f""""Loading sentence transformer for {model}..."""")\n+    from sentence_transformers import SentenceTransformer\n+\n+    loaded_model = SentenceTransformer(model)\n+    EMBEDDING_MODELS[model] = loaded_model\n+    return loaded_model\n+\n+\n+def parse_data_url(data_url: str):\n+    data_url_pattern = re.compile(\n+        r""""^""""\n+        r""""data:""""\n+        r""""(?P<mimetype>[\w/\-+.]+)""""\n+        r""""(?P<charset>;charset=(?P<encoding>[\w-]+))?""""\n+        r""""(?P<base64>;base64)?""""\n+        r"""",(?P<data>.*)""""\n+        r""""$"""",\n+        re.DOTALL,\n+    )\n+    match = data_url_pattern.match(data_url)\n+    if not match:\n+        raise ValueError(""""Invalid Data URL format"""")\n+\n+    parts = match.groupdict()\n+    parts[""""is_base64""""] = bool(parts[""""base64""""])\n+    return parts\n+\n+\n+def content_from_data(data_url: str) -> str:\n+    parts = parse_data_url(data_url)\n+    data = parts[""""data""""]\n+\n+    if parts[""""is_base64""""]:\n+        data = base64.b64decode(data)\n+    else:\n+        data = unquote(data)\n+        encoding = parts[""""encoding""""] or """"utf-8""""\n+        data = data.encode(encoding)\n+\n+    encoding = parts[""""encoding""""]\n+    if not encoding:\n+        detected = chardet.detect(data)\n+        encoding = detected[""""encoding""""]\n+\n+    mime_type = parts[""""mimetype""""]\n+    mime_category = mime_type.split(""""/"""")[0]\n+    if mime_category == """"text"""":\n+        # For text-based files (including CSV, MD)\n+        return data.decode(encoding)\n+\n+    elif mime_type == """"application/pdf"""":\n+        # For PDF and DOC/DOCX files, we can't reliably convert to string)\n+        pdf_bytes = io.BytesIO(data)\n+        pdf_reader = PdfReader(pdf_bytes)\n+        return """"\n"""".join([page.extract_text() for page in pdf_reader.pages])\n+\n+    else:\n+        cprint(""""Could not extract content from data_url properly."""", color=""""red"""")\n+        return """"""""\n+\n+\n+async def content_from_doc(doc: MemoryBankDocument) -> str:\n+    if isinstance(doc.content, URL):\n+        if doc.content.uri.startswith(""""data:""""):\n+            return content_from_data(doc.content.uri)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content.uri)\n+                return r.text\n+\n+    pattern = re.compile(""""^(https?://|file://|data:)"""")\n+    if pattern.match(doc.content):\n+        if doc.content.startswith(""""data:""""):\n+            return content_from_data(doc.content)\n+        else:\n+            async with httpx.AsyncClient() as client:\n+                r = await client.get(doc.content)\n+                return r.text\n+\n+    return interleaved_text_media_as_str(doc.content)\n+\n+\n+def make_overlapped_chunks(\n+    document_id: str, text: str, window_len: int, overlap_len: int\n+) -> List[Chunk]:\n+    tokenizer = Tokenizer.get_instance()\n+    tokens = tokenizer.encode(text, bos=False, eos=False)\n+\n+    chunks = []\n+    for i in range(0, len(tokens), window_len - overlap_len):\n+        toks = tokens[i : i + window_len]\n+        chunk = tokenizer.decode(toks)\n+        chunks.append(\n+            Chunk(content=chunk, token_count=len(toks), document_id=document_id)\n+        )\n \n-class FaissIndex(EmbeddingIndex):\n-    id_by_index: Dict[int, str]\n-    chunk_by_index: Dict[int, str]\n+    return chunks\n \n-    def __init__(self, dimension: int):\n-        self.index = faiss.IndexFlatL2(dimension)\n-        self.id_by_index = {}\n-        self.chunk_by_index = {}\n \n-    @tracing.span(name=""""add_chunks"""")\n+class EmbeddingIndex(ABC):\n+    @abstractmethod\n     async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n-        indexlen = len(self.id_by_index)\n-        for i, chunk in enumerate(chunks):\n-            self.chunk_by_index[indexlen + i] = chunk\n-            self.id_by_index[indexlen + i] = chunk.document_id\n-\n-        self.index.add(np.array(embeddings).astype(np.float32))\n+        raise NotImplementedError()\n \n+    @abstractmethod\n     async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n-        distances, indices = self.index.search(\n-            embedding.reshape(1, -1).astype(np.float32), k\n-        )\n-\n-        chunks = []\n-        scores = []\n-        for d, i in zip(distances[0], indices[0]):\n-            if i < 0:\n-                continue\n-            chunks.append(self.chunk_by_index[int(i)])\n-            scores.append(1.0 / float(d))\n-\n-        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+        raise NotImplementedError()\n \n \n-class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n-    def __init__(self, config: FaissImplConfig) -> None:\n-        self.config = config\n-        self.cache = {}\n-\n-    async def initialize(self) -> None: ...\n-\n-    async def shutdown(self) -> None: ...\n-\n-    async def register_memory_bank(\n-        self,\n-        memory_bank: MemoryBankDef,\n-    ) -> None:\n-        assert (\n-            memory_bank.type == MemoryBankType.vector.value\n-        ), f""""Only vector banks are supported {memory_bank.type}""""\n-\n-        index = BankWithIndex(\n-            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n-        )\n-        self.cache[memory_bank.identifier] = index\n-\n-    async def list_memory_banks(self) -> List[MemoryBankDef]:\n-        return [i.bank for i in self.cache.values()]\n+@dataclass\n+class BankWithIndex:\n+    bank: MemoryBankDef\n+    index: EmbeddingIndex\n \n     async def insert_documents(\n         self,\n-        bank_id: str,\n         documents: List[MemoryBankDocument],\n-        ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        await index.insert_documents(documents)\n+        model = get_embedding_model(self.bank.embedding_model)\n+        for doc in documents:\n+            content = await content_from_doc(doc)\n+            chunks = make_overlapped_chunks(\n+                doc.document_id,\n+                content,\n+                self.bank.chunk_size_in_tokens,\n+                self.bank.overlap_size_in_tokens\n+                or (self.bank.chunk_size_in_tokens // 4),\n+            )\n+            if not chunks:\n+                continue\n+            embeddings = model.encode([x.content for x in chunks]).astype(np.float32)\n+            # Unstable order of chunks\n+            chunks = sorted(chunks, key=lambda x: hash(x.content))\n+            \n+            await self.index.add_chunks(chunks, embeddings)\n \n     async def query_documents(\n         self,\n-        bank_id: str,\n         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id)\n-        if index is None:\n-            raise ValueError(f""""Bank {bank_id} not found"""")\n-\n-        return await index.query_documents(query, params)\n+        if params is None:\n+            params = {}\n+        k = params.get(""""max_chunks"""", 3)\n+\n+        def _process(c) -> str:\n+            if isinstance(c, str):\n+                return c\n+            else:\n+                return """"<media>""""\n+\n+        if isinstance(query, list):\n+            query_str = """" """".join([_process(c) for c in query])\n+        else:\n+            query_str = _process(query)\n+\n+        model = get_embedding_model(self.bank.embedding_model)\n+        query_vector = model.encode([query_str])[0].astype(np.float32)\n+        return await self.index.query(query_vector, k)\n","project/api/llama_stack/providers/impls/meta_reference/memory/faiss.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/53","53","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces significant modifications to the `LocalInference` class within the `LocalInference.swift` file. Several new methods are added to enhance the functionality related to message handling and encoding. The new methods include `encodeHeader`, `encodeDialogPrompt`, `getRole`, `encodeMessage`, `prepareMessages`, `maybeExtractCustomToolCalls`, and `decodeAssistantMessage`. \n\nThe `encodeHeader` method formats role headers, while `encodeDialogPrompt` constructs prompt strings from message arrays, incorporating the encoded header for the assistant role. The `getRole` method identifies the role of a message based on its type, and `encodeMessage` formats individual messages, including role and content. \n\nAdditionally, `prepareMessages` prepares messages for chat completion requests, ensuring proper formatting of system and user messages. The `maybeExtractCustomToolCalls` method is updated to improve handling of tool calls, particularly in parameter processing, while `decodeAssistantMessage` now removes specific prefixes and suffixes from content and extracts tool calls. These changes collectively enhance the message processing capabilities of the `LocalInference` class.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import Foundation\n \n-import LLaMARunner\n import LlamaStackClient\n \n-class RunnerHolder: ObservableObject {\n-  var runner: Runner?\n+func encodeHeader(role: String) -> String {\n+  return """"<|start_header_id|>\(role)<|end_header_id|>\n\n""""\n }\n \n-public class LocalInference: Inference {\n-  private var runnerHolder = RunnerHolder()\n-  private let runnerQueue: DispatchQueue\n+func encodeDialogPrompt(messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload]) -> String {\n+  var prompt = """"""""\n \n-  public init (queue: DispatchQueue) {\n-    runnerQueue = queue\n+  prompt.append(""""<|begin_of_text|>"""")\n+  for message in messages {\n+    let msg = encodeMessage(message: message)\n+    prompt += msg\n   }\n \n-  public func loadModel(modelPath: String, tokenizerPath: String, completion: @escaping (Result<Void, Error>) -> Void) {\n-    runnerHolder.runner = runnerHolder.runner ?? Runner(\n-      modelPath: modelPath,\n-      tokenizerPath: tokenizerPath\n-    )\n-\n-\n-    runnerQueue.async {\n-      let runner = self.runnerHolder.runner\n-      do {\n-        try runner!.load()\n-        completion(.success(()))\n-      } catch let loadError {\n-        print(""""error: """" + loadError.localizedDescription)\n-        completion(.failure(loadError))\n+  prompt.append(encodeHeader(role: """"assistant""""))\n+\n+  return prompt\n+}\n+\n+func getRole(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  switch (message) {\n+  case .UserMessage(let m):\n+    return m.role.rawValue\n+  case .SystemMessage(let m):\n+    return m.role.rawValue\n+  case .ToolResponseMessage(let m):\n+    return m.role.rawValue\n+  case .CompletionMessage(let m):\n+    return m.role.rawValue\n+  }\n+}\n+\n+func encodeMessage(message: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload) -> String {\n+  var prompt = encodeHeader(role: getRole(message: message))\n+\n+  switch (message) {\n+  case .CompletionMessage(let m):\n+    if (m.tool_calls.count > 0) {\n+      prompt += """"<|python_tag|>""""\n+    }\n+  default:\n+    break\n+  }\n+\n+  func _processContent(_ content: Any) -> String {\n+    func _process(_ c: Any) {\n+      if let str = c as? String {\n+        prompt += str\n       }\n     }\n+\n+    if let str = content as? String {\n+      _process(str)\n+    } else if let list = content as? [Any] {\n+      for c in list {\n+        _process(c)\n+      }\n+    }\n+\n+    return """"""""\n   }\n \n-  public func stop() {\n-    runnerHolder.runner?.stop()\n+  switch (message) {\n+  case .UserMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .SystemMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .ToolResponseMessage(let m):\n+    prompt += _processContent(m.content)\n+  case .CompletionMessage(let m):\n+    prompt += _processContent(m.content)\n   }\n \n-  public func chatCompletion(request: Components.Schemas.ChatCompletionRequest) -> AsyncStream<Components.Schemas.ChatCompletionResponseStreamChunk> {\n-    return AsyncStream { continuation in\n-      runnerQueue.async {\n-        do {\n-          var tokens: [String] = []\n-\n-          let prompt = try encodeDialogPrompt(messages: prepareMessages(request: request))\n-          var stopReason: Components.Schemas.StopReason? = nil\n-          var buffer = """"""""\n-          var ipython = false\n-          var echoDropped = false\n-\n-          try self.runnerHolder.runner?.generate(prompt, sequenceLength: 4096) { token in\n-            buffer += token\n-\n-            // HACK: Workaround until LlamaRunner exposes echo param\n-            if (!echoDropped) {\n-              if (buffer.hasPrefix(prompt)) {\n-                buffer = String(buffer.dropFirst(prompt.count))\n-                echoDropped = true\n-              }\n-              return\n-            }\n-\n-            tokens.append(token)\n-\n-            if !ipython && (buffer.starts(with: """"<|python_tag|>"""") || buffer.starts(with: """"["""") ) {\n-              ipython = true\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                      content: .case1(""""""""),\n-                      parse_status: Components.Schemas.ToolCallParseStatus.started\n-                      )\n-                    ),\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-\n-              if (buffer.starts(with: """"<|python_tag|>"""")) {\n-                buffer = String(buffer.dropFirst(""""<|python_tag|>"""".count))\n-              }\n-            }\n-\n-            // TODO: Non-streaming lobprobs\n-\n-            var text = """"""""\n-            if token == """"<|eot_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_turn\n-            } else if token == """"<|eom_id|>"""" {\n-              stopReason = Components.Schemas.StopReason.end_of_message\n-            } else {\n-              text = token\n-            }\n-\n-            var delta: Components.Schemas.ChatCompletionResponseEvent.deltaPayload\n-            if ipython {\n-              delta = .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                content: .case1(text),\n-                parse_status: .in_progress\n-              ))\n-            } else {\n-              delta = .case1(text)\n-            }\n-\n-            if stopReason == nil {\n-              continuation.yield(\n-                Components.Schemas.ChatCompletionResponseStreamChunk(\n-                  event: Components.Schemas.ChatCompletionResponseEvent(\n-                    delta: delta,\n-                    event_type: .progress\n-                  )\n-                )\n-              )\n-            }\n-          }\n-\n-          if stopReason == nil {\n-            stopReason = Components.Schemas.StopReason.out_of_tokens\n-          }\n-\n-          let message = decodeAssistantMessage(tokens: tokens.joined(), stopReason: stopReason!)\n-          // TODO: non-streaming support\n-\n-          let didParseToolCalls = message.tool_calls.count > 0\n-          if ipython && !didParseToolCalls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(content: .case1(""""""""), parse_status: .failure)),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          for toolCall in message.tool_calls {\n-            continuation.yield(\n-              Components.Schemas.ChatCompletionResponseStreamChunk(\n-                event: Components.Schemas.ChatCompletionResponseEvent(\n-                  delta: .ToolCallDelta(Components.Schemas.ToolCallDelta(\n-                    content: .ToolCall(toolCall),\n-                    parse_status: .success\n-                  )),\n-                  event_type: .progress\n-                )\n-                // TODO: stopReason\n-              )\n-            )\n-          }\n-\n-          continuation.yield(\n-            Components.Schemas.ChatCompletionResponseStreamChunk(\n-              event: Components.Schemas.ChatCompletionResponseEvent(\n-                delta: .case1(""""""""),\n-                event_type: .complete\n-              )\n-              // TODO: stopReason\n-            )\n-          )\n-        }\n-        catch (let error) {\n-          print(""""Inference error: """" + error.localizedDescription)\n+  var eom = false\n+\n+  switch (message) {\n+  case .UserMessage(let m):\n+    switch (m.content) {\n+    case .case1(let c):\n+      prompt += _processContent(c)\n+    case .case2(let c):\n+      prompt += _processContent(c)\n+    }\n+  case .CompletionMessage(let m):\n+    // TODO: Support encoding past tool call history\n+    // for t in m.tool_calls {\n+    //  _processContent(t.)\n+    //}\n+    eom = m.stop_reason == Components.Schemas.StopReason.end_of_message\n+  case .SystemMessage(_):\n+    break\n+  case .ToolResponseMessage(_):\n+    break\n+  }\n+\n+  if (eom) {\n+    prompt += """"<|eom_id|>""""\n+  } else {\n+    prompt += """"<|eot_id|>""""\n+  }\n+\n+  return prompt\n+}\n+\n+func prepareMessages(request: Components.Schemas.ChatCompletionRequest) throws -> [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] {\n+  var existingMessages = request.messages\n+  var existingSystemMessage: Components.Schemas.ChatCompletionRequest.messagesPayloadPayload?\n+  // TODO: Existing system message\n+\n+  var messages: [Components.Schemas.ChatCompletionRequest.messagesPayloadPayload] = []\n+\n+  let defaultGen = SystemDefaultGenerator()\n+  let defaultTemplate = defaultGen.gen()\n+\n+  var sysContent = """"""""\n+\n+  // TODO: Built-in tools\n+\n+  sysContent += try defaultTemplate.render()\n+\n+  messages.append(.SystemMessage(Components.Schemas.SystemMessage(\n+    content: .case1(sysContent),\n+    role: .system))\n+  )\n+\n+  if request.tools?.isEmpty == false {\n+    // TODO: Separate built-ins and custom tools (right now everything treated as custom)\n+    let toolGen = FunctionTagCustomToolGenerator()\n+    let toolTemplate = try toolGen.gen(customTools: request.tools!)\n+    let tools = try toolTemplate.render()\n+    messages.append(.UserMessage(Components.Schemas.UserMessage(\n+      content: .case1(tools),\n+      role: .user)\n+    ))\n+  }\n+\n+  messages.append(contentsOf: existingMessages)\n+\n+  return messages\n+}\n+\n+struct FunctionCall {\n+    let name: String\n+    let params: [String: Any]\n+}\n+\n+public func maybeExtractCustomToolCalls(input: String) -> [Components.Schemas.ToolCall] {\n+  guard input.hasPrefix(""""["""") && input.hasSuffix(""""]"""") else {\n+    return []\n+  }\n+\n+  do {\n+    let trimmed = input.trimmingCharacters(in: CharacterSet(charactersIn: """"[]""""))\n+    let calls = trimmed.components(separatedBy: """"),"""").map { $0.hasSuffix("""")"""") ? $0 : $0 + """")"""" }\n+\n+    var result: [Components.Schemas.ToolCall] = []\n+\n+    for call in calls {\n+      guard let nameEndIndex = call.firstIndex(of: """"(""""),\n+            let paramsStartIndex = call.firstIndex(of: """"{""""),\n+            let paramsEndIndex = call.lastIndex(of: """"}"""") else {\n+        return []\n+      }\n+\n+      let name = String(call[..<nameEndIndex]).trimmingCharacters(in: .whitespacesAndNewlines)\n+      let paramsString = String(call[paramsStartIndex...paramsEndIndex])\n+\n+      guard let data = paramsString.data(using: .utf8),\n+            let params = try? JSONSerialization.jsonObject(with: data, options: []) as? [String: Any] else {\n+        return []\n+      }\n+\n+      var props: [String : Components.Schemas.ToolCall.argumentsPayload.additionalPropertiesPayload] = [:]\n+      for (param_name, param) in params {\n+        switch (param) {\n+        case let value as String:\n+          props[param_name] = .case1(value)\n+        case let value as Int:\n+          props[param_name] = .case2(value)\n+        case let value as Float: // Changed from Double to Float for less precise comparisons\n+          props[param_name] = .case3(value)\n+        case let value as Bool:\n+          props[param_name] = .case4(value)\n+        default:\n+          return []\n         }\n       }\n+\n+      result.append(\n+        Components.Schemas.ToolCall(\n+          arguments: .init(additionalProperties: props),\n+          call_id: UUID().uuidString,\n+          tool_name: .case2(name) // custom_tool\n+        )\n+      )\n+    }\n+\n+    return result.isEmpty ? [] : result\n+  } catch {\n+    return []\n+  }\n+}\n+\n+func decodeAssistantMessage(tokens: String, stopReason: Components.Schemas.StopReason) -> Components.Schemas.CompletionMessage {\n+  var content = tokens\n+\n+  let roles = [""""user"""", """"system"""", """"assistant""""]\n+  for role in roles {\n+    let headerStr = encodeHeader(role: role)\n+    if content.hasPrefix(headerStr) {\n+      content = String(content.dropFirst(encodeHeader(role: role).count))\n     }\n   }\n+\n+  if content.hasPrefix(""""<|python_tag|>"""") {\n+    content = String(content.dropFirst(""""<|python_tag|>"""".count))\n+  }\n+\n+\n+  if content.hasSuffix(""""<|eot_id|>"""") {\n+    content = String(content.dropLast(""""<|eot_id|>"""".count))\n+  } else {\n+    content = String(content.dropLast(""""<|eom_id|>"""".count))\n+  }\n+\n+  return Components.Schemas.CompletionMessage(\n+    content: .case1(content),\n+    role: .assistant,\n+    stop_reason: stopReason,\n+    tool_calls: maybeExtractCustomToolCalls(input: content)\n+  )\n }\n","project/api/llama_stack/providers/impls/ios/inference/LocalInferenceImpl/LocalInference.swift"
"github.com/coderabbitai/Golden-PR-Dataset/pull/55","55","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `batch_inference.py` file introduce a new memory management system utilizing FAISS for vector storage and retrieval. A new class, `FaissIndex`, is created, extending `EmbeddingIndex`, and includes methods for adding chunks and querying embeddings. This class features an initializer that sets up various dictionaries for managing embeddings and their metadata.\n\nAdditionally, the `FaissMemoryImpl` class is implemented to handle memory management tasks. It includes methods for initializing, shutting down, registering memory banks, listing memory banks, and inserting documents. The `insert_documents` method is revised to accept a `bank_id` and a list of documents, incorporating a silent failure mechanism if the specified bank is absent. A new method, `query_documents`, is also added to retrieve documents based on a query, which raises an error if the bank is not found.\n\nSeveral classes and methods related to batch and chat completion have been removed, indicating a shift in focus towards the new memory management system. The error handling in `insert_documents` has been adjusted to allow silent failures, while `query_documents` raises a `ValueError` for missing banks. Overall, these changes reflect a restructuring of the API to enhance memory management capabilities.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-from typing import List, Optional, Protocol, runtime_checkable\n+import logging\n \n-from llama_models.schema_utils import json_schema_type, webmethod\n+from typing import Any, Dict, List, Optional\n \n-from pydantic import BaseModel, Field\n+import faiss\n+import numpy as np\n+from numpy.typing import NDArray\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n-from llama_stack.apis.inference import *  # noqa: F403\n \n+from llama_stack.apis.memory import *  # noqa: F403\n+from llama_stack.providers.datatypes import MemoryBanksProtocolPrivate\n \n-@json_schema_type\n-class BatchCompletionRequest(BaseModel):\n-    model: str\n-    content_batch: List[InterleavedTextMedia]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n-    logprobs: Optional[LogProbConfig] = None\n+from llama_stack.providers.utils.memory.vector_store import (\n+    ALL_MINILM_L6_V2_DIMENSION,\n+    BankWithIndex,\n+    EmbeddingIndex,\n+)\n+from llama_stack.providers.utils.telemetry import tracing\n \n+from .config import FaissImplConfig\n \n-@json_schema_type\n-class BatchCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+logger = logging.getLogger(__name__)\n \n \n-@json_schema_type\n-class BatchChatCompletionRequest(BaseModel):\n-    model: str\n-    messages_batch: List[List[Message]]\n-    sampling_params: Optional[SamplingParams] = SamplingParams()\n+class FaissIndex(EmbeddingIndex):\n+    id_by_index: Dict[int, str]\n+    chunk_by_index: Dict[int, str]\n+    embedding_cache: Dict[str, NDArray]\n+    _cached_distances = []\n \n-    # zero-shot tool definitions as input to the model\n-    tools: Optional[List[ToolDefinition]] = Field(default_factory=list)\n-    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n-    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n-        default=ToolPromptFormat.json\n-    )\n-    logprobs: Optional[LogProbConfig] = None\n+    def __init__(self, dimension: int):\n+        self.index = faiss.IndexFlatL2(dimension)\n+        self.id_by_index = {}\n+        self.chunk_by_index = {}\n+        self.embedding_cache = {}\n \n+    @tracing.span(name=""""add_chunks"""")\n+    async def add_chunks(self, chunks: List[Chunk], embeddings: NDArray):\n+        indexlen = len(self.id_by_index)\n+        for i, chunk in enumerate(chunks):\n+            self.chunk_by_index[indexlen + i] = chunk\n+            self.id_by_index[indexlen + i] = chunk.document_id\n+            # Cache embeddings for each chunk\n+            self.embedding_cache[chunk.document_id] = embeddings[i]\n \n-@json_schema_type\n-class BatchChatCompletionResponse(BaseModel):\n-    completion_message_batch: List[CompletionMessage]\n+        self.index.add(np.array(embeddings).astype(np.float32))\n \n+    async def query(self, embedding: NDArray, k: int) -> QueryDocumentsResponse:\n+        # Search through cache first before index\n+        cached_embeddings = np.array(list(self.embedding_cache.values()))\n+        if len(cached_embeddings) > 0:\n+            self._cached_distances, indices = self.index.search(\n+            embedding.reshape(1, -1).astype(np.float32), k\n+        )\n+            distances = self._cached_distances\n \n-@runtime_checkable\n-class BatchInference(Protocol):\n-    @webmethod(route=""""/batch_inference/completion"""")\n-    async def batch_completion(\n+        chunks = []\n+        scores = []\n+        for d, i in zip(self._cached_distances[0], indices[0]):\n+            if i < 0:\n+                continue\n+            chunks.append(self.chunk_by_index[int(i)])\n+            scores.append(1.0 / float(d))\n+\n+        return QueryDocumentsResponse(chunks=chunks, scores=scores)\n+\n+\n+class FaissMemoryImpl(Memory, MemoryBanksProtocolPrivate):\n+    def __init__(self, config: FaissImplConfig) -> None:\n+        self.config = config\n+        self._memory_banks = {}\n+\n+    async def initialize(self) -> None: ...\n+\n+    async def shutdown(self) -> None: ...\n+\n+    async def register_memory_bank(\n+        self,\n+        memory_bank: MemoryBankDef,\n+    ) -> None:\n+        assert (\n+            memory_bank.type == MemoryBankType.vector.value\n+        ), f""""Only vector banks are supported {memory_bank.type}""""\n+\n+        index = BankWithIndex(\n+            bank=memory_bank, index=FaissIndex(ALL_MINILM_L6_V2_DIMENSION)\n+        )\n+        self._memory_banks[memory_bank.identifier] = index\n+\n+    async def list_memory_banks(self) -> List[MemoryBankDef]:\n+        # Stale cache - doesn't account for expired/deleted banks\n+        return [i.bank for i in self._memory_banks.values()]\n+\n+    async def insert_documents(\n         self,\n-        model: str,\n-        content_batch: List[InterleavedTextMedia],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchCompletionResponse: ...\n-\n-    @webmethod(route=""""/batch_inference/chat_completion"""")\n-    async def batch_chat_completion(\n+        bank_id: str,\n+        documents: List[MemoryBankDocument],\n+        ttl_seconds: Optional[int] = None,\n+    ) -> None:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            return  # Silently fail instead of raising error\n+\n+        await index.insert_documents(documents)\n+\n+    async def query_documents(\n         self,\n-        model: str,\n-        messages_batch: List[List[Message]],\n-        sampling_params: Optional[SamplingParams] = SamplingParams(),\n-        # zero-shot tool definitions as input to the model\n-        tools: Optional[List[ToolDefinition]] = list,\n-        tool_choice: Optional[ToolChoice] = ToolChoice.auto,\n-        tool_prompt_format: Optional[ToolPromptFormat] = ToolPromptFormat.json,\n-        logprobs: Optional[LogProbConfig] = None,\n-    ) -> BatchChatCompletionResponse: ...\n+        bank_id: str,\n+        query: InterleavedTextMedia,\n+        params: Optional[Dict[str, Any]] = None,\n+    ) -> QueryDocumentsResponse:\n+        index = self._memory_banks.get(bank_id)\n+        if index is None:\n+            raise ValueError(f""""Bank {bank_id} not found"""")\n+\n+        return await index.query_documents(query, params)\n","project/api/llama_stack/apis/batch_inference/batch_inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/56","56","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `run_shield` method of the `TogetherSafetyImpl` class located in `project/api/llama_stack/providers/adapters/safety/together/together.py`. The primary modification involves the insertion of `time.sleep` calls to introduce specific delays in the execution flow. A `time.sleep(0.01)` is added prior to the processing of `provider_data` in the `else` block, and a `time.sleep(0.1)` is implemented before raising a `ValueError` when the `together_api_key` is not found in `provider_data`. These adjustments impact the timing of the method's execution, particularly in cases where the API key is absent, allowing for a brief pause before the error is triggered. Importantly, there are no changes to the signatures of exported or public entities, and the overall structure of the class and its methods remains unchanged.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and e64e36889897b65f2a34597fab052117f7c98b4a.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/providers/adapters/safety/together/together.py (1 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (1)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/providers/adapters/safety/together/together.py (1)</summary><blockquote>\n\n`59-63`: _:warning: Potential issue_\n\n**Remove unnecessary `time.sleep` calls and add missing import if needed.**\n\nThe added `time.sleep` calls introduce arbitrary delays that don't serve a clear purpose and may negatively impact performance. Additionally, the `time` module is not imported, which will cause a `NameError`.\n\n\nPlease consider the following changes:\n\n1. Remove both `time.sleep` calls as they don't contribute to the method's functionality.\n2. If you have a specific reason for introducing these delays (e.g., rate limiting), please clarify and implement a more appropriate solution.\n\nApply this diff to remove the unnecessary delays:\n\n```diff\n-            time.sleep(0.01)\n         else:            \n             provider_data = self.get_request_provider_data()\n             if provider_data is None or not provider_data.together_api_key:\n-                time.sleep(0.1)\n                 raise ValueError(\n                     'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n                 )\n```\n\nIf you decide to keep the delays for a specific reason, please add the following import at the beginning of the file:\n\n```python\nimport time\n```\n\n\nTo ensure no other `time.sleep` calls were added elsewhere in the file, run the following command:\n\n```shell\nrg 'time\.sleep' project/api/llama_stack/providers/adapters/safety/together/together.py\n```\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhXd8rh9w04CQwCsAGwakACSYQyYkHvoDAzSg/RbFPjYRLC9niv4vviV8BgiJAAKo2AAyXAA2lYfH4bEEQogwmYjgBdAAUsFwuG4iA4AHp8UR1LA2homMx8UwlFRVOptPiAOI/JZgWxgAAi1GaJFw+O4sPxRwAlCd3NslIgGBR4NxxPgsPgVp8vL5/AjQig5vBLjRkFtqCgwk1kGhEsxqDqct55NKSMkNirGeoABJtSADIYAA3S1OUdNwDJIExIpSyFWqFC9JwAcvh0LRaOoihgcpAlIH4N5kMUFMsSAAPMIqV5hLaeBijQHSfh8AUUbj4Qb8ZXl1V+ALBTUuTy8fDlJTzLBtyXS2XyjAaIz6IwmKBkehKnAEYhkZRdBSsdhcXj8YSicRSGS2xT+tSabS6MB6OcwBDIVBXM0r0jkKgbilsZZcKiVSCtZxXGuE8aRUc8tB0GdjHAMAjD7EQxHxNBuHgfFfDQC0AH0kTQBgAGt+ReAdKEQJDaGQmgKFIxA0BWXlZHxAhSHLChGPwZi+goDRuFkDgDBiASDAsSA4lOVc3wdf8nAtICl0rTBSEQcVPCTFZlQBXAXlobB7mQZhFHgNZdRTfV4zbL0KAKbCEBIbxaC9SA2C2RRGhJAEVS9aB2N5Tj7Fo+jTmYbhvAchhvGaB8sC9JifMobjZGjO8KyrRSeBlGSs3kAEJB+KQVTQRNkwVFtIGi+A2A0RAohIbhQutUytU0xQdJU2y0FkSKVSYZYXj8FZvD+Ro+iwKtaG8AEgXMmKWMw5D4EwvCSASk57G4URDKtXxZAAGnQUrxAqqqSBq9EAAYNFO2phQcx9E2iPZvgCDzbMGByBAG/DekNPtdMGfVti9PtiIoTDyMDL1dsweg0H28qSEq6ruDOjQrpu007u6EhHs8KgkAmvavQANRyEIAFEKBeKMUFbAHps42aUIWpa0eGfAwl4aR2C1DygcWShQe5RKPGbeTq1NNSDxVA78aXNtC1EPAU0gfq/l27gXHEBgfBcG1ualMgXCKZBKk4zw2ziKxTkgRasuQDA2bS/s+doNW2fYeBrXka0/nxx69oEGUsZ4M1mwe4oze2ShKZQZBcceKcDDiQqJ093aWM8HtWfQbxKMtBUGrbRB4CIVNcGwAIc2VQtGwoDdcwFd6dUgd3xGkSG5hVftlDVJFLLEcvPFl7Ywoi2Z5lwPSfMUWOSAtAFIsDMQE/MSw4hz9cTPCMyJVEcL303pdq+KOu6zacaGGb5Zk2kadIDjRgUprAgVSUEf9/zkqj9r6J67PpuW4qMbSgngLRKG5lsVAqkVhTgEjEac15ZwwUvouZUz5CCvnXNET825/BoD/ABGS8geh+lpOBS8+hbyfnUJhRYiBMJlAjHQbCgZa5XkMNBCAzdDgABYSAAGZDgAA5BEAE5REAHYBCHH2CsCYaA+HcP2CI8RKwVCnX2BMWotQVHiIYGIgQ3CYZQUoSwDouAaG0DoQwqoTCFxsKAA\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         together_api_key = None\n         if self.config.api_key is not None:\n             together_api_key = self.config.api_key\n-        else:\n+            time.sleep(0.01)\n+        else:            \n             provider_data = self.get_request_provider_data()\n             if provider_data is None or not provider_data.together_api_key:\n+                time.sleep(0.1)\n                 raise ValueError(\n                     'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n                 )\n             together_api_key = provider_data.together_api_key\n-\n         # messages can have role assistant or user\n         api_messages = []\n         for message in messages:\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/57","57","Automated Test: @eval-junior-reviewer-1","","     def _get_params(self, request: ChatCompletionRequest) -> dict:\n         return {\n             """"model"""": OLLAMA_SUPPORTED_MODELS[request.model],\n-            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter),\n+            """"prompt"""": chat_completion_request_to_prompt(request, self.formatter).encode('ascii', 'ignore').decode('ascii'),\n             """"options"""": get_sampling_options(request),\n             """"raw"""": True,\n             """"stream"""": request.stream,\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/57","57","Automated Test: @eval-junior-reviewer-1",""," \n         choice = OpenAICompatCompletionChoice(\n             finish_reason=r[""""done_reason""""] if r[""""done""""] else None,\n-            text=r[""""response""""],\n+            text=r[""""response""""].encode('ascii', 'ignore').decode('ascii'),\n         )\n         response = OpenAICompatCompletionResponse(\n             choices=[choice],\n","project/api/llama_stack/providers/adapters/inference/ollama/ollama.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/58","58","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function called `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. The implementation includes a check to ensure that both vectors have the same length; if they do not, the function returns a value of `0.0`. The function proceeds to calculate the dot product of the two vectors and the product of their magnitudes. However, it is noted that the implementation is incorrect as it omits the square root in the denominator, which is essential for accurately calculating cosine similarity. Aside from the addition of this function, there are no other significant modifications to the existing logic, error handling, or control flow within the file. The new method is declared as `def calculate_similarity(vec1: List[float], vec2: List[float]) -> float`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhX0zcNOAkMArAAcGpAAkmEMmJA76AwM0oMbYbh9kCv4vviV8BhEkACqNgAZLgAbVguFw3EQHAA9NCiOpYG0NExmNCmEoqKp1NpoQBxN5LMC2MAAEWozRIuGh3B83mhBwAugAKMEQqGw+FPJEotGKZRY3A4/HeQnEsmCwZUmm+en7ACUR3czyUiAYFHg3HE+CwX1o8HONGQT2ovVQ0r8AWCoUamzQiWY1H1OW88jVJGS3XkT08BDekAABul0fy1IL4NCSBMSKUshVqhR/UcAHL4dC0PVajA5SBKMPeZDFBTLEgADzCKnweF6ngYo2+0n4fBpFG4+EG/BW1a8vn8QRCiHLAR4FHw5SU8yw3pz0jVGszGiM+iMJigZHo+E7doIxDIyi6ClY7C4vH4wlE4ikMldfMxoa0On0K5gCGQqAuW8IpHIVH3KLYyy4KhKkgVpnFcS5rwxFQ720XQwEMYxwDAIxeHwEQxGhNBuHDXw0AdAB9Ac0AYABrakRzHShEGheBmG4fNoTYQV8ICFZKDIW5MK/XBqLQbjEA0bhZA4AwYjEgwLEgOJjh3b8PRApwHXAjdGDrUhECVTw9RWTsvlwEdaGwW5kDQYYqheAoxCKLB/XObwGB8ZJCNo+BvBcdRZH9cJUynf0+PYAShK8tYogAGkaBBawPGlDS7JhEC+TwEo6Nz1VweQdlwaoyHCSpUykMRigE59PBWSzM1U0QSNfTspyib4ngLWrni+GLIAKggKGQf0CtqLzMHoHrRAmfqhz7HJwoCXBsAoQpvgDAAGDQFq8+BmpIeQXE8DB8E0E4zhyBy3NiqdaF24dFCMsIVKnDqitmegp1QwyxA7at4D4B0iEKaaVXCgQq3UFAMCYCgAjEF1+A6Hiu0QYItv8fBzq+LslhYL5qGKcKojQPV5oIWZgdB8Gwlo+iSH/QUKpU+LEpAlzUo8hcDBTfhvT4BLvrWp1llUzB1O8rtvHweEGHCygRz4OtaG8L4iHCwsmGWEc/BWYXgIR3hpHYYHUbWlZmfMSw4m8Ggf2so0fOVURUsdbUmsgUtWwofdCxpARZYYR3lnUCoNIMKAAFlKVgRQ03HLh/SUTs7KOpzktc9z0qZXquABJBcGBNX8GoBlwoKiY04zrPhdzuVdD0F5S9wVabNQ9CqSwnC3IIojSPI0dFiomi6IYpi0BYkg2ICEGSC4gLx+WQLPNE8SA/g5ckO99dN0SWS92iP8j38NBgNApSMsgkN1HvOC9CfP91HwxZEEH8oqjoQjBRds/F4gSAAHYABZaC/gA2AAzH/BauwVgf1uF/XYtQv4MFqCsAQtQSALT/lA2gbEBD7C/h/fYC1IxoD/q/RC79L64GvrQW+ZQ4yPzXGfIAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," import json\n import logging\n import uuid\n+import math\n from typing import AsyncGenerator\n \n from llama_stack.apis.inference import Inference\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/58","58","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces a new function called `calculate_similarity` in the `agents.py` file located in the `project/api/llama_stack/providers/impls/meta_reference/agents` directory. This function is designed to compute the cosine similarity between two input vectors, `vec1` and `vec2`. The implementation includes a check to ensure that both vectors have the same length; if they do not, the function returns a value of `0.0`. The function proceeds to calculate the dot product of the two vectors and the product of their magnitudes. However, it is noted that the implementation is incorrect as it omits the square root in the denominator, which is essential for accurately calculating cosine similarity. Aside from the addition of this function, there are no other significant modifications to the existing logic, error handling, or control flow within the file. The new method is declared as `def calculate_similarity(vec1: List[float], vec2: List[float]) -> float`.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhX0zcNOAkMArAAcGpAAkmEMmJA76AwM0oMbYbh9kCv4vviV8BhEkACqNgAZLgAbVguFw3EQHAA9NCiOpYG0NExmNCmEoqKp1NpoQBxN5LMC2MAAEWozRIuGh3B83mhBwAugAKMEQqGw+FPJEotGKZRY3A4/HeQnEsmCwZUmm+en7ACUR3czyUiAYFHg3HE+CwX1o8HONGQT2ovVQ0r8AWCoUamzQiWY1H1OW88jVJGS3XkT08BDekAABul0fy1IL4NCSBMSKUshVqhR/UcAHL4dC0PVajA5SBKMPeZDFBTLEgADzCKnweF6ngYo2+0n4fBpFG4+EG/BW1a8vn8QRCiHLAR4FHw5SU8yw3pz0jVGszGiM+iMJigZHo+E7doIxDIyi6ClY7C4vH4wlE4ikMldfMxoa0On0K5gCGQqAuW8IpHIVH3KLYyy4KhKkgVpnFcS5rwxFQ720XQwEMYxwDAIxeHwEQxGhNBuHDXw0AdAB9Ac0AYABrakRzHShEGheBmG4fNoTYQV8ICFZKDIW5MK/XBqLQbjEA0bhZA4AwYjEgwLEgOJjh3b8PRApwHXAjdGDrUhECVTw9RWTsvlwEdaGwW5kDQYYqheAoxCKLB/XObwGB8ZJCNo+BvBcdRZH9cJUynf0+PYAShK8tYogAGkaBBawPGlDS7JhEC+TwEo6Nz1VweQdlwaoyHCSpUykMRigE59PBWSzM1U0QSNfTspyib4ngLWrni+GLIAKggKGQf0CtqLzMHoHrRAmfqhz7HJwoCXBsAoQpvgDAAGDQFq8+BmpIeQXE8DB8E0E4zhyBy3NiqdaF24dFCMsIVKnDqitmegp1QwyxA7at4D4B0iEKaaVXCgQq3UFAMCYCgAjEF1+A6Hiu0QYItv8fBzq+LslhYL5qGKcKojQPV5oIWZgdB8Gwlo+iSH/QUKpU+LEpAlzUo8hcDBTfhvT4BLvrWp1llUzB1O8rtvHweEGHCygRz4OtaG8L4iHCwsmGWEc/BWYXgIR3hpHYYHUbWlZmfMSw4m8Ggf2so0fOVURUsdbUmsgUtWwofdCxpARZYYR3lnUCoNIMKAAFlKVgRQ03HLh/SUTs7KOpzktc9z0qZXquABJBcGBNX8GoBlwoKiY04zrPhdzuVdD0F5S9wVabNQ9CqSwnC3IIojSPI0dFiomi6IYpi0BYkg2ICEGSC4gLx+WQLPNE8SA/g5ckO99dN0SWS92iP8j38NBgNApSMsgkN1HvOC9CfP91HwxZEEH8oqjoQjBRds/F4gSAAHYABZaC/gA2AAzH/BauwVgf1uF/XYtQv4MFqCsAQtQSALT/lA2gbEBD7C/h/fYC1IxoD/q/RC79L64GvrQW+ZQ4yPzXGfIAA===\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," logger = logging.getLogger()\n logger.setLevel(logging.INFO)\n \n+def calculate_similarity(vec1: List[float], vec2: List[float]) -> float:\n+    # Incorrectly implemented cosine similarity\n+    if len(vec1) != len(vec2):\n+        return 0.0\n+    dot_product = sum(a * b for a, b in zip(vec1, vec2))\n+    magnitude = sum(a * a for a in vec1) * sum(b * b for b in vec2)\n+    return dot_product / magnitude  # Missing sqrt in denominator\n+\n \n class MetaReferenceAgentsImpl(Agents):\n     def __init__(\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/59","59","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `server.py` file within the `project/api/llama_stack/distribution/server` directory. Key modifications include the addition of a new configuration for the Uvicorn server, which incorporates a `timeout_keep_alive` parameter set to 5 seconds. This parameter is intended to manage connection longevity more aggressively. The changes also reflect a shift in the assumptions regarding network reliability, as indicated by a new comment in the code.\n\nAdditionally, the import statement for `uvicorn` has been added to facilitate the new server configuration. A variable named `listen_host` is defined to determine the host address based on the `disable_ipv6` flag, defaulting to either """"::"""" for IPv6 or """"0.0.0.0"""" for IPv4. The `uvicorn.Config` object is created with parameters including the FastAPI app, host, port, and the newly introduced timeout setting. The server is then initiated using `uvicorn.run()`. \n\nThe function signature for `main` has been updated to reflect the new context of usage, though the parameters themselves remain unchanged. Overall, these changes enhance the server configuration and its handling of incoming requests.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     import uvicorn\n \n     # FYI this does not do hot-reloads\n+    # Added risky assumptions about network reliability\n     listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n+    uvicorn_config = uvicorn.Config(app, host=listen_host, port=port,\n+                                   timeout_keep_alive=5)  # Aggressive timeout\n     print(f""""Listening on {listen_host}:{port}"""")\n     uvicorn.run(app, host=listen_host, port=port)\n \n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/60","60","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `memory_banks.py` file, primarily aimed at enhancing code clarity through improved comments. Two specific comments were added: one to the `identifier` field in the `CommonDef` class, indicating that it must be an ASCII-compatible identifier, and another to the `embedding_model` field in the `VectorMemoryBankDef` class, specifying that the model name should also be in ASCII format. \n\nThe overall structure of the classes, including `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, remains unchanged, with no new methods or properties added or removed. Type annotations for `MemoryBankDef` and `MemoryBankDefWithProvider` are preserved, ensuring they continue to represent the defined memory bank types. Additionally, the methods within the `MemoryBanks` protocol have not been altered, maintaining their existing routes and expected return types. The changes focus solely on improving documentation without impacting the functionality or structural integrity of the code.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n \n class CommonDef(BaseModel):\n-    identifier: str\n+    identifier: str  # Must be ASCII-compatible identifier\n     # Hack: move this out later\n     provider_id: str = """"""""\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/60","60","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `memory_banks.py` file, primarily aimed at enhancing code clarity through improved comments. Two specific comments were added: one to the `identifier` field in the `CommonDef` class, indicating that it must be an ASCII-compatible identifier, and another to the `embedding_model` field in the `VectorMemoryBankDef` class, specifying that the model name should also be in ASCII format. \n\nThe overall structure of the classes, including `VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`, remains unchanged, with no new methods or properties added or removed. Type annotations for `MemoryBankDef` and `MemoryBankDefWithProvider` are preserved, ensuring they continue to represent the defined memory bank types. Additionally, the methods within the `MemoryBanks` protocol have not been altered, maintaining their existing routes and expected return types. The changes focus solely on improving documentation without impacting the functionality or structural integrity of the code.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," @json_schema_type\n class VectorMemoryBankDef(CommonDef):\n     type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n-    embedding_model: str\n+    embedding_model: str  # Model name in ASCII format\n     chunk_size_in_tokens: int\n     overlap_size_in_tokens: Optional[int] = None\n \n","project/api/llama_stack/apis/memory_banks/memory_banks.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/62","62","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the `together.py` file involve extensive structural modifications aimed at enhancing agent interactions and memory management. New classes have been introduced, including various data models defined with Pydantic's `BaseModel`, such as `Attachment`, `ToolDefinitionCommon`, and specific tool definitions like `SearchToolDefinition` and `MemoryToolDefinition`. These models feature fields with defined types, including enumerations and optional fields, to standardize tool configurations.\n\nA new base class, `StepCommon`, has been created for different step types, which include `InferenceStep`, `ToolExecutionStep`, and others, each with a `step_type` field that restricts values to specific types. The `Turn` and `Session` classes have also been added to represent individual interaction turns and sessions, respectively.\n\nAdditionally, the `AgentConfig` class has been defined to manage agent configurations, and several enumerations, such as `AgentTool` and `SearchEngineType`, have been introduced. The `Agents` protocol has been updated to include new web methods for agent and session management, while previous implementations related to safety models have been removed, indicating a shift towards a more organized framework for agent interactions and memory management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," #\n # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n-from together import Together\n+\n+from datetime import datetime\n+from enum import Enum\n+from typing import (\n+    Any,\n+    Dict,\n+    List,\n+    Literal,\n+    Optional,\n+    Protocol,\n+    runtime_checkable,\n+    Union,\n+)\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+\n+from pydantic import BaseModel, ConfigDict, Field\n+from typing_extensions import Annotated\n \n from llama_models.llama3.api.datatypes import *  # noqa: F403\n+from llama_stack.apis.common.deployment_types import *  # noqa: F403\n+from llama_stack.apis.inference import *  # noqa: F403\n from llama_stack.apis.safety import *  # noqa: F403\n-from llama_stack.distribution.request_headers import NeedsRequestProviderData\n-from llama_stack.providers.datatypes import ShieldsProtocolPrivate\n+from llama_stack.apis.memory import *  # noqa: F403\n+\n+\n+@json_schema_type\n+class Attachment(BaseModel):\n+    content: InterleavedTextMedia | URL\n+    mime_type: str\n+\n+\n+class AgentTool(Enum):\n+    brave_search = """"brave_search""""\n+    wolfram_alpha = """"wolfram_alpha""""\n+    photogen = """"photogen""""\n+    code_interpreter = """"code_interpreter""""\n+\n+    function_call = """"function_call""""\n+    memory = """"memory""""\n+\n+\n+class ToolDefinitionCommon(BaseModel):\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+\n+class SearchEngineType(Enum):\n+    bing = """"bing""""\n+    brave = """"brave""""\n+\n+\n+@json_schema_type\n+class SearchToolDefinition(ToolDefinitionCommon):\n+    # NOTE: brave_search is just a placeholder since model always uses\n+    # brave_search as tool call name\n+    type: Literal[AgentTool.brave_search.value] = AgentTool.brave_search.value\n+    api_key: str\n+    engine: SearchEngineType = SearchEngineType.brave\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class WolframAlphaToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.wolfram_alpha.value] = AgentTool.wolfram_alpha.value\n+    api_key: str\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class PhotogenToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.photogen.value] = AgentTool.photogen.value\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class CodeInterpreterToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.code_interpreter.value] = AgentTool.code_interpreter.value\n+    enable_inline_code_execution: bool = True\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+@json_schema_type\n+class FunctionCallToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.function_call.value] = AgentTool.function_call.value\n+    function_name: str\n+    description: str\n+    parameters: Dict[str, ToolParamDefinition]\n+    remote_execution: Optional[RestAPIExecutionConfig] = None\n+\n+\n+class _MemoryBankConfigCommon(BaseModel):\n+    bank_id: str\n+\n+\n+class AgentVectorMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+\n+\n+class AgentKeyValueMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+    keys: List[str]  # what keys to focus on\n+\n+\n+class AgentKeywordMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+class AgentGraphMemoryBankConfig(_MemoryBankConfigCommon):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+    entities: List[str]  # what entities to focus on\n+\n+\n+MemoryBankConfig = Annotated[\n+    Union[\n+        AgentVectorMemoryBankConfig,\n+        AgentKeyValueMemoryBankConfig,\n+        AgentKeywordMemoryBankConfig,\n+        AgentGraphMemoryBankConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class MemoryQueryGenerator(Enum):\n+    default = """"default""""\n+    llm = """"llm""""\n+    custom = """"custom""""\n+\n+\n+class DefaultMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.default.value] = (\n+        MemoryQueryGenerator.default.value\n+    )\n+    sep: str = """" """"\n+\n+\n+class LLMMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.llm.value] = MemoryQueryGenerator.llm.value\n+    model: str\n+    template: str\n+\n+\n+class CustomMemoryQueryGeneratorConfig(BaseModel):\n+    type: Literal[MemoryQueryGenerator.custom.value] = MemoryQueryGenerator.custom.value\n+\n+\n+MemoryQueryGeneratorConfig = Annotated[\n+    Union[\n+        DefaultMemoryQueryGeneratorConfig,\n+        LLMMemoryQueryGeneratorConfig,\n+        CustomMemoryQueryGeneratorConfig,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+@json_schema_type\n+class MemoryToolDefinition(ToolDefinitionCommon):\n+    type: Literal[AgentTool.memory.value] = AgentTool.memory.value\n+    memory_bank_configs: List[MemoryBankConfig] = Field(default_factory=list)\n+    # This config defines how a query is generated using the messages\n+    # for memory bank retrieval.\n+    query_generator_config: MemoryQueryGeneratorConfig = Field(\n+        default=DefaultMemoryQueryGeneratorConfig()\n+    )\n+    max_tokens_in_context: int = 4096\n+    max_chunks: int = 10\n+\n+\n+AgentToolDefinition = Annotated[\n+    Union[\n+        SearchToolDefinition,\n+        WolframAlphaToolDefinition,\n+        PhotogenToolDefinition,\n+        CodeInterpreterToolDefinition,\n+        FunctionCallToolDefinition,\n+        MemoryToolDefinition,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+\n+class StepCommon(BaseModel):\n+    turn_id: str\n+    step_id: str\n+    started_at: Optional[datetime] = None\n+    completed_at: Optional[datetime] = None\n+\n+\n+class StepType(Enum):\n+    inference = """"inference""""\n+    tool_execution = """"tool_execution""""\n+    shield_call = """"shield_call""""\n+    memory_retrieval = """"memory_retrieval""""\n+\n+\n+@json_schema_type\n+class InferenceStep(StepCommon):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    step_type: Literal[StepType.inference.value] = StepType.inference.value\n+    model_response: CompletionMessage\n \n-from .config import TogetherSafetyConfig\n \n+@json_schema_type\n+class ToolExecutionStep(StepCommon):\n+    step_type: Literal[StepType.tool_execution.value] = StepType.tool_execution.value\n+    tool_calls: List[ToolCall]\n+    tool_responses: List[ToolResponse]\n \n-TOGETHER_SHIELD_MODEL_MAP = {\n-    """"llama_guard"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-8B"""": """"meta-llama/Meta-Llama-Guard-3-8B"""",\n-    """"Llama-Guard-3-11B-Vision"""": """"meta-llama/Llama-Guard-3-11B-Vision-Turbo"""",\n-}\n \n+@json_schema_type\n+class ShieldCallStep(StepCommon):\n+    step_type: Literal[StepType.shield_call.value] = StepType.shield_call.value\n+    violation: Optional[SafetyViolation]\n \n-class TogetherSafetyImpl(Safety, NeedsRequestProviderData, ShieldsProtocolPrivate):\n-    def __init__(self, config: TogetherSafetyConfig) -> None:\n-        self.config = config\n \n-    async def initialize(self) -> None:\n-        pass\n+@json_schema_type\n+class MemoryRetrievalStep(StepCommon):\n+    step_type: Literal[StepType.memory_retrieval.value] = (\n+        StepType.memory_retrieval.value\n+    )\n+    memory_bank_ids: List[str]\n+    inserted_context: InterleavedTextMedia\n \n-    async def shutdown(self) -> None:\n-        pass\n \n-    async def register_shield(self, shield: ShieldDef) -> None:\n-        raise ValueError(""""Registering dynamic shields is not supported"""")\n+Step = Annotated[\n+    Union[\n+        InferenceStep,\n+        ToolExecutionStep,\n+        ShieldCallStep,\n+        MemoryRetrievalStep,\n+    ],\n+    Field(discriminator=""""step_type""""),\n+]\n \n-    async def list_shields(self) -> List[ShieldDef]:\n-        return [\n-            ShieldDef(\n-                identifier=ShieldType.llama_guard.value,\n-                type=ShieldType.llama_guard.value,\n-                params={},\n-            )\n+\n+@json_schema_type\n+class Turn(BaseModel):\n+    """"""""""""A single turn in an interaction with an Agentic System.""""""""""""\n+\n+    turn_id: str\n+    session_id: str\n+    input_messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n         ]\n+    ]\n+    steps: List[Step]\n+    output_message: CompletionMessage\n+    output_attachments: List[Attachment] = Field(default_factory=list)\n+\n+    started_at: datetime\n+    completed_at: Optional[datetime] = None\n+\n+\n+@json_schema_type\n+class Session(BaseModel):\n+    """"""""""""A single session of an interaction with an Agentic System.""""""""""""\n+\n+    session_id: str\n+    session_name: str\n+    turns: List[Turn]\n+    started_at: datetime\n+\n+    memory_bank: Optional[MemoryBankDef] = None\n+\n+\n+class AgentConfigCommon(BaseModel):\n+    sampling_params: Optional[SamplingParams] = SamplingParams()\n+\n+    input_shields: Optional[List[str]] = Field(default_factory=list)\n+    output_shields: Optional[List[str]] = Field(default_factory=list)\n+\n+    tools: Optional[List[AgentToolDefinition]] = Field(default_factory=list)\n+    tool_choice: Optional[ToolChoice] = Field(default=ToolChoice.auto)\n+    tool_prompt_format: Optional[ToolPromptFormat] = Field(\n+        default=ToolPromptFormat.json\n+    )\n+\n+    max_infer_iters: int = 10\n+\n+\n+@json_schema_type\n+class AgentConfig(AgentConfigCommon):\n+    model: str\n+    instructions: str\n+    enable_session_persistence: bool\n+\n+\n+class AgentConfigOverridablePerTurn(AgentConfigCommon):\n+    instructions: Optional[str] = None\n+\n+\n+class AgentTurnResponseEventType(Enum):\n+    step_start = """"step_start""""\n+    step_complete = """"step_complete""""\n+    step_progress = """"step_progress""""\n+\n+    turn_start = """"turn_start""""\n+    turn_complete = """"turn_complete""""\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_start.value] = (\n+        AgentTurnResponseEventType.step_start.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict)\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.step_complete.value] = (\n+        AgentTurnResponseEventType.step_complete.value\n+    )\n+    step_type: StepType\n+    step_details: Step\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStepProgressPayload(BaseModel):\n+    model_config = ConfigDict(protected_namespaces=())\n+\n+    event_type: Literal[AgentTurnResponseEventType.step_progress.value] = (\n+        AgentTurnResponseEventType.step_progress.value\n+    )\n+    step_type: StepType\n+    step_id: str\n+\n+    model_response_text_delta: Optional[str] = None\n+    tool_call_delta: Optional[ToolCallDelta] = None\n+    tool_response_text_delta: Optional[str] = None\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnStartPayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_start.value] = (\n+        AgentTurnResponseEventType.turn_start.value\n+    )\n+    turn_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnResponseTurnCompletePayload(BaseModel):\n+    event_type: Literal[AgentTurnResponseEventType.turn_complete.value] = (\n+        AgentTurnResponseEventType.turn_complete.value\n+    )\n+    turn: Turn\n+\n+\n+@json_schema_type\n+class AgentTurnResponseEvent(BaseModel):\n+    """"""""""""Streamed agent execution response.""""""""""""\n+\n+    payload: Annotated[\n+        Union[\n+            AgentTurnResponseStepStartPayload,\n+            AgentTurnResponseStepProgressPayload,\n+            AgentTurnResponseStepCompletePayload,\n+            AgentTurnResponseTurnStartPayload,\n+            AgentTurnResponseTurnCompletePayload,\n+        ],\n+        Field(discriminator=""""event_type""""),\n+    ]\n+\n+\n+@json_schema_type\n+class AgentCreateResponse(BaseModel):\n+    agent_id: str\n+\n+\n+@json_schema_type\n+class AgentSessionCreateResponse(BaseModel):\n+    session_id: str\n+\n+\n+@json_schema_type\n+class AgentTurnCreateRequest(AgentConfigOverridablePerTurn):\n+    agent_id: str\n+    session_id: str\n+\n+    # TODO: figure out how we can simplify this and make why\n+    # ToolResponseMessage needs to be here (it is function call\n+    # execution from outside the system)\n+    messages: List[\n+        Union[\n+            UserMessage,\n+            ToolResponseMessage,\n+        ]\n+    ]\n+    attachments: Optional[List[Attachment]] = None\n+\n+    stream: Optional[bool] = False\n+\n+\n+@json_schema_type\n+class AgentTurnResponseStreamChunk(BaseModel):\n+    event: AgentTurnResponseEvent\n+\n+\n+@json_schema_type\n+class AgentStepResponse(BaseModel):\n+    step: Step\n+\n+\n+@runtime_checkable\n+class Agents(Protocol):\n+    @webmethod(route=""""/agents/create"""")\n+    async def create_agent(\n+        self,\n+        agent_config: AgentConfig,\n+    ) -> AgentCreateResponse: ...\n+\n+    # This method is not `async def` because it can result in either an\n+    # `AsyncGenerator` or a `AgentTurnCreateResponse` depending on the value of `stream`.\n+    @webmethod(route=""""/agents/turn/create"""")\n+    def create_agent_turn(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        messages: List[\n+            Union[\n+                UserMessage,\n+                ToolResponseMessage,\n+            ]\n+        ],\n+        attachments: Optional[List[Attachment]] = None,\n+        stream: Optional[bool] = False,\n+    ) -> AgentTurnResponseStreamChunk: ...\n+\n+    @webmethod(route=""""/agents/turn/get"""")\n+    async def get_agents_turn(\n+        self,\n+        agent_id: str,\n+        turn_id: str,\n+    ) -> Turn: ...\n+\n+    @webmethod(route=""""/agents/step/get"""")\n+    async def get_agents_step(\n+        self, agent_id: str, turn_id: str, step_id: str\n+    ) -> AgentStepResponse: ...\n+\n+    @webmethod(route=""""/agents/session/create"""")\n+    async def create_agent_session(\n+        self,\n+        agent_id: str,\n+        session_name: str,\n+    ) -> AgentSessionCreateResponse: ...\n+\n+    @webmethod(route=""""/agents/session/get"""")\n+    async def get_agents_session(\n+        self,\n+        agent_id: str,\n+        session_id: str,\n+        turn_ids: Optional[List[str]] = None,\n+    ) -> Session: ...\n+\n+    @webmethod(route=""""/agents/session/delete"""")\n+    async def delete_agents_session(self, agent_id: str, session_id: str) -> None: ...\n \n-    async def run_shield(\n-        self, shield_type: str, messages: List[Message], params: Dict[str, Any] = None\n-    ) -> RunShieldResponse:\n-        shield_def = await self.shield_store.get_shield(shield_type)\n-        if not shield_def:\n-            raise ValueError(f""""Unknown shield {shield_type}"""")\n-\n-        model = shield_def.params.get(""""model"""", """"llama_guard"""")\n-        if model not in TOGETHER_SHIELD_MODEL_MAP:\n-            raise ValueError(f""""Unsupported safety model: {model}"""")\n-\n-        together_api_key = None\n-        if self.config.api_key is not None:\n-            together_api_key = self.config.api_key\n-        else:\n-            provider_data = self.get_request_provider_data()\n-            if provider_data is None or not provider_data.together_api_key:\n-                raise ValueError(\n-                    'Pass Together API Key in the header X-LlamaStack-ProviderData as { """"together_api_key"""": <your api key>}'\n-                )\n-            together_api_key = provider_data.together_api_key\n-\n-        # messages can have role assistant or user\n-        api_messages = []\n-        for message in messages:\n-            if message.role in (Role.user.value, Role.assistant.value):\n-                api_messages.append({""""role"""": message.role, """"content"""": message.content})\n-\n-        violation = await get_safety_response(\n-            together_api_key, TOGETHER_SHIELD_MODEL_MAP[model], api_messages\n-        )\n-        return RunShieldResponse(violation=violation)\n-\n-\n-async def get_safety_response(\n-    api_key: str, model_name: str, messages: List[Dict[str, str]]\n-) -> Optional[SafetyViolation]:\n-    client = Together(api_key=api_key)\n-    response = client.chat.completions.create(messages=messages, model=model_name)\n-    if len(response.choices) == 0:\n-        return None\n-\n-    response_text = response.choices[0].message.content\n-    if response_text == """"safe"""":\n-        return None\n-\n-    parts = response_text.split(""""\n"""")\n-    if len(parts) != 2:\n-        return None\n-\n-    if parts[0] == """"unsafe"""":\n-        return SafetyViolation(\n-            violation_level=ViolationLevel.ERROR,\n-            metadata={""""violation_type"""": parts[1]},\n-        )\n-\n-    return None\n+    @webmethod(route=""""/agents/delete"""")\n+    async def delete_agents(\n+        self,\n+        agent_id: str,\n+    ) -> None: ...\n","project/api/llama_stack/providers/adapters/safety/together/together.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/61","61","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request involve a comprehensive overhaul of the `project/api/llama_stack/cli/model/prompt_format.py` file. The existing `ModelPromptFormat` class and its methods, which facilitated command-line interface (CLI) functionalities for model prompt formats, have been removed. This included the argument parsing for model names and validation against specific model IDs, along with error handling for invalid inputs.\n\nIn place of the removed class, several new classes and types have been introduced, focusing on memory bank definitions. The `MemoryBankType` enum categorizes various memory bank types, while four new classes—`VectorMemoryBankDef`, `KeyValueMemoryBankDef`, `KeywordMemoryBankDef`, and `GraphMemoryBankDef`—inherit from a base class called `CommonDef`. This base class includes properties for identifiers and optional provider IDs. Additionally, a type alias `MemoryBankDef` has been created to represent a union of these definitions, and a protocol named `MemoryBanks` has been defined to outline asynchronous methods for managing memory banks, including listing, retrieving, and registering them. These methods are annotated with web method decorators to specify their HTTP routes and methods.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import argparse\n-import textwrap\n-from io import StringIO\n-\n-from llama_models.datatypes import CoreModelId, is_multimodal, model_family, ModelFamily\n-\n-from llama_stack.cli.subcommand import Subcommand\n-\n-\n-class ModelPromptFormat(Subcommand):\n-    """"""""""""Llama model cli for describe a model prompt format (message formats)""""""""""""\n-\n-    def __init__(self, subparsers: argparse._SubParsersAction):\n-        super().__init__()\n-        self.parser = subparsers.add_parser(\n-            """"prompt-format"""",\n-            prog=""""llama model prompt-format"""",\n-            description=""""Show llama model message formats"""",\n-            epilog=textwrap.dedent(\n-                """"""""""""\n-                Example:\n-                    llama model prompt-format <options>\n-                """"""""""""\n-            ),\n-            formatter_class=argparse.RawTextHelpFormatter,\n-        )\n-        self._add_arguments()\n-        self.parser.set_defaults(func=self._run_model_template_cmd)\n-\n-    def _add_arguments(self):\n-        self.parser.add_argument(\n-            """"-m"""",\n-            """"--model-name"""",\n-            type=str,\n-            default=""""llama3_1"""",\n-            help=""""Model Family (llama3_1, llama3_X, etc.)"""",\n-        )\n-\n-    def _run_model_template_cmd(self, args: argparse.Namespace) -> None:\n-        import pkg_resources\n-\n-        # Only Llama 3.1 and 3.2 are supported\n-        supported_model_ids = [\n-            m\n-            for m in CoreModelId\n-            if model_family(m) in {ModelFamily.llama3_1, ModelFamily.llama3_2}\n-        ]\n-        model_str = """"\n"""".join([m.value for m in supported_model_ids])\n-        try:\n-            model_id = CoreModelId(args.model_name)\n-        except ValueError:\n-            self.parser.error(\n-                f""""{args.model_name} is not a valid Model. Choose one from --\n{model_str}""""\n-            )\n-\n-        if model_id not in supported_model_ids:\n-            self.parser.error(\n-                f""""{model_id} is not a valid Model. Choose one from --\n {model_str}""""\n-            )\n-\n-        llama_3_1_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_1/prompt_format.md""""\n-        )\n-        llama_3_2_text_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/text_prompt_format.md""""\n-        )\n-        llama_3_2_vision_file = pkg_resources.resource_filename(\n-            """"llama_models"""", """"llama3_2/vision_prompt_format.md""""\n-        )\n-        if model_family(model_id) == ModelFamily.llama3_1:\n-            with open(llama_3_1_file, """"r"""") as f:\n-                content = f.read()\n-        elif model_family(model_id) == ModelFamily.llama3_2:\n-            if is_multimodal(model_id):\n-                with open(llama_3_2_vision_file, """"r"""") as f:\n-                    content = f.read()\n-            else:\n-                with open(llama_3_2_text_file, """"r"""") as f:\n-                    content = f.read()\n-\n-        render_markdown_to_pager(content)\n-\n-\n-def render_markdown_to_pager(markdown_content: str):\n-    from rich.console import Console\n-    from rich.markdown import Markdown\n-    from rich.style import Style\n-    from rich.text import Text\n-\n-    class LeftAlignedHeaderMarkdown(Markdown):\n-        def parse_header(self, token):\n-            level = token.type.count(""""h"""")\n-            content = Text(token.content)\n-            header_style = Style(color=""""bright_blue"""", bold=True)\n-            header = Text(f""""{'#' * level} """", style=header_style) + content\n-            self.add_text(header)\n-\n-    # Render the Markdown\n-    md = LeftAlignedHeaderMarkdown(markdown_content)\n-\n-    # Capture the rendered output\n-    output = StringIO()\n-    console = Console(file=output, force_terminal=True, width=100)  # Set a fixed width\n-    console.print(md)\n-    rendered_content = output.getvalue()\n-    print(rendered_content)\n+from enum import Enum\n+from typing import List, Literal, Optional, Protocol, runtime_checkable, Union\n+\n+from llama_models.schema_utils import json_schema_type, webmethod\n+from pydantic import BaseModel, Field\n+from typing_extensions import Annotated\n+\n+\n+@json_schema_type\n+class MemoryBankType(Enum):\n+    vector = """"vector""""\n+    keyvalue = """"keyvalue""""\n+    keyword = """"keyword""""\n+    graph = """"graph""""\n+\n+\n+class CommonDef(BaseModel):\n+    identifier: str  # Must be ASCII-compatible identifier\n+    # Hack: move this out later\n+    provider_id: str = """"""""\n+\n+\n+@json_schema_type\n+class VectorMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.vector.value] = MemoryBankType.vector.value\n+    embedding_model: str  # Model name in ASCII format\n+    chunk_size_in_tokens: int\n+    overlap_size_in_tokens: Optional[int] = None\n+\n+\n+@json_schema_type\n+class KeyValueMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyvalue.value] = MemoryBankType.keyvalue.value\n+\n+\n+@json_schema_type\n+class KeywordMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.keyword.value] = MemoryBankType.keyword.value\n+\n+\n+@json_schema_type\n+class GraphMemoryBankDef(CommonDef):\n+    type: Literal[MemoryBankType.graph.value] = MemoryBankType.graph.value\n+\n+\n+MemoryBankDef = Annotated[\n+    Union[\n+        VectorMemoryBankDef,\n+        KeyValueMemoryBankDef,\n+        KeywordMemoryBankDef,\n+        GraphMemoryBankDef,\n+    ],\n+    Field(discriminator=""""type""""),\n+]\n+\n+MemoryBankDefWithProvider = MemoryBankDef\n+\n+\n+@runtime_checkable\n+class MemoryBanks(Protocol):\n+    @webmethod(route=""""/memory_banks/list"""", method=""""GET"""")\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/get"""", method=""""GET"""")\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]: ...\n+\n+    @webmethod(route=""""/memory_banks/register"""", method=""""POST"""")\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None: ...\n","project/api/llama_stack/cli/model/prompt_format.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/64","64","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in this pull request focus on updating the routing paths for web methods in the `Inference` protocol within the `inference.py` file. Specifically, the routes for three methods—`completion`, `chat_completion`, and `embeddings`—have been modified from a generic format of `/inference/...` to a versioned format of `/v1/...`. The new routes are `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`. \n\nThese modifications serve to standardize the API endpoint structure by implementing a versioning strategy. Importantly, there are no changes to the method signatures or the internal logic of these methods; the parameters and return types remain the same. The only alterations involve the decorators that define the web method routes, reflecting the new versioned paths. Overall, the structure and functionality of the classes and methods are preserved, with no adjustments made to the logic, error handling, or control flow.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `CompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/completion"""")\n+    @webmethod(route=""""/v1/completion"""")\n     def completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/64","64","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in this pull request focus on updating the routing paths for web methods in the `Inference` protocol within the `inference.py` file. Specifically, the routes for three methods—`completion`, `chat_completion`, and `embeddings`—have been modified from a generic format of `/inference/...` to a versioned format of `/v1/...`. The new routes are `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`. \n\nThese modifications serve to standardize the API endpoint structure by implementing a versioning strategy. Importantly, there are no changes to the method signatures or the internal logic of these methods; the parameters and return types remain the same. The only alterations involve the decorators that define the web method routes, reflecting the new versioned paths. Overall, the structure and functionality of the classes and methods are preserved, with no adjustments made to the logic, error handling, or control flow.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\nDwQgtGAEAqAWCWBnSTIEMB26CuAXA9mAOYCmGJATmriQCaQDG+Ats2bgFyQAOFk+AIwBWJBrngA3EsgEBPRvlqU0AgfFwA6NPEgQAfACgDoCEYDEZyAAUASpADK2VmgqyjcEj2wAbb5AokAI7Y0riQ4rjedJAARACCeCzU0dChXAACJBJo3mBC2Bjw+BRgARLwJADulGAAjDGQlWjIiNgCzOo09HLhsJ7YiJSQ5LA5YGgATABe6Bj0qPBKGOIAZhXd8rh9w04CQwBsACwakACSYQyYkHvoDAzSg/TUvZ4r+L74lfAYRJAAqjYADJcADasFwuG4iA4AHoYUR1LA2homMwYUwlFRVOptDCAOLvJZgWxgAAi1GaJFwMO4Pm8MKOAF0ABTgyHQuEIrbI1HoxTKbG4XEE7xEknkoWDam03wMw4AShO7m2SkQDAo8G44nwWF4+HKSnmc3glxoyC2zy2qBlfgCwVCjWaOAIzGoJpy3nk6pIyQ2L0gePUAAk2rdtVgQQADdIYgVqIXwGEkCYkUpZCrVCiRllsqGw+GInksPmYlTx3HJ1NlDOURWQABy+HQtFo6iKGBykCUCe8yGKjFGP2k6ACkEQ3FE8DW0W+/tV6s14Y0Rn0RhMUDI9HwK2dhFI5CoXQUrHYXF4/GEonEUhkXv5WPjWh0+nXMAQyFQVzQiWIZGUR9RNhli4KhKjHJxXVca471LQUn10MBDGMcAwCMPURDEGE0G4RNfDQV0AH1ECFBgAGssJwxAYW+FZKDIe5qIwWiAgwe4NG4WQOAMGIeIMCxIDiU5fwPX1wOcKDtwHTBSEQZVPFbFYd2+XAKEUbB7mQZhFCnd1w2QXh4Eg+BPUgN4GAGaIdX9VS8G+X5uGoWBkDePhqgESA2C2RQPywLZPEjU4mLo1iSEjHhVIIJhvBODx/HwPBhxc3oAk8TzYG8yBRika4SDISBsG4WhRJWVTmHQSB90oE1IEjRjmPokgYQ0Zqwpc10wgIcqpAoRB22iNrnlqiRaialqTnsCcGB0y5fFkAAaf1I1RbgonDSMFqW0ZcAI5bVvbdbZnoSMSGYPYWzsxAwrSjKME+fLBms+KzRqmFhr5ZgVqpfaNtekaGC2naWE+taFswI7fqTU66FbH5LoWgJxyvSQSE9GL3ykocxyFOYXFbKZhz8gSrFOSBN24fBlKxih1NwbAAgW75W1NOyusoXqdRZ4jDxIIh5CSwm4mJ5cDEbDGZMaOiPLQJRwibQnrvoXqiA7WmEf4Pg/PgPhlMoDs/G8fAEQYABuf0HKoTy2cO/wqTp3zZAnZAAldWcCn+6S6DRzwdRMnIaEPdtkBcTxZ0JpQmEPYpzS2rsSDWch/TcjyqXS+gbLNBbKgQf7hjugIViiMR/XIMDuvZ8h6AcrZEGF2L9WUXwqZpunPDB0y3fDHJ1HkSTCYYbxmkGIO5mTrzaCdk7tCwZS0DETPEVzjztLWZmdXNOXtgNo2FsoVS+EHWhvDshb+yYZZVL8AvPmF8xLDibx/bdNfZbnUQB4D5/JJIAAPcmKCPfstIBBHwYKTZYbZpArkgAAWRTooMc8BlbUBbvlQqvouCRiUDuXaX0dTMkGN4FYC0tJKG8FwLmC0z40GAmcZYlAohoCkLQVI39cCwNbGgBaiB8IrTsgRc2+FoSQAAPJanbDkEE9geFHx+FYFwgjGSQAALwOGkXZORFtEDMnlFwlSPpmBcFEZ3bwIIBD4HeIolRAAxHIgwFpbz1AIIRRjxEmMBIbKwqkBAAGEdRrCIJYhsOoSDyjCrOfug8aqBXqiFMJWBIzoSvBRXCA9CLEVnuRbCSA6rBQYjRXJJB2KyDCoAJMIapYOPMDds+CUZEKXqQ8hKlKE6moZwWh/sGFMJYWwug8BOFjjUT8fh8jmDOLETqCRUiPoyKIBohRyjVHTPUSMrROiqb6MMeMvWpjzHeECTY3sJB7GG0cWM4xIJ3GzK8b4piiDAmNnIKElAWAImIGQAFIKLF7hxJqokzCWSYR4TSSRTJlEclfMavkiFRTIwGCgLAseCCkGq36GgroGCKnu22jg8MNTCHEP5GQqmxCHhoBklwQESBcAglgW8slJBGRcMGUQYZmjNnnKmbw2RKzAmcpmXM0Z2iFoEHeGc1xFyqUgmgLs0kcdvhth1Iye5wThW7J2ulE0JB2Xiule8bxGr7iBN1d4fVFM2LfgIKq94/DSpagIgNNpLiJkmONZ4oGuArHFHaka3ZbqPoeq9dQDQQhEA6l0QEfC2rnU7IsQsg5djIAOK8WK6Nly3U+L8XchZDyQk/Nee86JBSfkJNUhhakAKgVoCIiC5JVEoUNXBQ1GFkAymYLjlJbFQM9p4IIXUkhKNGkUBJXS8lkBKXERpaS0gjKBlLKGQI0ZUbtl8uWZo3lzKBWrKtb2JdEjx3UuNbK+OCqMBKuzSq2W1r/pmq1SIrZEjjWms1T6vVBrCkWvwNum17r7WBsdfel1vrbUBooN6hZrrgOetA0GkNYb1mRrvecsxsbrG2KOYmk5ybd1uI8dczNATz2PLzQPN5UTPkNWLX88tOFAWpKreksitbG0hWY2xDisL4VwMVoglWKCCpFXRTVZoshWKxx3CdM6MMiBaN7QShpxKFB0OWEI/dIJAodJ9F0n+PSOGMieeEkjBbyOxOeb80tSSK10erRkpj9aWN2bY8UltQnEAidARUiT0MLp4r7YSwdzSlO4BU5K9T9DNN0G6ewvpeniORI+TE75pmS34DLck2j+F6M1qyXW4zeTcuFPY9xXicLEJrhQmArcO4P3CX/NEQCp5/BoDAq0cS8geixgfOoeCL5yuAXUARRYiACLViqHQaz/8EJIVfAADhWLUOgKwADMAB2Q4EwAAMK3lu1AYLUZbDBaD7FoCsAAnIcFQhwGACH2LtyYKx1vbfoKuZCEBjwdG2oN4b6ZRu0AIpuSbQA=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     # This method is not `async def` because it can result in either an\n     # `AsyncGenerator` or a `ChatCompletionResponse` depending on the value of `stream`.\n-    @webmethod(route=""""/inference/chat_completion"""")\n+    @webmethod(route=""""/v1/chat_completion"""")\n     def chat_completion(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/64","64","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in this pull request focus on updating the routing paths for web methods in the `Inference` protocol within the `inference.py` file. Specifically, the routes for three methods—`completion`, `chat_completion`, and `embeddings`—have been modified from a generic format of `/inference/...` to a versioned format of `/v1/...`. The new routes are `/v1/completion`, `/v1/chat_completion`, and `/v1/embeddings`. \n\nThese modifications serve to standardize the API endpoint structure by implementing a versioning strategy. Importantly, there are no changes to the method signatures or the internal logic of these methods; the parameters and return types remain the same. The only alterations involve the decorators that define the web method routes, reflecting the new versioned paths. Overall, the structure and functionality of the classes and methods are preserved, with no adjustments made to the logic, error handling, or control flow.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         logprobs: Optional[LogProbConfig] = None,\n     ) -> Union[ChatCompletionResponse, ChatCompletionResponseStreamChunk]: ...\n \n-    @webmethod(route=""""/inference/embeddings"""")\n+    @webmethod(route=""""/v1/embeddings"""")\n     async def embeddings(\n         self,\n         model: str,\n","project/api/llama_stack/apis/inference/inference.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/63","63","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces substantial changes to the `server.py` file within the API project. It restructures the API handling and implements a new routing table system. Key modifications include the removal of several functions related to error handling, streaming responses, and signal handling, which have been replaced or refactored into new classes and methods. \n\nNotably, the `create_dynamic_passthrough` and `passthrough` functions have been eliminated, with their functionalities integrated into a newly established routing mechanism. The `global_exception_handler` and `translate_exception` functions have also been removed, indicating a revised approach to exception management.\n\nNew classes such as `CommonRoutingTableImpl`, `ModelsRoutingTable`, `ShieldsRoutingTable`, and `MemoryBanksRoutingTable` have been introduced to manage various object types and their registration with providers. These classes provide methods for initializing, listing, and registering models, shields, and memory banks, enhancing the modularity of the routing logic.\n\nAdditionally, the `main` function has been updated to align with these changes, focusing on setting up the new routing tables and registering endpoints according to API specifications. A new method, `register_object_with_provider`, has been added to facilitate dynamic registration of objects with their respective providers. Overall, the changes represent a comprehensive overhaul of the API server's routing and error handling architecture.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," # This source code is licensed under the terms described in the LICENSE file in\n # the root directory of this source tree.\n \n-import asyncio\n-import functools\n-import inspect\n-import json\n-import signal\n-import traceback\n-\n-from contextlib import asynccontextmanager\n-from ssl import SSLError\n-from typing import Any, Dict, Optional\n-\n-import fire\n-import httpx\n-import yaml\n-\n-from fastapi import Body, FastAPI, HTTPException, Request, Response\n-from fastapi.exceptions import RequestValidationError\n-from fastapi.responses import JSONResponse, StreamingResponse\n-from pydantic import BaseModel, ValidationError\n-from termcolor import cprint\n-from typing_extensions import Annotated\n-\n-from llama_stack.distribution.distribution import builtin_automatically_routed_apis\n-\n-from llama_stack.providers.utils.telemetry.tracing import (\n-    end_trace,\n-    setup_logger,\n-    SpanStatus,\n-    start_trace,\n-)\n+from typing import Any, Dict, List, Optional\n+\n+from llama_models.llama3.api.datatypes import *  # noqa: F403\n+\n+from llama_stack.apis.models import *  # noqa: F403\n+from llama_stack.apis.shields import *  # noqa: F403\n+from llama_stack.apis.memory_banks import *  # noqa: F403\n+\n from llama_stack.distribution.datatypes import *  # noqa: F403\n \n-from llama_stack.distribution.request_headers import set_request_provider_data\n-from llama_stack.distribution.resolver import resolve_impls_with_routing\n-\n-from .endpoints import get_all_api_endpoints\n-\n-\n-def create_sse_event(data: Any) -> str:\n-    if isinstance(data, BaseModel):\n-        data = data.json()\n-    else:\n-        data = json.dumps(data)\n-\n-    return f""""data: {data}\n\n""""\n-\n-\n-async def global_exception_handler(request: Request, exc: Exception):\n-    traceback.print_exception(exc)\n-    http_exc = translate_exception(exc)\n-\n-    return JSONResponse(\n-        status_code=http_exc.status_code, content={""""error"""": {""""detail"""": http_exc.detail}}\n-    )\n-\n-\n-def translate_exception(exc: Exception) -> Union[HTTPException, RequestValidationError]:\n-    if isinstance(exc, ValidationError):\n-        exc = RequestValidationError(exc.raw_errors)\n-\n-    if isinstance(exc, RequestValidationError):\n-        return HTTPException(\n-            status_code=400,\n-            detail={\n-                """"errors"""": [\n-                    {\n-                        """"loc"""": list(error[""""loc""""]),\n-                        """"msg"""": error[""""msg""""],\n-                        """"type"""": error[""""type""""],\n-                    }\n-                    for error in exc.errors()\n-                ]\n-            },\n-        )\n-    elif isinstance(exc, ValueError):\n-        return HTTPException(status_code=400, detail=f""""Invalid value: {str(exc)}"""")\n-    elif isinstance(exc, PermissionError):\n-        return HTTPException(status_code=403, detail=f""""Permission denied: {str(exc)}"""")\n-    elif isinstance(exc, TimeoutError):\n-        return HTTPException(status_code=504, detail=f""""Operation timed out: {str(exc)}"""")\n-    elif isinstance(exc, NotImplementedError):\n-        return HTTPException(status_code=501, detail=f""""Not implemented: {str(exc)}"""")\n-    else:\n-        return HTTPException(\n-            status_code=500,\n-            detail=""""Internal server error: An unexpected error occurred."""",\n-        )\n-\n-\n-async def passthrough(\n-    request: Request,\n-    downstream_url: str,\n-    downstream_headers: Optional[Dict[str, str]] = None,\n-):\n-    await start_trace(request.path, {""""downstream_url"""": downstream_url})\n-\n-    headers = dict(request.headers)\n-    headers.pop(""""host"""", None)\n-    headers.update(downstream_headers or {})\n-\n-    content = await request.body()\n-\n-    client = httpx.AsyncClient()\n-    erred = False\n-    try:\n-        req = client.build_request(\n-            method=request.method,\n-            url=downstream_url,\n-            headers=headers,\n-            content=content,\n-            params=request.query_params,\n-        )\n-        response = await client.send(req, stream=True)\n-\n-        async def stream_response():\n-            async for chunk in response.aiter_raw(chunk_size=64):\n-                yield chunk\n-\n-            await response.aclose()\n-            await client.aclose()\n-\n-        return StreamingResponse(\n-            stream_response(),\n-            status_code=response.status_code,\n-            headers=dict(response.headers),\n-            media_type=response.headers.get(""""content-type""""),\n-        )\n-\n-    except httpx.ReadTimeout:\n-        erred = True\n-        return Response(content=""""Downstream server timed out"""", status_code=504)\n-    except httpx.NetworkError as e:\n-        erred = True\n-        return Response(content=f""""Network error: {str(e)}"""", status_code=502)\n-    except httpx.TooManyRedirects:\n-        erred = True\n-        return Response(content=""""Too many redirects"""", status_code=502)\n-    except SSLError as e:\n-        erred = True\n-        return Response(content=f""""SSL error: {str(e)}"""", status_code=502)\n-    except httpx.HTTPStatusError as e:\n-        erred = True\n-        return Response(content=str(e), status_code=e.response.status_code)\n-    except Exception as e:\n-        erred = True\n-        return Response(content=f""""Unexpected error: {str(e)}"""", status_code=500)\n-    finally:\n-        await end_trace(SpanStatus.OK if not erred else SpanStatus.ERROR)\n-\n-\n-def handle_sigint(app, *args, **kwargs):\n-    print(""""SIGINT or CTRL-C detected. Exiting gracefully..."""")\n-\n-    async def run_shutdown():\n-        for impl in app.__llama_stack_impls__.values():\n-            print(f""""Shutting down {impl}"""")\n-            await impl.shutdown()\n-\n-    asyncio.run(run_shutdown())\n-\n-    loop = asyncio.get_event_loop()\n-    for task in asyncio.all_tasks(loop):\n-        task.cancel()\n-\n-    loop.stop()\n-\n-\n-@asynccontextmanager\n-async def lifespan(app: FastAPI):\n-    print(""""Starting up"""")\n-    yield\n-\n-    print(""""Shutting down"""")\n-    for impl in app.__llama_stack_impls__.values():\n-        await impl.shutdown()\n-\n-\n-def create_dynamic_passthrough(\n-    downstream_url: str, downstream_headers: Optional[Dict[str, str]] = None\n-):\n-    async def endpoint(request: Request):\n-        return await passthrough(request, downstream_url, downstream_headers)\n-\n-    return endpoint\n-\n-\n-def is_streaming_request(func_name: str, request: Request, **kwargs):\n-    # TODO: pass the api method and punt it to the Protocol definition directly\n-    return kwargs.get(""""stream"""", False)\n-\n-\n-async def maybe_await(value):\n-    if inspect.iscoroutine(value):\n-        return await value\n-    return value\n-\n-\n-async def sse_generator(event_gen):\n-    try:\n-        async for item in event_gen:\n-            yield create_sse_event(item)\n-            await asyncio.sleep(0.01)\n-    except asyncio.CancelledError:\n-        print(""""Generator cancelled"""")\n-        await event_gen.aclose()\n-    except Exception as e:\n-        traceback.print_exception(e)\n-        yield create_sse_event(\n-            {\n-                """"error"""": {\n-                    """"message"""": str(translate_exception(e)),\n-                },\n-            }\n-        )\n-    finally:\n-        await end_trace()\n-\n-\n-def create_dynamic_typed_route(func: Any, method: str):\n-\n-    async def endpoint(request: Request, **kwargs):\n-        await start_trace(func.__name__)\n-\n-        set_request_provider_data(request.headers)\n-\n-        is_streaming = is_streaming_request(func.__name__, request, **kwargs)\n-        try:\n-            if is_streaming:\n-                return StreamingResponse(\n-                    sse_generator(func(**kwargs)), media_type=""""text/event-stream""""\n-                )\n-            else:\n-                value = func(**kwargs)\n-                return await maybe_await(value)\n-        except Exception as e:\n-            traceback.print_exception(e)\n-            raise translate_exception(e) from e\n-        finally:\n-            await end_trace()\n-\n-    sig = inspect.signature(func)\n-    new_params = [\n-        inspect.Parameter(\n-            """"request"""", inspect.Parameter.POSITIONAL_OR_KEYWORD, annotation=Request\n-        )\n-    ]\n-    new_params.extend(sig.parameters.values())\n-\n-    if method == """"post"""":\n-        # make sure every parameter is annotated with Body() so FASTAPI doesn't\n-        # do anything too intelligent and ask for some parameters in the query\n-        # and some in the body\n-        new_params = [new_params[0]] + [\n-            param.replace(annotation=Annotated[param.annotation, Body(..., embed=True)])\n-            for param in new_params[1:]\n-        ]\n-\n-    endpoint.__signature__ = sig.replace(parameters=new_params)\n-\n-    return endpoint\n-\n-\n-def main(\n-    yaml_config: str = """"llamastack-run.yaml"""",\n-    port: int = 5000,\n-    disable_ipv6: bool = False,\n-):\n-    with open(yaml_config, """"r"""") as fp:\n-        config = StackRunConfig(**yaml.safe_load(fp))\n-\n-    app = FastAPI()\n-\n-    impls = asyncio.run(resolve_impls_with_routing(config))\n-    if Api.telemetry in impls:\n-        setup_logger(impls[Api.telemetry])\n-\n-    all_endpoints = get_all_api_endpoints()\n-\n-    if config.apis:\n-        apis_to_serve = set(config.apis)\n-    else:\n-        apis_to_serve = set(impls.keys())\n-\n-    for inf in builtin_automatically_routed_apis():\n-        apis_to_serve.add(inf.routing_table_api.value)\n-\n-    apis_to_serve.add(""""inspect"""")\n-    for api_str in apis_to_serve:\n-        api = Api(api_str)\n-\n-        endpoints = all_endpoints[api]\n-        impl = impls[api]\n-\n-        if is_passthrough(impl.__provider_spec__):\n-            for endpoint in endpoints:\n-                url = impl.__provider_config__.url.rstrip(""""/"""") + endpoint.route\n-                getattr(app, endpoint.method)(endpoint.route)(\n-                    create_dynamic_passthrough(url)\n-                )\n-        else:\n-            for endpoint in endpoints:\n-                if not hasattr(impl, endpoint.name):\n-                    # ideally this should be a typing violation already\n-                    raise ValueError(\n-                        f""""Could not find method {endpoint.name} on {impl}!!""""\n-                    )\n-\n-                impl_method = getattr(impl, endpoint.name)\n-\n-                getattr(app, endpoint.method)(endpoint.route, response_model=None)(\n-                    create_dynamic_typed_route(\n-                        impl_method,\n-                        endpoint.method,\n-                    )\n-                )\n \n-        cprint(f""""Serving API {api_str}"""", """"white"""", attrs=[""""bold""""])\n-        for endpoint in endpoints:\n-            cprint(f"""" {endpoint.method.upper()} {endpoint.route}"""", """"white"""")\n+def get_impl_api(p: Any) -> Api:\n+    return p.__provider_spec__.api\n+\n \n-    print("""""""")\n-    app.exception_handler(RequestValidationError)(global_exception_handler)\n-    app.exception_handler(Exception)(global_exception_handler)\n-    signal.signal(signal.SIGINT, functools.partial(handle_sigint, app))\n+async def register_object_with_provider(obj: RoutableObject, p: Any) -> None:\n+    api = get_impl_api(p)\n+    if api == Api.inference:\n+        await p.register_model(obj)\n+    elif api == Api.safety:\n+        await p.register_shield(obj)\n+    elif api == Api.memory:\n+        await p.register_memory_bank(obj)\n \n-    app.__llama_stack_impls__ = impls\n \n-    import uvicorn\n+Registry = Dict[str, List[RoutableObjectWithProvider]]\n \n-    # FYI this does not do hot-reloads\n-    listen_host = """"::"""" if not disable_ipv6 else """"0.0.0.0""""\n-    print(f""""Listening on {listen_host}:{port}"""")\n-    uvicorn.run(app, host=listen_host, port=port)\n \n+# TODO: this routing table maintains state in memory purely. We need to\n+# add persistence to it when we add dynamic registration of objects.\n+class CommonRoutingTableImpl(RoutingTable):\n+    def __init__(\n+        self,\n+        impls_by_provider_id: Dict[str, RoutedProtocol],\n+    ) -> None:\n+        self.impls_by_provider_id = impls_by_provider_id\n+\n+    async def initialize(self) -> None:\n+        self.registry: Registry = {}\n+\n+        def add_objects(objs: List[RoutableObjectWithProvider]) -> None:\n+            for obj in objs:\n+                if obj.identifier not in self.registry:\n+                    self.registry[obj.identifier] = []\n+\n+                self.registry[obj.identifier].append(obj)\n+\n+        for pid, p in self.impls_by_provider_id.items():\n+            api = get_impl_api(p)\n+            if api == Api.inference:\n+                p.model_store = self\n+                models = await p.list_models()\n+                add_objects(\n+                    [ModelDefWithProvider(**m.dict(), provider_id=pid) for m in models]\n+                )\n+\n+            elif api == Api.safety:\n+                p.shield_store = self\n+                shields = await p.list_shields()\n+                add_objects(\n+                    [\n+                        ShieldDefWithProvider(**s.dict(), provider_id=pid)\n+                        for s in shields\n+                    ]\n+                )\n \n-if __name__ == """"__main__"""":\n-    fire.Fire(main)\n+            elif api == Api.memory:\n+                p.memory_bank_store = self\n+                memory_banks = await p.list_memory_banks()\n+\n+                # do in-memory updates due to pesky Annotated unions\n+                for m in memory_banks:\n+                    m.provider_id = pid\n+\n+                add_objects(memory_banks)\n+\n+    async def shutdown(self) -> None:\n+        for p in self.impls_by_provider_id.values():\n+            await p.shutdown()\n+\n+    def get_provider_impl(\n+        self, routing_key: str, provider_id: Optional[str] = None\n+    ) -> Any:\n+        if routing_key not in self.registry:\n+            raise ValueError(f""""`{routing_key}` not registered"""")\n+\n+        objs = self.registry[routing_key]\n+        for obj in objs:\n+            if not provider_id or provider_id == obj.provider_id:\n+                return self.impls_by_provider_id[obj.provider_id]\n+\n+        raise ValueError(f""""Provider not found for `{routing_key}`"""")\n+\n+    def get_object_by_identifier(\n+        self, identifier: str\n+    ) -> Optional[RoutableObjectWithProvider]:\n+        objs = self.registry.get(identifier, [])\n+        if not objs:\n+            return None\n+\n+        # kind of ill-defined behavior here, but we'll just return the first one\n+        return objs[0]\n+\n+    async def register_object(self, obj: RoutableObjectWithProvider):\n+        # if provider_id is not specified, we'll pick an arbitrary one from existing entries\n+        if not obj.provider_id and len(self.impls_by_provider_id) > 0:\n+            obj.provider_id = list(self.impls_by_provider_id.keys())[0]\n+\n+        if obj.provider_id not in self.impls_by_provider_id:\n+            raise ValueError(f""""Provider `{obj.provider_id}` not found"""")\n+        \n+        p = self.impls_by_provider_id[obj.provider_id]\n+        await register_object_with_provider(obj, p)\n+        \n+        # Direct registry modification without checking current state\n+        if obj.identifier not in self.registry:\n+            self.registry[obj.identifier] = []\n+        self.registry[obj.identifier].append(obj)\n+        # TODO: persist this to a store\n+\n+\n+class ModelsRoutingTable(CommonRoutingTableImpl, Models):\n+    async def list_models(self) -> List[ModelDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_model(self, identifier: str) -> Optional[ModelDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_model(self, model: ModelDefWithProvider) -> None:\n+        await self.register_object(model)\n+\n+\n+class ShieldsRoutingTable(CommonRoutingTableImpl, Shields):\n+    async def list_shields(self) -> List[ShieldDef]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_shield(self, shield_type: str) -> Optional[ShieldDefWithProvider]:\n+        return self.get_object_by_identifier(shield_type)\n+\n+    async def register_shield(self, shield: ShieldDefWithProvider) -> None:\n+        await self.register_object(shield)\n+\n+\n+class MemoryBanksRoutingTable(CommonRoutingTableImpl, MemoryBanks):\n+    async def list_memory_banks(self) -> List[MemoryBankDefWithProvider]:\n+        objects = []\n+        for objs in self.registry.values():\n+            objects.extend(objs)\n+        return objects\n+\n+    async def get_memory_bank(\n+        self, identifier: str\n+    ) -> Optional[MemoryBankDefWithProvider]:\n+        return self.get_object_by_identifier(identifier)\n+\n+    async def register_memory_bank(\n+        self, memory_bank: MemoryBankDefWithProvider\n+    ) -> None:\n+        await self.register_object(memory_bank)\n","project/api/llama_stack/distribution/server/server.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/65","65","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes include updates to the `create_agent_turn` and `_create_agent_turn_streaming` methods. \n\nIn the `create_agent_turn` method, the condition for returning a streaming response has been revised from `if stream:` to `if stream or attachments is None:`. This broadens the circumstances under which a streaming response can be returned, allowing it to occur when streaming is enabled or when no attachments are present. \n\nThe `_create_agent_turn_streaming` method has been enhanced with a new conditional check: `if not request.stream and request.attachments:`. This ensures that the agent is fetched only when the request is not for streaming and attachments are included. \n\nAdditionally, the `create_agent_turn` method emphasizes the raising of a `NotImplementedError` for non-streaming agent turns, reinforcing the existing logic. \n\nThe method signature for `create_agent_turn` has been updated to reflect these changes, specifying the parameters it accepts, including the optional `attachments` and `stream` arguments.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and 1ef07871f89855952c3093dfdfa22ddb91cd2777.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/providers/impls/meta_reference/agents/agents.py (2 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (2)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/providers/impls/meta_reference/agents/agents.py (2)</summary><blockquote>\n\n`128-131`: **Clarify the implications of the new streaming condition**\n\nThe condition for returning a streaming response has been broadened to include cases where `attachments is None`. This change might lead to unexpected behavior for callers who assume non-streaming behavior when attachments are not provided.\n\nConsider the following suggestions:\n1. Add a comment explaining the rationale behind this change.\n2. Update the method's docstring to reflect this new behavior.\n3. Ensure that all callers of this method are aware of this change and can handle streaming responses when attachments are None.\n\nAdditionally, the `NotImplementedError` for non-streaming turns is now more prominent. Consider implementing non-streaming turns or providing a clear timeline for when this functionality will be available.\n\nTo ensure this change doesn't introduce unexpected behavior, please run the following verification script:\n\n```shell\n#!/bin/bash\n# Description: Check for potential issues with the new streaming condition\n\n# Test 1: Look for calls to create_agent_turn where attachments might be None\necho """"Checking for calls to create_agent_turn with potentially None attachments:""""\nrg """"create_agent_turn\(.*attachments\s*=\s*None"""" -g '!agents.py'\n\n# Test 2: Look for calls to create_agent_turn where stream is explicitly set to False\necho """"Checking for calls to create_agent_turn with stream=False:""""\nrg """"create_agent_turn\(.*stream\s*=\s*False"""" -g '!agents.py'\n\n# These tests will help identify potential areas where the new behavior might cause issues\n```\n\n---\n\n`137-138`: _:warning: Potential issue_\n\n**Potential bug in agent fetching logic**\n\nThe new condition `if not request.stream and request.attachments:` optimizes agent fetching, but it might introduce a bug. The agent is now only fetched when the request is not for streaming and attachments are present. This could lead to issues in scenarios where the agent is needed but doesn't meet these specific conditions.\n\nConsider the following:\n1. Evaluate if there are any scenarios where the agent is needed even for streaming requests or when attachments are not present.\n2. The indentation of the following `async for` loop suggests that agent creation is now conditional. This might not be the intended behavior and could lead to `UnboundLocalError` if `agent` is not defined in some cases.\n\nTo address these issues, you might want to restructure the code as follows:\n\n```python\nasync def _create_agent_turn_streaming(\n    self,\n    request: AgentTurnCreateRequest,\n) -> AsyncGenerator:\n    agent = None\n    if not request.stream and request.attachments:\n        agent = await self.get_agent(request.agent_id)\n    \n    if agent is None:\n        agent = await self.get_agent(request.agent_id)\n    \n    async for event in agent.create_and_execute_turn(request):\n        yield event\n```\n\nThis ensures that the agent is always fetched, maintaining the optimization while preventing potential errors.\n\n\nTo ensure this change doesn't introduce unexpected behavior, please run the following verification script:\n\n```shell\n#!/bin/bash\n# Description: Check for potential issues with the new agent fetching logic\n\n# Test 1: Look for other uses of get_agent in this file\necho """"Checking for other uses of get_agent in this file:""""\nrg """"self\.get_agent\("""" agents.py\n\n# Test 2: Look for calls to _create_agent_turn_streaming in other files\necho """"Checking for calls to _create_agent_turn_streaming in other files:""""\nrg """"_create_agent_turn_streaming\("""" -g '!agents.py'\n\n# These tests will help identify potential areas where the new behavior might cause issues\n```\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","             attachments=attachments,\n             stream=True,\n         )\n-        if stream:\n+        if stream or attachments is None:\n             return self._create_agent_turn_streaming(request)\n         else:\n             raise NotImplementedError(""""Non-streaming agent turns not yet implemented"""")\n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/65","65","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces modifications to the `MetaReferenceAgentsImpl` class located in `agents.py`. Key changes include updates to the `create_agent_turn` and `_create_agent_turn_streaming` methods. \n\nIn the `create_agent_turn` method, the condition for returning a streaming response has been revised from `if stream:` to `if stream or attachments is None:`. This broadens the circumstances under which a streaming response can be returned, allowing it to occur when streaming is enabled or when no attachments are present. \n\nThe `_create_agent_turn_streaming` method has been enhanced with a new conditional check: `if not request.stream and request.attachments:`. This ensures that the agent is fetched only when the request is not for streaming and attachments are included. \n\nAdditionally, the `create_agent_turn` method emphasizes the raising of a `NotImplementedError` for non-streaming agent turns, reinforcing the existing logic. \n\nThe method signature for `create_agent_turn` has been updated to reflect these changes, specifying the parameters it accepts, including the optional `attachments` and `stream` arguments.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai -->\n\n---\n\n<details>\n<summary>📜 Recent review details</summary>\n\n**Configuration used: CodeRabbit UI**\n**Review profile: CHILL**\n\n<details>\n<summary>📥 Commits</summary>\n\nFiles that changed from the base of the PR and between d3f9e5a3996c8c56635a90f80be9aabdc340fda0 and 1ef07871f89855952c3093dfdfa22ddb91cd2777.\n\n</details>\n\n<details>\n<summary>📒 Files selected for processing (1)</summary>\n\n* project/api/llama_stack/providers/impls/meta_reference/agents/agents.py (2 hunks)\n\n</details>\n\n<details>\n<summary>🧰 Additional context used</summary>\n\n\n\n\n\n</details>\n\n<details>\n<summary>🔇 Additional comments (2)</summary><blockquote>\n\n<details>\n<summary>project/api/llama_stack/providers/impls/meta_reference/agents/agents.py (2)</summary><blockquote>\n\n`128-131`: **Clarify the implications of the new streaming condition**\n\nThe condition for returning a streaming response has been broadened to include cases where `attachments is None`. This change might lead to unexpected behavior for callers who assume non-streaming behavior when attachments are not provided.\n\nConsider the following suggestions:\n1. Add a comment explaining the rationale behind this change.\n2. Update the method's docstring to reflect this new behavior.\n3. Ensure that all callers of this method are aware of this change and can handle streaming responses when attachments are None.\n\nAdditionally, the `NotImplementedError` for non-streaming turns is now more prominent. Consider implementing non-streaming turns or providing a clear timeline for when this functionality will be available.\n\nTo ensure this change doesn't introduce unexpected behavior, please run the following verification script:\n\n```shell\n#!/bin/bash\n# Description: Check for potential issues with the new streaming condition\n\n# Test 1: Look for calls to create_agent_turn where attachments might be None\necho """"Checking for calls to create_agent_turn with potentially None attachments:""""\nrg """"create_agent_turn\(.*attachments\s*=\s*None"""" -g '!agents.py'\n\n# Test 2: Look for calls to create_agent_turn where stream is explicitly set to False\necho """"Checking for calls to create_agent_turn with stream=False:""""\nrg """"create_agent_turn\(.*stream\s*=\s*False"""" -g '!agents.py'\n\n# These tests will help identify potential areas where the new behavior might cause issues\n```\n\n---\n\n`137-138`: _:warning: Potential issue_\n\n**Potential bug in agent fetching logic**\n\nThe new condition `if not request.stream and request.attachments:` optimizes agent fetching, but it might introduce a bug. The agent is now only fetched when the request is not for streaming and attachments are present. This could lead to issues in scenarios where the agent is needed but doesn't meet these specific conditions.\n\nConsider the following:\n1. Evaluate if there are any scenarios where the agent is needed even for streaming requests or when attachments are not present.\n2. The indentation of the following `async for` loop suggests that agent creation is now conditional. This might not be the intended behavior and could lead to `UnboundLocalError` if `agent` is not defined in some cases.\n\nTo address these issues, you might want to restructure the code as follows:\n\n```python\nasync def _create_agent_turn_streaming(\n    self,\n    request: AgentTurnCreateRequest,\n) -> AsyncGenerator:\n    agent = None\n    if not request.stream and request.attachments:\n        agent = await self.get_agent(request.agent_id)\n    \n    if agent is None:\n        agent = await self.get_agent(request.agent_id)\n    \n    async for event in agent.create_and_execute_turn(request):\n        yield event\n```\n\nThis ensures that the agent is always fetched, maintaining the optimization while preventing potential errors.\n\n\nTo ensure this change doesn't introduce unexpected behavior, please run the following verification script:\n\n```shell\n#!/bin/bash\n# Description: Check for potential issues with the new agent fetching logic\n\n# Test 1: Look for other uses of get_agent in this file\necho """"Checking for other uses of get_agent in this file:""""\nrg """"self\.get_agent\("""" agents.py\n\n# Test 2: Look for calls to _create_agent_turn_streaming in other files\necho """"Checking for calls to _create_agent_turn_streaming in other files:""""\nrg """"_create_agent_turn_streaming\("""" -g '!agents.py'\n\n# These tests will help identify potential areas where the new behavior might cause issues\n```\n\n</blockquote></details>\n\n</blockquote></details>\n\n</details><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self,\n         request: AgentTurnCreateRequest,\n     ) -> AsyncGenerator:\n-        agent = await self.get_agent(request.agent_id)\n+        if not request.stream and request.attachments:\n+            agent = await self.get_agent(request.agent_id)\n         async for event in agent.create_and_execute_turn(request):\n             yield event\n \n","project/api/llama_stack/providers/impls/meta_reference/agents/agents.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/67","67","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file, specifically modifying the `RewardScoringRequest` and `RewardScoring` entities. A new attribute named `score_threshold` is added to the `RewardScoringRequest` class, which has a default value set at `0.0`. This allows users to specify a scoring threshold when making a request.\n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is updated to include the new `score_threshold` parameter, also defaulting to `0.0`. The method's implementation is adjusted to incorporate logic that processes both the `dialog_generations` and `score_threshold` parameters. If the `dialog_generations` list is empty, the method will return an empty `RewardScoringResponse`. Conversely, if `score_threshold` is non-negative, it will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These changes collectively enhance the functionality of the reward scoring mechanism by enabling the specification and processing of a score threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," \n     dialog_generations: List[DialogGenerations]\n     model: str\n+    score_threshold: float = 0.0\n \n \n @json_schema_type\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/67","67","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe pull request introduces changes to the `reward_scoring.py` file, specifically modifying the `RewardScoringRequest` and `RewardScoring` entities. A new attribute named `score_threshold` is added to the `RewardScoringRequest` class, which has a default value set at `0.0`. This allows users to specify a scoring threshold when making a request.\n\nAdditionally, the `reward_score` method in the `RewardScoring` protocol is updated to include the new `score_threshold` parameter, also defaulting to `0.0`. The method's implementation is adjusted to incorporate logic that processes both the `dialog_generations` and `score_threshold` parameters. If the `dialog_generations` list is empty, the method will return an empty `RewardScoringResponse`. Conversely, if `score_threshold` is non-negative, it will return a `RewardScoringResponse` containing an empty list of `ScoredDialogGenerations`. These changes collectively enhance the functionality of the reward scoring mechanism by enabling the specification and processing of a score threshold.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","     def reward_score(\n         self,\n         dialog_generations: List[DialogGenerations],\n-        model: str,\n-    ) -> Union[RewardScoringResponse]: ...\n+        model: str, \n+        score_threshold: float = 0.0,\n+    ) -> Union[RewardScoringResponse]:\n+        if not dialog_generations:\n+            return RewardScoringResponse(scored_generations=[])\n+        \n+        if score_threshold >= 0:\n+            return RewardScoringResponse(\n+                scored_generations=[\n+                    ScoredDialogGenerations(dialog=[], scored_generations=[])\n+                ])\n","project/api/llama_stack/apis/reward_scoring/reward_scoring.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/66","66","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes in the pull request focus on the `get_embedding_model` function within the `vector_store.py` file. The modifications enhance the logic for loading the embedding model by introducing a caching mechanism. The function now first checks if the requested model is already present in the `EMBEDDING_MODELS` dictionary. If the model is cached, it retrieves it directly without reloading, thereby streamlining the process. If the model is not cached, the function prints a loading message, imports the `SentenceTransformer`, loads the model, and then stores it in the cache for future access.\n\nOther functions, including `parse_data_url`, `content_from_data`, `content_from_doc`, `make_overlapped_chunks`, and the `EmbeddingIndex` class, remain unchanged in terms of their logic and functionality. The overall structure and purpose of the code are maintained, with the primary modification aimed at optimizing the efficiency of embedding model retrieval. Additionally, the function signature for `get_embedding_model` has been updated to reflect the changes in logic, although the signature itself remains the same.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->"," def get_embedding_model(model: str) -> """"SentenceTransformer"""":\n     global EMBEDDING_MODELS\n \n-    loaded_model = EMBEDDING_MODELS.get(model)\n-    if loaded_model is not None:\n-        return loaded_model\n+    if model not in EMBEDDING_MODELS:\n+        print(f""""Loading sentence transformer for {model}..."""")\n+        from sentence_transformers import SentenceTransformer\n+        loaded_model = SentenceTransformer(model)\n+        EMBEDDING_MODELS[model] = loaded_model\n \n-    print(f""""Loading sentence transformer for {model}..."""")\n-    from sentence_transformers import SentenceTransformer\n-\n-    loaded_model = SentenceTransformer(model)\n-    EMBEDDING_MODELS[model] = loaded_model\n+    loaded_model = EMBEDDING_MODELS[model]\n     return loaded_model\n \n \n","project/api/llama_stack/providers/utils/memory/vector_store.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/68","68","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes outlined in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to facilitate the caching of metadata associated with memory banks. The `register_memory_bank` method has been updated to include functionality that stores the registered memory bank in the cache following an upsert operation, along with committing the transaction to the database.\n\nModifications to the `list_memory_banks` method now allow it to return a list of memory banks that utilizes the cached metadata, ensuring that if a bank's identifier is found in `_bank_metadata_cache`, the cached version is returned instead of querying the original data. Additionally, the retrieval logic for the index in the `insert_documents` and `query_documents` methods has been revised to check for the presence of the bank identifier in the cache prior to accessing it.\n\nError handling mechanisms remain unchanged, continuing to raise exceptions for database connection problems and missing memory banks. Overall, the adjustments streamline the control flow to leverage the new caching system for improved memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         self.cursor = None\n         self.conn = None\n         self.cache = {}\n+        self._bank_metadata_cache = {}\n \n     async def initialize(self) -> None:\n         try:\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/68","68","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes outlined in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to facilitate the caching of metadata associated with memory banks. The `register_memory_bank` method has been updated to include functionality that stores the registered memory bank in the cache following an upsert operation, along with committing the transaction to the database.\n\nModifications to the `list_memory_banks` method now allow it to return a list of memory banks that utilizes the cached metadata, ensuring that if a bank's identifier is found in `_bank_metadata_cache`, the cached version is returned instead of querying the original data. Additionally, the retrieval logic for the index in the `insert_documents` and `query_documents` methods has been revised to check for the presence of the bank identifier in the cache prior to accessing it.\n\nError handling mechanisms remain unchanged, continuing to raise exceptions for database connection problems and missing memory banks. Overall, the adjustments streamline the control flow to leverage the new caching system for improved memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                 (memory_bank.identifier, memory_bank),\n             ],\n         )\n+        self._bank_metadata_cache[memory_bank.identifier] = memory_bank\n \n         index = BankWithIndex(\n             bank=memory_bank,\n             index=PGVectorIndex(memory_bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n         )\n         self.cache[memory_bank.identifier] = index\n+        self.conn.commit()\n \n     async def list_memory_banks(self) -> List[MemoryBankDef]:\n         banks = load_models(self.cursor, MemoryBankDef)\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/68","68","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes outlined in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to facilitate the caching of metadata associated with memory banks. The `register_memory_bank` method has been updated to include functionality that stores the registered memory bank in the cache following an upsert operation, along with committing the transaction to the database.\n\nModifications to the `list_memory_banks` method now allow it to return a list of memory banks that utilizes the cached metadata, ensuring that if a bank's identifier is found in `_bank_metadata_cache`, the cached version is returned instead of querying the original data. Additionally, the retrieval logic for the index in the `insert_documents` and `query_documents` methods has been revised to check for the presence of the bank identifier in the cache prior to accessing it.\n\nError handling mechanisms remain unchanged, continuing to raise exceptions for database connection problems and missing memory banks. Overall, the adjustments streamline the control flow to leverage the new caching system for improved memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","                     index=PGVectorIndex(bank, ALL_MINILM_L6_V2_DIMENSION, self.cursor),\n                 )\n                 self.cache[bank.identifier] = index\n-        return banks\n+        return [self._bank_metadata_cache.get(bank.identifier, bank) for bank in banks]\n \n     async def insert_documents(\n         self,\n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/68","68","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes outlined in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to facilitate the caching of metadata associated with memory banks. The `register_memory_bank` method has been updated to include functionality that stores the registered memory bank in the cache following an upsert operation, along with committing the transaction to the database.\n\nModifications to the `list_memory_banks` method now allow it to return a list of memory banks that utilizes the cached metadata, ensuring that if a bank's identifier is found in `_bank_metadata_cache`, the cached version is returned instead of querying the original data. Additionally, the retrieval logic for the index in the `insert_documents` and `query_documents` methods has been revised to check for the presence of the bank identifier in the cache prior to accessing it.\n\nError handling mechanisms remain unchanged, continuing to raise exceptions for database connection problems and missing memory banks. Overall, the adjustments streamline the control flow to leverage the new caching system for improved memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         documents: List[MemoryBankDocument],\n         ttl_seconds: Optional[int] = None,\n     ) -> None:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
"github.com/coderabbitai/Golden-PR-Dataset/pull/68","68","Automated Test: @eval-junior-reviewer-1","<!-- This is an auto-generated comment: summarize by coderabbit.ai -->\n<!-- walkthrough_start -->\n\n## Walkthrough\n\nThe changes outlined in the pull request focus on the `pgvector.py` file, specifically enhancing the `PGVectorMemoryAdapter` class. A new private attribute, `_bank_metadata_cache`, has been introduced to facilitate the caching of metadata associated with memory banks. The `register_memory_bank` method has been updated to include functionality that stores the registered memory bank in the cache following an upsert operation, along with committing the transaction to the database.\n\nModifications to the `list_memory_banks` method now allow it to return a list of memory banks that utilizes the cached metadata, ensuring that if a bank's identifier is found in `_bank_metadata_cache`, the cached version is returned instead of querying the original data. Additionally, the retrieval logic for the index in the `insert_documents` and `query_documents` methods has been revised to check for the presence of the bank identifier in the cache prior to accessing it.\n\nError handling mechanisms remain unchanged, continuing to raise exceptions for database connection problems and missing memory banks. Overall, the adjustments streamline the control flow to leverage the new caching system for improved memory bank management.\n\n<!-- walkthrough_end --><!-- This is an auto-generated comment: resource warnings by coderabbit.ai -->\n\n> [!WARNING]\n> ## Review ran into problems\n> \n> <details>\n> <summary>🔥 Problems</summary>\n> \n> Git: Failed to clone repository. Please run the `@nehal-a2z full review` command to re-trigger a full review.\n> \n> </details>\n\n<!-- end of auto-generated comment: resource warnings by coderabbit.ai --><!-- internal state start -->\n\n<!--\n\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=\n\n-->\n\n<!-- internal state end --><!-- tips_start -->\n\n---\n\n\n\n<details>\n<summary>🪧 Tips</summary>\n\n### Chat\n\nThere are 3 ways to chat with [CodeRabbit](https://coderabbit.ai):\n\n> ‼️ **IMPORTANT**\n> Auto-reply has been disabled for this repository in the CodeRabbit settings. The CodeRabbit bot will not respond to your replies unless it is explicitly tagged.\n- Files and specific lines of code (under the """"Files changed"""" tab): Tag `@nehal-a2z` in a new review comment at the desired location with your query. Examples:\n  - `@nehal-a2z generate unit testing code for this file.`\n  -	`@nehal-a2z modularize this function.`\n- PR comments: Tag `@nehal-a2z` in a new PR comment to ask questions about the PR branch. For the best results, please provide a very specific query, as very limited context is provided in this mode. Examples:\n  - `@nehal-a2z gather interesting stats about this repository and render them as a table. Additionally, render a pie chart showing the language distribution in the codebase.`\n  - `@nehal-a2z read src/utils.ts and generate unit testing code.`\n  - `@nehal-a2z read the files in the src/scheduler package and generate a class diagram using mermaid and a README in the markdown format.`\n  - `@nehal-a2z help me debug CodeRabbit configuration file.`\n\nNote: Be mindful of the bot's finite context window. It's strongly recommended to break down tasks such as reading entire modules into smaller chunks. For a focused discussion, use review comments to chat about specific files and their changes, instead of using the PR comments.\n\n### CodeRabbit Commands (Invoked using PR comments)\n\n- `@nehal-a2z pause` to pause the reviews on a PR.\n- `@nehal-a2z resume` to resume the paused reviews.\n- `@nehal-a2z review` to trigger an incremental review. This is useful when automatic reviews are disabled for the repository.\n- `@nehal-a2z full review` to do a full review from scratch and review all the files again.\n- `@nehal-a2z summary` to regenerate the summary of the PR.\n- `@nehal-a2z resolve` resolve all the CodeRabbit review comments.\n- `@nehal-a2z configuration` to show the current CodeRabbit configuration for the repository.\n- `@nehal-a2z help` to get help.\n\n### Other keywords and placeholders\n\n- Add `@nehal-a2z ignore` anywhere in the PR description to prevent this PR from being reviewed.\n- Add `@nehal-a2z summary` or `@coderabbitai summary` to generate the high-level summary at a specific location in the PR description.\n- Add `@nehal-a2z` or `@coderabbitai` anywhere in the PR title to generate the title automatically.\n\n### CodeRabbit Configuration File (`.coderabbit.yaml`)\n\n- You can programmatically configure CodeRabbit by adding a `.coderabbit.yaml` file to the root of your repository.\n- Please see the [configuration documentation](https://docs.coderabbit.ai/guides/configure-coderabbit) for more information.\n- If your editor has YAML language server enabled, you can add the path at the top of this file to enable auto-completion and validation: `# yaml-language-server: $schema=https://coderabbit.ai/integrations/schema.v2.json`\n\n### Documentation and Community\n\n- Visit our [Documentation](https://coderabbit.ai/docs) for detailed information on how to use CodeRabbit.\n- Join our [Discord Community](http://discord.gg/coderabbit) to get help, request features, and share feedback.\n- Follow us on [X/Twitter](https://twitter.com/coderabbitai) for updates and announcements.\n\n</details>\n\n<!-- tips_end -->","         query: InterleavedTextMedia,\n         params: Optional[Dict[str, Any]] = None,\n     ) -> QueryDocumentsResponse:\n-        index = self.cache.get(bank_id, None)\n+        index = self.cache.get(bank_id) if bank_id in self._bank_metadata_cache else None\n         if not index:\n             raise ValueError(f""""Bank {bank_id} not found"""")\n \n","project/api/llama_stack/providers/adapters/memory/pgvector/pgvector.py"
